+ ulimit -c
unlimited
+ '[' -z rssd2 ']'
+ pool_name=rssd2
++ date +%FT%T
+ cur_time=2024-01-12T16:59:27
+ default_cache_size=128849018880
+ cache_size=128849018880
++ git rev-parse --show-toplevel
+ lsvd_dir=/home/isaackhor/code/lsvd-rbd
++ ip addr
++ perl -lane 'print $1 if /inet (10\.1\.[0-9.]+)\/24/'
++ head -n 1
+ gw_ip=10.1.0.5
+ client_ip=10.1.0.6
+ rcache=/mnt/nvme/
+ wlog=/mnt/nvme-remote/
+ cache_size_gb=120
+ outfile=/home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T16:59:27.lsvd-multi.rssd2.txt
+ echo 'Running gateway on 10.1.0.5, client on 10.1.0.6'
Running gateway on 10.1.0.5, client on 10.1.0.6
+ imgname=lsvd-benchmark
+ imgsize=10g
+ blocksize=4096
+ source /home/isaackhor/code/lsvd-rbd/experiments/common.bash
++ set -xeuo pipefail
++ '[' 0 -ne 0 ']'
+ echo '===Building LSVD...'
===Building LSVD...
+ cd /home/isaackhor/code/lsvd-rbd
+ make clean
make[1]: Entering directory '/home/isaackhor/code/lsvd-rbd/atc2024'
latexmk -C
Rc files read:
  /etc/LatexMk
  latexmkrc
Latexmk: This is Latexmk, John Collins, 20 November 2021, version: 4.76.
rm -f main.pdf
make[1]: Leaving directory '/home/isaackhor/code/lsvd-rbd/atc2024'
+ make -j20 release
CC objects.cc
CC translate.cc
CC io.cc
CC img_reader.cc
CC config.cc
CC mkcache.cc
CC nvme.cc
CC write_cache.cc
CC file_backend.cc
CC shared_read_cache.cc
CC rados_backend.cc
CC lsvd_debug.cc
CC liblsvd.cc
CC image.cc
CC imgtool.cc
CC thick-image.cc
In file included from translate.cc:28:
./extent.h:160:13: warning: implicit truncation from 'int' to a one-bit wide bit-field changes value from 1 to -1 [-Wsingle-bit-bitfield-constant-conversion]
  160 |         s.d = 1; // new extents are dirty
      |             ^ ~
./extent.h:520:11: note: in instantiation of member function 'extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>::_extent' requested here
  520 |         T _e(base, limit - base, e);
      |           ^
./extent.h:671:9: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::_update' requested here
  671 |         _update(base, limit, e, false, nullptr);
      |         ^
translate.cc:451:18: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::update' requested here
  451 |             map->update(m.lba, m.lba + m.len,
      |                  ^
In file included from translate.cc:28:
./extent.h:174:13: warning: implicit truncation from 'int' to a one-bit wide bit-field changes value from 1 to -1 [-Wsingle-bit-bitfield-constant-conversion]
  174 |         s.d = 1; // dirty
      |             ^ ~
./extent.h:553:21: note: in instantiation of member function 'extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>::relimit' requested here
  553 |                 it->relimit(base);
      |                     ^
./extent.h:671:9: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::_update' requested here
  671 |         _update(base, limit, e, false, nullptr);
      |         ^
translate.cc:451:18: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::update' requested here
  451 |             map->update(m.lba, m.lba + m.len,
      |                  ^
In file included from translate.cc:28:
./extent.h:185:13: warning: implicit truncation from 'int' to a one-bit wide bit-field changes value from 1 to -1 [-Wsingle-bit-bitfield-constant-conversion]
  185 |         s.d = 1; // dirty
      |             ^ ~
./extent.h:601:21: note: in instantiation of member function 'extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>::rebase' requested here
  601 |                 it->rebase(limit);
      |                     ^
./extent.h:671:9: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::_update' requested here
  671 |         _update(base, limit, e, false, nullptr);
      |         ^
translate.cc:451:18: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::update' requested here
  451 |             map->update(m.lba, m.lba + m.len,
      |                  ^
3 warnings generated.
LD liblsvd.so
LD imgtool
LD thick-image
+ mkdir -p /home/isaackhor/code/lsvd-rbd/test/baklibs/
+ cp /home/isaackhor/code/lsvd-rbd/liblsvd.so /home/isaackhor/code/lsvd-rbd/test/baklibs/liblsvd.so.2024-01-12T16:59:27
+ create_lsvd_thick rssd2 lsvd-benchmark.multi.1 10g
+ local pool=rssd2
+ local img=lsvd-benchmark.multi.1
+ local size=10g
+ cd /home/isaackhor/code/lsvd-rbd
+ create_lsvd_thick rssd2 lsvd-benchmark.multi.2 10g
+ ./remove_objs.py rssd2 lsvd-benchmark.multi.1
+ local pool=rssd2
+ local img=lsvd-benchmark.multi.2
+ local size=10g
+ cd /home/isaackhor/code/lsvd-rbd
+ create_lsvd_thick rssd2 lsvd-benchmark.multi.3 10g
+ ./remove_objs.py rssd2 lsvd-benchmark.multi.2
+ local pool=rssd2
+ local img=lsvd-benchmark.multi.3
+ local size=10g
+ cd /home/isaackhor/code/lsvd-rbd
+ ./remove_objs.py rssd2 lsvd-benchmark.multi.3
+ wait
+ create_lsvd_thick rssd2 lsvd-benchmark.multi.4 10g
+ local pool=rssd2
+ local img=lsvd-benchmark.multi.4
+ local size=10g
+ cd /home/isaackhor/code/lsvd-rbd
+ ./remove_objs.py rssd2 lsvd-benchmark.multi.4
Removing all objects from pool rssd2 with prefix lsvd-benchmark.multi.1
+Removing all objects from pool rssd2 with prefix lsvd-benchmark.multi.4
+Removing all objects from pool rssd2 with prefix lsvd-benchmark.multi.3
+Removing all objects from pool rssd2 with prefix lsvd-benchmark.multi.2
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Removed 1283/60942 objects

Removed 1283/60919 objects
+ ./thick-image --size=10g rssd2/lsvd-benchmark.multi.4
+ ./thick-image --size=10g rssd2/lsvd-benchmark.multi.2

Removed 1283/60923 objects

Removed 1283/60916 objects
+ ./thick-image --size=10g rssd2/lsvd-benchmark.multi.3
+ ./thick-image --size=10g rssd2/lsvd-benchmark.multi.1
Thick provisioning: 1% complete...Thick provisioning: 1% complete...Thick provisioning: 1% complete...Thick provisioning: 1% complete...Thick provisioning: 2% complete...Thick provisioning: 2% complete...Thick provisioning: 2% complete...Thick provisioning: 2% complete...Thick provisioning: 3% complete...Thick provisioning: 3% complete...Thick provisioning: 3% complete...Thick provisioning: 3% complete...Thick provisioning: 4% complete...Thick provisioning: 4% complete...Thick provisioning: 4% complete...Thick provisioning: 4% complete...Thick provisioning: 5% complete...Thick provisioning: 5% complete...Thick provisioning: 5% complete...Thick provisioning: 5% complete...Thick provisioning: 6% complete...Thick provisioning: 6% complete...Thick provisioning: 6% complete...Thick provisioning: 6% complete...Thick provisioning: 7% complete...Thick provisioning: 7% complete...Thick provisioning: 7% complete...Thick provisioning: 7% complete...Thick provisioning: 8% complete...Thick provisioning: 8% complete...Thick provisioning: 8% complete...Thick provisioning: 9% complete...Thick provisioning: 8% complete...Thick provisioning: 9% complete...Thick provisioning: 9% complete...Thick provisioning: 9% complete...Thick provisioning: 10% complete...Thick provisioning: 10% complete...Thick provisioning: 10% complete...Thick provisioning: 11% complete...Thick provisioning: 11% complete...Thick provisioning: 10% complete...Thick provisioning: 12% complete...Thick provisioning: 11% complete...Thick provisioning: 12% complete...Thick provisioning: 11% complete...Thick provisioning: 13% complete...Thick provisioning: 12% complete...Thick provisioning: 13% complete...Thick provisioning: 12% complete...Thick provisioning: 14% complete...Thick provisioning: 13% complete...Thick provisioning: 13% complete...Thick provisioning: 14% complete...Thick provisioning: 15% complete...Thick provisioning: 14% complete...Thick provisioning: 14% complete...Thick provisioning: 15% complete...Thick provisioning: 15% complete...Thick provisioning: 16% complete...Thick provisioning: 16% complete...Thick provisioning: 15% complete...Thick provisioning: 16% complete...Thick provisioning: 17% complete...Thick provisioning: 17% complete...Thick provisioning: 16% complete...Thick provisioning: 17% complete...Thick provisioning: 18% complete...Thick provisioning: 18% complete...Thick provisioning: 17% complete...Thick provisioning: 18% complete...Thick provisioning: 19% complete...Thick provisioning: 19% complete...Thick provisioning: 19% complete...Thick provisioning: 18% complete...Thick provisioning: 20% complete...Thick provisioning: 20% complete...Thick provisioning: 20% complete...Thick provisioning: 19% complete...Thick provisioning: 21% complete...Thick provisioning: 20% complete...Thick provisioning: 21% complete...Thick provisioning: 21% complete...Thick provisioning: 22% complete...Thick provisioning: 22% complete...Thick provisioning: 21% complete...Thick provisioning: 22% complete...Thick provisioning: 23% complete...Thick provisioning: 22% complete...Thick provisioning: 23% complete...Thick provisioning: 24% complete...Thick provisioning: 23% complete...Thick provisioning: 23% complete...Thick provisioning: 24% complete...Thick provisioning: 25% complete...Thick provisioning: 24% complete...Thick provisioning: 24% complete...Thick provisioning: 25% complete...Thick provisioning: 26% complete...Thick provisioning: 25% complete...Thick provisioning: 25% complete...Thick provisioning: 26% complete...Thick provisioning: 27% complete...Thick provisioning: 26% complete...Thick provisioning: 26% complete...Thick provisioning: 28% complete...Thick provisioning: 27% complete...Thick provisioning: 27% complete...Thick provisioning: 27% complete...Thick provisioning: 29% complete...Thick provisioning: 28% complete...Thick provisioning: 30% complete...Thick provisioning: 28% complete...Thick provisioning: 31% complete...Thick provisioning: 29% complete...Thick provisioning: 28% complete...Thick provisioning: 29% complete...Thick provisioning: 29% complete...Thick provisioning: 30% complete...Thick provisioning: 30% complete...Thick provisioning: 32% complete...Thick provisioning: 30% complete...Thick provisioning: 31% complete...Thick provisioning: 31% complete...Thick provisioning: 33% complete...Thick provisioning: 31% complete...Thick provisioning: 32% complete...Thick provisioning: 32% complete...Thick provisioning: 34% complete...Thick provisioning: 33% complete...Thick provisioning: 32% complete...Thick provisioning: 33% complete...Thick provisioning: 35% complete...Thick provisioning: 33% complete...Thick provisioning: 34% complete...Thick provisioning: 34% complete...Thick provisioning: 36% complete...Thick provisioning: 34% complete...Thick provisioning: 35% complete...Thick provisioning: 35% complete...Thick provisioning: 37% complete...Thick provisioning: 36% complete...Thick provisioning: 35% complete...Thick provisioning: 36% complete...Thick provisioning: 38% complete...Thick provisioning: 36% complete...Thick provisioning: 37% complete...Thick provisioning: 37% complete...Thick provisioning: 37% complete...Thick provisioning: 39% complete...Thick provisioning: 38% complete...Thick provisioning: 38% complete...Thick provisioning: 40% complete...Thick provisioning: 38% complete...Thick provisioning: 39% complete...Thick provisioning: 41% complete...Thick provisioning: 40% complete...Thick provisioning: 39% complete...Thick provisioning: 39% complete...Thick provisioning: 41% complete...Thick provisioning: 40% complete...Thick provisioning: 42% complete...Thick provisioning: 40% complete...Thick provisioning: 41% complete...Thick provisioning: 41% complete...Thick provisioning: 43% complete...Thick provisioning: 42% complete...Thick provisioning: 44% complete...Thick provisioning: 43% complete...Thick provisioning: 42% complete...Thick provisioning: 42% complete...Thick provisioning: 45% complete...Thick provisioning: 44% complete...Thick provisioning: 43% complete...Thick provisioning: 43% complete...Thick provisioning: 44% complete...Thick provisioning: 45% complete...Thick provisioning: 46% complete...Thick provisioning: 44% complete...Thick provisioning: 45% complete...Thick provisioning: 46% complete...Thick provisioning: 47% complete...Thick provisioning: 45% complete...Thick provisioning: 46% complete...Thick provisioning: 47% complete...Thick provisioning: 46% complete...Thick provisioning: 48% complete...Thick provisioning: 47% complete...Thick provisioning: 49% complete...Thick provisioning: 48% complete...Thick provisioning: 47% complete...Thick provisioning: 49% complete...Thick provisioning: 48% complete...Thick provisioning: 50% complete...Thick provisioning: 48% complete...Thick provisioning: 50% complete...Thick provisioning: 51% complete...Thick provisioning: 49% complete...Thick provisioning: 49% complete...Thick provisioning: 51% complete...Thick provisioning: 52% complete...Thick provisioning: 50% complete...Thick provisioning: 50% complete...Thick provisioning: 52% complete...Thick provisioning: 53% complete...Thick provisioning: 51% complete...Thick provisioning: 51% complete...Thick provisioning: 53% complete...Thick provisioning: 54% complete...Thick provisioning: 52% complete...Thick provisioning: 52% complete...Thick provisioning: 54% complete...Thick provisioning: 55% complete...Thick provisioning: 53% complete...Thick provisioning: 55% complete...Thick provisioning: 53% complete...Thick provisioning: 56% complete...Thick provisioning: 54% complete...Thick provisioning: 56% complete...Thick provisioning: 55% complete...Thick provisioning: 57% complete...Thick provisioning: 54% complete...Thick provisioning: 56% complete...Thick provisioning: 57% complete...Thick provisioning: 58% complete...Thick provisioning: 55% complete...Thick provisioning: 56% complete...Thick provisioning: 59% complete...Thick provisioning: 57% complete...Thick provisioning: 58% complete...Thick provisioning: 58% complete...Thick provisioning: 60% complete...Thick provisioning: 59% complete...Thick provisioning: 57% complete...Thick provisioning: 61% complete...Thick provisioning: 59% complete...Thick provisioning: 60% complete...Thick provisioning: 58% complete...Thick provisioning: 61% complete...Thick provisioning: 62% complete...Thick provisioning: 60% complete...Thick provisioning: 59% complete...Thick provisioning: 62% complete...Thick provisioning: 63% complete...Thick provisioning: 61% complete...Thick provisioning: 60% complete...Thick provisioning: 63% complete...Thick provisioning: 64% complete...Thick provisioning: 62% complete...Thick provisioning: 61% complete...Thick provisioning: 65% complete...Thick provisioning: 64% complete...Thick provisioning: 63% complete...Thick provisioning: 62% complete...Thick provisioning: 65% complete...Thick provisioning: 64% complete...Thick provisioning: 66% complete...Thick provisioning: 63% complete...Thick provisioning: 66% complete...Thick provisioning: 65% complete...Thick provisioning: 67% complete...Thick provisioning: 64% complete...Thick provisioning: 67% complete...Thick provisioning: 66% complete...Thick provisioning: 68% complete...Thick provisioning: 65% complete...Thick provisioning: 68% complete...Thick provisioning: 67% complete...Thick provisioning: 69% complete...Thick provisioning: 66% complete...Thick provisioning: 70% complete...Thick provisioning: 69% complete...Thick provisioning: 68% complete...Thick provisioning: 70% complete...Thick provisioning: 67% complete...Thick provisioning: 71% complete...Thick provisioning: 69% complete...Thick provisioning: 71% complete...Thick provisioning: 70% complete...Thick provisioning: 72% complete...Thick provisioning: 72% complete...Thick provisioning: 68% complete...Thick provisioning: 71% complete...Thick provisioning: 73% complete...Thick provisioning: 73% complete...Thick provisioning: 69% complete...Thick provisioning: 72% complete...Thick provisioning: 74% complete...Thick provisioning: 74% complete...Thick provisioning: 70% complete...Thick provisioning: 75% complete...Thick provisioning: 75% complete...Thick provisioning: 73% complete...Thick provisioning: 71% complete...Thick provisioning: 76% complete...Thick provisioning: 74% complete...Thick provisioning: 72% complete...Thick provisioning: 77% complete...Thick provisioning: 75% complete...Thick provisioning: 73% complete...Thick provisioning: 76% complete...Thick provisioning: 74% complete...Thick provisioning: 76% complete...Thick provisioning: 75% complete...Thick provisioning: 77% complete...Thick provisioning: 76% complete...Thick provisioning: 78% complete...Thick provisioning: 77% complete...Thick provisioning: 78% complete...Thick provisioning: 77% complete...Thick provisioning: 79% complete...Thick provisioning: 78% complete...Thick provisioning: 80% complete...Thick provisioning: 79% complete...Thick provisioning: 78% complete...Thick provisioning: 79% complete...Thick provisioning: 81% complete...Thick provisioning: 79% complete...Thick provisioning: 80% complete...Thick provisioning: 80% complete...Thick provisioning: 81% complete...Thick provisioning: 80% complete...Thick provisioning: 81% complete...Thick provisioning: 82% complete...Thick provisioning: 81% complete...Thick provisioning: 82% complete...Thick provisioning: 82% complete...Thick provisioning: 83% complete...Thick provisioning: 83% complete...Thick provisioning: 84% complete...Thick provisioning: 82% complete...Thick provisioning: 83% complete...Thick provisioning: 84% complete...Thick provisioning: 85% complete...Thick provisioning: 83% complete...Thick provisioning: 84% complete...Thick provisioning: 86% complete...Thick provisioning: 84% complete...Thick provisioning: 85% complete...Thick provisioning: 85% complete...Thick provisioning: 87% complete...Thick provisioning: 85% complete...Thick provisioning: 86% complete...Thick provisioning: 86% complete...Thick provisioning: 88% complete...Thick provisioning: 86% complete...Thick provisioning: 87% complete...Thick provisioning: 87% complete...Thick provisioning: 88% complete...Thick provisioning: 87% complete...Thick provisioning: 88% complete...Thick provisioning: 89% complete...Thick provisioning: 89% complete...Thick provisioning: 88% complete...Thick provisioning: 90% complete...Thick provisioning: 89% complete...Thick provisioning: 90% complete...Thick provisioning: 91% complete...Thick provisioning: 89% complete...Thick provisioning: 90% complete...Thick provisioning: 92% complete...Thick provisioning: 91% complete...Thick provisioning: 90% complete...Thick provisioning: 91% complete...Thick provisioning: 93% complete...Thick provisioning: 92% complete...Thick provisioning: 92% complete...Thick provisioning: 94% complete...Thick provisioning: 91% complete...Thick provisioning: 93% complete...Thick provisioning: 93% complete...Thick provisioning: 95% complete...Thick provisioning: 92% complete...Thick provisioning: 94% complete...Thick provisioning: 96% complete...Thick provisioning: 94% complete...Thick provisioning: 93% complete...Thick provisioning: 95% complete...Thick provisioning: 95% complete...Thick provisioning: 97% complete...Thick provisioning: 94% complete...Thick provisioning: 96% complete...Thick provisioning: 96% complete...Thick provisioning: 98% complete...Thick provisioning: 95% complete...Thick provisioning: 97% complete...Thick provisioning: 97% complete...Thick provisioning: 96% complete...Thick provisioning: 99% complete...Thick provisioning: 98% complete...Thick provisioning: 98% complete...Thick provisioning: 97% complete...Thick provisioning: 100% complete...Thick provisioning: 99% complete...Thick provisioning: 98% complete...Thick provisioning: 99% complete...Thick provisioning: 100% complete...Thick provisioning: 100% complete...Thick provisioning: 99% complete...Thick provisioning: 100% complete...done
+ rados -p rssd2 stat lsvd-benchmark.multi.3
Thick provisioning: 100% complete...Thick provisioning: 100% complete...done
rssd2/lsvd-benchmark.multi.3 mtime 2024-01-12T17:00:48.000000+0000, size 4096
+ rados -p rssd2 stat lsvd-benchmark.multi.4
Thick provisioning: 100% complete...done
rssd2/lsvd-benchmark.multi.4 mtime 2024-01-12T17:00:48.000000+0000, size 4096
+ rados -p rssd2 stat lsvd-benchmark.multi.2
Thick provisioning: 100% complete...done
+ rados -p rssd2 stat lsvd-benchmark.multi.1
rssd2/lsvd-benchmark.multi.2 mtime 2024-01-12T17:00:48.000000+0000, size 4096
rssd2/lsvd-benchmark.multi.1 mtime 2024-01-12T17:00:48.000000+0000, size 4096
+ kill_nvmf
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ scripts/rpc.py spdk_kill_instance SIGTERM
+ true
+ scripts/rpc.py spdk_kill_instance SIGKILL
+ true
+ pkill -f nvmf_tgt
+ true
+ pkill -f reactor_0
+ true
+ sleep 2
+ fstrim /mnt/nvme
+ launch_lsvd_gw_background /mnt/nvme/ /mnt/nvme-remote/ 128849018880
+ local rcache_root=/mnt/nvme/
+ local wlog_root=/mnt/nvme-remote/
+ local cache_size=128849018880
+ echo 4096
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ mkdir -p /mnt/nvme//lsvd-read/ /mnt/nvme-remote//lsvd-write/
+ export LSVD_RCACHE_DIR=/mnt/nvme//lsvd-read/
+ LSVD_RCACHE_DIR=/mnt/nvme//lsvd-read/
+ export LSVD_WCACHE_DIR=/mnt/nvme-remote//lsvd-write/
+ LSVD_WCACHE_DIR=/mnt/nvme-remote//lsvd-write/
+ export LSVD_GC_THRESHOLD=40
+ LSVD_GC_THRESHOLD=40
+ export LSVD_CACHE_SIZE=128849018880
+ LSVD_CACHE_SIZE=128849018880
+ rm -rf '/mnt/nvme-remote//lsvd-write/*'
+ sleep 5
+ LD_PRELOAD=/home/isaackhor/code/lsvd-rbd/liblsvd.so
+ ./build/bin/nvmf_tgt -m '[0,1,2,3]'
[2024-01-12 17:00:52.232467] Starting SPDK v23.09 git sha1 fb13eebf5 / DPDK 23.07.0 initialization...
[2024-01-12 17:00:52.232589] [ DPDK EAL parameters: nvmf --no-shconf -l 0,1,2,3 --huge-unlink --log-level=lib.eal:6 --log-level=lib.cryptodev:5 --log-level=user1:6 --iova-mode=pa --base-virtaddr=0x200000000000 --match-allocations --file-prefix=spdk_pid2818929 ]
TELEMETRY: No legacy callbacks, legacy socket not created
[2024-01-12 17:00:52.319794] app.c: 786:spdk_app_start: *NOTICE*: Total cores available: 4
[2024-01-12 17:00:52.436583] reactor.c: 937:reactor_run: *NOTICE*: Reactor started on core 1
[2024-01-12 17:00:52.436689] reactor.c: 937:reactor_run: *NOTICE*: Reactor started on core 2
[2024-01-12 17:00:52.436783] reactor.c: 937:reactor_run: *NOTICE*: Reactor started on core 3
[2024-01-12 17:00:52.436787] reactor.c: 937:reactor_run: *NOTICE*: Reactor started on core 0
+ configure_nvmf_common 10.1.0.5
+ local gateway_ip=10.1.0.5
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ scripts/rpc.py bdev_rbd_register_cluster rbd_cluster
rbd_cluster
+ scripts/rpc.py nvmf_create_transport -t TCP -u 16384 -m 8 -c 8192
[2024-01-12 17:00:57.992054] tcp.c: 656:nvmf_tcp_create: *NOTICE*: *** TCP Transport Init ***
+ scripts/rpc.py nvmf_create_subsystem nqn.2016-06.io.spdk:cnode1 -a -s SPDK00000000000001 -d SPDK_Controller1
+ scripts/rpc.py nvmf_subsystem_add_listener nqn.2016-06.io.spdk:cnode1 -t tcp -a 10.1.0.5 -s 9922
[2024-01-12 17:00:58.678738] tcp.c: 948:nvmf_tcp_listen: *NOTICE*: *** NVMe/TCP Target Listening on 10.1.0.5 port 9922 ***
+ add_rbd_img rssd2 lsvd-benchmark.multi.1
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ local pool=rssd2
+ local img=lsvd-benchmark.multi.1
+ local bdev=bdev_lsvd-benchmark.multi.1
+ scripts/rpc.py bdev_rbd_create rssd2 lsvd-benchmark.multi.1 4096 -c rbd_cluster -b bdev_lsvd-benchmark.multi.1
[1m[36m[INFO shared_read_cache.cc:692 sharded_cache] Initialising read cache of size 122880 MiB in 16 shards, 7680 MiB each
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_0 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_1 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_2 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_3 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_4 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_5 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_6 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_7 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_8 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_9 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_10 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_11 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_12 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_13 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_14 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_15 for the read cache
[0m[1m[36m[INFO image.cc:74 image_open] Creating write cache file /mnt/nvme-remote//lsvd-write//ce9dbd0e-67a2-447b-8ff8-4e386d1605f7.wcache
[0m[1m[36m[INFO liblsvd.cc:280 rbd_open] Opened image: lsvd-benchmark.multi.1, size 10737418240
[0m[35m[DBG translate.cc:1365 gc_thread] starting gc thread
[0m[2024-01-12 17:01:11.624154] bdev_rbd.c:1329:bdev_rbd_create: *NOTICE*: Add bdev_lsvd-benchmark.multi.1 rbd disk to lun
bdev_lsvd-benchmark.multi.1
+ scripts/rpc.py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 bdev_lsvd-benchmark.multi.1
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 1/2 hits, 0 MiB read, 1.778 read amp, 2 total
[0m+ add_rbd_img rssd2 lsvd-benchmark.multi.2
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ local pool=rssd2
+ local img=lsvd-benchmark.multi.2
+ local bdev=bdev_lsvd-benchmark.multi.2
+ scripts/rpc.py bdev_rbd_create rssd2 lsvd-benchmark.multi.2 4096 -c rbd_cluster -b bdev_lsvd-benchmark.multi.2
[1m[36m[INFO image.cc:74 image_open] Creating write cache file /mnt/nvme-remote//lsvd-write//347196c9-2e6a-4c8f-89bb-ff9a2d684937.wcache
[0m[1m[36m[INFO liblsvd.cc:280 rbd_open] Opened image: lsvd-benchmark.multi.2, size 10737418240
[0m[35m[DBG translate.cc:1365 gc_thread] starting gc thread
[0m[2024-01-12 17:01:13.162940] bdev_rbd.c:1329:bdev_rbd_create: *NOTICE*: Add bdev_lsvd-benchmark.multi.2 rbd disk to lun
bdev_lsvd-benchmark.multi.2
+ scripts/rpc.py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 bdev_lsvd-benchmark.multi.2
+ add_rbd_img rssd2 lsvd-benchmark.multi.3
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ local pool=rssd2
+ local img=lsvd-benchmark.multi.3
+ local bdev=bdev_lsvd-benchmark.multi.3
+ scripts/rpc.py bdev_rbd_create rssd2 lsvd-benchmark.multi.3 4096 -c rbd_cluster -b bdev_lsvd-benchmark.multi.3
[1m[36m[INFO image.cc:74 image_open] Creating write cache file /mnt/nvme-remote//lsvd-write//7d7b21ef-0c62-4f9f-86f7-8a11f7993dfa.wcache
[0m[1m[36m[INFO liblsvd.cc:280 rbd_open] Opened image: lsvd-benchmark.multi.3, size 10737418240
[0m[35m[DBG translate.cc:1365 gc_thread] starting gc thread
[0m[2024-01-12 17:01:14.634569] bdev_rbd.c:1329:bdev_rbd_create: *NOTICE*: Add bdev_lsvd-benchmark.multi.3 rbd disk to lun
bdev_lsvd-benchmark.multi.3
+ scripts/rpc.py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 bdev_lsvd-benchmark.multi.3
+ add_rbd_img rssd2 lsvd-benchmark.multi.4
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ local pool=rssd2
+ local img=lsvd-benchmark.multi.4
+ local bdev=bdev_lsvd-benchmark.multi.4
+ scripts/rpc.py bdev_rbd_create rssd2 lsvd-benchmark.multi.4 4096 -c rbd_cluster -b bdev_lsvd-benchmark.multi.4
[1m[36m[INFO image.cc:74 image_open] Creating write cache file /mnt/nvme-remote//lsvd-write//1d5bd8bc-155c-4c01-ae6f-6f75e3aa914e.wcache
[0m[1m[36m[INFO liblsvd.cc:280 rbd_open] Opened image: lsvd-benchmark.multi.4, size 10737418240
[0m[35m[DBG translate.cc:1365 gc_thread] starting gc thread
[0m[2024-01-12 17:01:16.077846] bdev_rbd.c:1329:bdev_rbd_create: *NOTICE*: Add bdev_lsvd-benchmark.multi.4 rbd disk to lun
bdev_lsvd-benchmark.multi.4
+ scripts/rpc.py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 bdev_lsvd-benchmark.multi.4
+ trap 'cleanup_nvmf; exit' SIGINT SIGTERM EXIT
+ run_client_bench 10.1.0.6 /home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T16:59:27.lsvd-multi.rssd2.txt multi-client/client-bench-multi.bash read_entire_img=1
+ local client_ip=10.1.0.6
+ local outfile=/home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T16:59:27.lsvd-multi.rssd2.txt
+ local benchscript=multi-client/client-bench-multi.bash
+ local additional_args=read_entire_img=1
+ cd /home/isaackhor/code/lsvd-rbd/experiments
+ ssh 10.1.0.6 'mkdir -p /tmp/filebench; rm -rf /tmp/filebench/*'
+ scp ./filebench-workloads/fileserver.f ./filebench-workloads/oltp.f ./filebench-workloads/randomwrite.f ./filebench-workloads/varmail.f root@10.1.0.6:/tmp/filebench/
+ ssh 10.1.0.6 'bash -s gw_ip=10.1.0.5 read_entire_img=1'
+ tee -a /home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T16:59:27.lsvd-multi.rssd2.txt
===Starting client benchmark

NQN:nqn.2016-06.io.spdk:cnode1 disconnected 0 controller(s)
device: nvme1
Node                  SN                   Model                                    Namespace Usage                      Format           FW Rev  
--------------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------
/dev/nvme0n1          PHM27522000B480BGN   INTEL SSDPE21D480GA                      1         480.10  GB / 480.10  GB    512   B +  0 B   E2010414
/dev/nvme1n1          SPDK00000000000001   SPDK_Controller1                         1          10.74  GB /  10.74  GB      4 KiB +  0 B   23.09   
/dev/nvme1n2          SPDK00000000000001   SPDK_Controller1                         2          10.74  GB /  10.74  GB      4 KiB +  0 B   23.09   
/dev/nvme1n3          SPDK00000000000001   SPDK_Controller1                         3          10.74  GB /  10.74  GB      4 KiB +  0 B   23.09   
/dev/nvme1n4          SPDK00000000000001   SPDK_Controller1                         4          10.74  GB /  10.74  GB      4 KiB +  0 B   23.09   
Using device /dev/nvme1n1
/dev/nvme1n2
/dev/nvme1n3
/dev/nvme1n4


===Reading entire image to warm cache===

116391936 bytes (116 MB, 111 MiB) copied, 1 s, 116 MB/s115343360 bytes (115 MB, 110 MiB) copied, 1 s, 115 MB/s108003328 bytes (108 MB, 103 MiB) copied, 1 s, 107 MB/s113246208 bytes (113 MB, 108 MiB) copied, 1 s, 112 MB/s220200960 bytes (220 MB, 210 MiB) copied, 2 s, 110 MB/s217055232 bytes (217 MB, 207 MiB) copied, 2 s, 108 MB/s230686720 bytes (231 MB, 220 MiB) copied, 2 s, 115 MB/s212860928 bytes (213 MB, 203 MiB) copied, 2 s, 106 MB/s328204288 bytes (328 MB, 313 MiB) copied, 3 s, 109 MB/s326107136 bytes (326 MB, 311 MiB) copied, 3 s, 109 MB/s318767104 bytes (319 MB, 304 MiB) copied, 3 s, 106 MB/s342884352 bytes (343 MB, 327 MiB) copied, 3 s, 114 MB/s432013312 bytes (432 MB, 412 MiB) copied, 4 s, 108 MB/s434110464 bytes (434 MB, 414 MiB) copied, 4 s, 108 MB/s426770432 bytes (427 MB, 407 MiB) copied, 4 s, 106 MB/s455081984 bytes (455 MB, 434 MiB) copied, 4 s, 113 MB/s526385152 bytes (526 MB, 502 MiB) copied, 5 s, 105 MB/s534773760 bytes (535 MB, 510 MiB) copied, 5 s, 107 MB/s558891008 bytes (559 MB, 533 MiB) copied, 5 s, 112 MB/s520093696 bytes (520 MB, 496 MiB) copied, 5 s, 104 MB/s649068544 bytes (649 MB, 619 MiB) copied, 6 s, 108 MB/s620756992 bytes (621 MB, 592 MiB) copied, 6 s, 103 MB/s661651456 bytes (662 MB, 631 MiB) copied, 6 s, 110 MB/s628097024 bytes (628 MB, 599 MiB) copied, 6 s, 105 MB/s743440384 bytes (743 MB, 709 MiB) copied, 7 s, 106 MB/s782237696 bytes (782 MB, 746 MiB) copied, 7 s, 112 MB/s741343232 bytes (741 MB, 707 MiB) copied, 7 s, 106 MB/s775946240 bytes (776 MB, 740 MiB) copied, 7 s, 111 MB/s907018240 bytes (907 MB, 865 MiB) copied, 8 s, 113 MB/s843055104 bytes (843 MB, 804 MiB) copied, 8 s, 105 MB/s874512384 bytes (875 MB, 834 MiB) copied, 8 s, 109 MB/s864026624 bytes (864 MB, 824 MiB) copied, 8 s, 108 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 28287/85762 hits, 3566 MiB read, 1.007 read amp, 85762 total
[0m1023410176 bytes (1.0 GB, 976 MiB) copied, 9 s, 114 MB/s980418560 bytes (980 MB, 935 MiB) copied, 9 s, 109 MB/s946864128 bytes (947 MB, 903 MiB) copied, 9 s, 105 MB/s963641344 bytes (964 MB, 919 MiB) copied, 9 s, 107 MB/s1092616192 bytes (1.1 GB, 1.0 GiB) copied, 10 s, 109 MB/s1063256064 bytes (1.1 GB, 1014 MiB) copied, 10 s, 106 MB/s1073741824 bytes (1.1 GB, 1.0 GiB) copied, 10 s, 107 MB/s1137704960 bytes (1.1 GB, 1.1 GiB) copied, 10 s, 114 MB/s1171259392 bytes (1.2 GB, 1.1 GiB) copied, 11 s, 106 MB/s1154482176 bytes (1.2 GB, 1.1 GiB) copied, 11 s, 105 MB/s 1229979648 bytes (1.2 GB, 1.1 GiB) copied, 11 s, 112 MB/s1178599424 bytes (1.2 GB, 1.1 GiB) copied, 11 s, 107 MB/s1265631232 bytes (1.3 GB, 1.2 GiB) copied, 12 s, 105 MB/s1284505600 bytes (1.3 GB, 1.2 GiB) copied, 12 s, 107 MB/s1343225856 bytes (1.3 GB, 1.3 GiB) copied, 12 s, 112 MB/s1286602752 bytes (1.3 GB, 1.2 GiB) copied, 12 s, 107 MB/s1396703232 bytes (1.4 GB, 1.3 GiB) copied, 13 s, 107 MB/s1399848960 bytes (1.4 GB, 1.3 GiB) copied, 13 s, 108 MB/s1375731712 bytes (1.4 GB, 1.3 GiB) copied, 13 s, 106 MB/s1451229184 bytes (1.5 GB, 1.4 GiB) copied, 13 s, 112 MB/s1490026496 bytes (1.5 GB, 1.4 GiB) copied, 14 s, 106 MB/s1503657984 bytes (1.5 GB, 1.4 GiB) copied, 14 s, 107 MB/s1547698176 bytes (1.5 GB, 1.4 GiB) copied, 14 s, 110 MB/s1486880768 bytes (1.5 GB, 1.4 GiB) copied, 14 s, 106 MB/s1653604352 bytes (1.7 GB, 1.5 GiB) copied, 15 s, 110 MB/s1605369856 bytes (1.6 GB, 1.5 GiB) copied, 15 s, 107 MB/s1615855616 bytes (1.6 GB, 1.5 GiB) copied, 15 s, 108 MB/s1594884096 bytes (1.6 GB, 1.5 GiB) copied, 15 s, 106 MB/s1749024768 bytes (1.7 GB, 1.6 GiB) copied, 16 s, 109 MB/s1684013056 bytes (1.7 GB, 1.6 GiB) copied, 16 s, 105 MB/s1715470336 bytes (1.7 GB, 1.6 GiB) copied, 16 s, 107 MB/s1704984576 bytes (1.7 GB, 1.6 GiB) copied, 16 s, 106 MB/s1850736640 bytes (1.9 GB, 1.7 GiB) copied, 17 s, 109 MB/s1810890752 bytes (1.8 GB, 1.7 GiB) copied, 17 s, 107 MB/s1802502144 bytes (1.8 GB, 1.7 GiB) copied, 17 s, 106 MB/s1784676352 bytes (1.8 GB, 1.7 GiB) copied, 17 s, 105 MB/s1920991232 bytes (1.9 GB, 1.8 GiB) copied, 18 s, 107 MB/s1891631104 bytes (1.9 GB, 1.8 GiB) copied, 18 s, 105 MB/s1960837120 bytes (2.0 GB, 1.8 GiB) copied, 18 s, 109 MB/s1906311168 bytes (1.9 GB, 1.8 GiB) copied, 18 s, 106 MB/s2017460224 bytes (2.0 GB, 1.9 GiB) copied, 19 s, 106 MB/s2010120192 bytes (2.0 GB, 1.9 GiB) copied, 19 s, 106 MB/s2053111808 bytes (2.1 GB, 1.9 GiB) copied, 19 s, 108 MB/s1993342976 bytes (2.0 GB, 1.9 GiB) copied, 19 s, 105 MB/s2170552320 bytes (2.2 GB, 2.0 GiB) copied, 20 s, 109 MB/s2101346304 bytes (2.1 GB, 2.0 GiB) copied, 20 s, 105 MB/s2121269248 bytes (2.1 GB, 2.0 GiB) copied, 20 s, 106 MB/s2126512128 bytes (2.1 GB, 2.0 GiB) copied, 20 s, 106 MB/s2227175424 bytes (2.2 GB, 2.1 GiB) copied, 21 s, 106 MB/s2207252480 bytes (2.2 GB, 2.1 GiB) copied, 21 s, 105 MB/s2237661184 bytes (2.2 GB, 2.1 GiB) copied, 21 s, 107 MB/s2279604224 bytes (2.3 GB, 2.1 GiB) copied, 21 s, 109 MB/s2384461824 bytes (2.4 GB, 2.2 GiB) copied, 22 s, 108 MB/s2302672896 bytes (2.3 GB, 2.1 GiB) copied, 22 s, 105 MB/s2323644416 bytes (2.3 GB, 2.2 GiB) copied, 22 s, 106 MB/s2339373056 bytes (2.3 GB, 2.2 GiB) copied, 22 s, 106 MB/s2403336192 bytes (2.4 GB, 2.2 GiB) copied, 23 s, 104 MB/s2446327808 bytes (2.4 GB, 2.3 GiB) copied, 23 s, 106 MB/s2425356288 bytes (2.4 GB, 2.3 GiB) copied, 23 s, 105 MB/s2486173696 bytes (2.5 GB, 2.3 GiB) copied, 23 s, 108 MB/s2544893952 bytes (2.5 GB, 2.4 GiB) copied, 24 s, 106 MB/s2583691264 bytes (2.6 GB, 2.4 GiB) copied, 24 s, 108 MB/s2512388096 bytes (2.5 GB, 2.3 GiB) copied, 24 s, 105 MB/s2527068160 bytes (2.5 GB, 2.4 GiB) copied, 24 s, 105 MB/s2617245696 bytes (2.6 GB, 2.4 GiB) copied, 25 s, 105 MB/s2679111680 bytes (2.7 GB, 2.5 GiB) copied, 25 s, 107 MB/s2615148544 bytes (2.6 GB, 2.4 GiB) copied, 25 s, 105 MB/s2651848704 bytes (2.7 GB, 2.5 GiB) copied, 25 s, 106 MB/s2727346176 bytes (2.7 GB, 2.5 GiB) copied, 26 s, 105 MB/s2727346176 bytes (2.7 GB, 2.5 GiB) copied, 26 s, 105 MB/s2764046336 bytes (2.8 GB, 2.6 GiB) copied, 26 s, 106 MB/s2787115008 bytes (2.8 GB, 2.6 GiB) copied, 26 s, 107 MB/s2838495232 bytes (2.8 GB, 2.6 GiB) copied, 27 s, 105 MB/s2831155200 bytes (2.8 GB, 2.6 GiB) copied, 27 s, 105 MB/s2898264064 bytes (2.9 GB, 2.7 GiB) copied, 27 s, 107 MB/s2875195392 bytes (2.9 GB, 2.7 GiB) copied, 27 s, 106 MB/s2984247296 bytes (3.0 GB, 2.8 GiB) copied, 28 s, 107 MB/s2936012800 bytes (2.9 GB, 2.7 GiB) copied, 28 s, 105 MB/s2946498560 bytes (2.9 GB, 2.7 GiB) copied, 28 s, 105 MB/s3002073088 bytes (3.0 GB, 2.8 GiB) copied, 28 s, 107 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52511/160000 hits, 6666 MiB read, 1.008 read amp, 276922 total
[0m3069181952 bytes (3.1 GB, 2.9 GiB) copied, 29 s, 106 MB/s3044016128 bytes (3.0 GB, 2.8 GiB) copied, 29 s, 105 MB/s3046113280 bytes (3.0 GB, 2.8 GiB) copied, 29 s, 105 MB/s3091202048 bytes (3.1 GB, 2.9 GiB) copied, 29 s, 107 MB/s3180331008 bytes (3.2 GB, 3.0 GiB) copied, 30 s, 106 MB/s3154116608 bytes (3.2 GB, 2.9 GiB) copied, 30 s, 105 MB/s3154116608 bytes (3.2 GB, 2.9 GiB) copied, 30 s, 105 MB/s3203399680 bytes (3.2 GB, 3.0 GiB) copied, 30 s, 107 MB/s3261071360 bytes (3.3 GB, 3.0 GiB) copied, 31 s, 105 MB/s3313500160 bytes (3.3 GB, 3.1 GiB) copied, 31 s, 107 MB/s3282042880 bytes (3.3 GB, 3.1 GiB) copied, 31 s, 106 MB/s3255828480 bytes (3.3 GB, 3.0 GiB) copied, 31 s, 105 MB/s3418357760 bytes (3.4 GB, 3.2 GiB) copied, 32 s, 107 MB/s3390046208 bytes (3.4 GB, 3.2 GiB) copied, 32 s, 106 MB/s3372220416 bytes (3.4 GB, 3.1 GiB) copied, 32 s, 105 MB/s3362783232 bytes (3.4 GB, 3.1 GiB) copied, 32 s, 105 MB/s3480223744 bytes (3.5 GB, 3.2 GiB) copied, 33 s, 105 MB/s3497000960 bytes (3.5 GB, 3.3 GiB) copied, 33 s, 106 MB/s3535798272 bytes (3.5 GB, 3.3 GiB) copied, 33 s, 107 MB/s3483369472 bytes (3.5 GB, 3.2 GiB) copied, 33 s, 106 MB/s3596615680 bytes (3.6 GB, 3.3 GiB) copied, 34 s, 106 MB/s3591372800 bytes (3.6 GB, 3.3 GiB) copied, 34 s, 106 MB/s3633315840 bytes (3.6 GB, 3.4 GiB) copied, 34 s, 107 MB/s3572498432 bytes (3.6 GB, 3.3 GiB) copied, 34 s, 105 MB/s3698327552 bytes (3.7 GB, 3.4 GiB) copied, 35 s, 106 MB/s3695181824 bytes (3.7 GB, 3.4 GiB) copied, 35 s, 106 MB/s3744464896 bytes (3.7 GB, 3.5 GiB) copied, 35 s, 107 MB/s3680501760 bytes (3.7 GB, 3.4 GiB) copied, 35 s, 105 MB/s3797942272 bytes (3.8 GB, 3.5 GiB) copied, 36 s, 105 MB/s3809476608 bytes (3.8 GB, 3.5 GiB) copied, 36 s, 106 MB/s3847225344 bytes (3.8 GB, 3.6 GiB) copied, 36 s, 107 MB/s3771727872 bytes (3.8 GB, 3.5 GiB) copied, 36 s, 105 MB/s3957325824 bytes (4.0 GB, 3.7 GiB) copied, 37 s, 107 MB/s3869245440 bytes (3.9 GB, 3.6 GiB) copied, 37 s, 105 MB/s3897556992 bytes (3.9 GB, 3.6 GiB) copied, 37 s, 105 MB/s3914334208 bytes (3.9 GB, 3.6 GiB) copied, 37 s, 106 MB/s3977248768 bytes (4.0 GB, 3.7 GiB) copied, 38 s, 105 MB/s4019191808 bytes (4.0 GB, 3.7 GiB) copied, 38 s, 106 MB/s4056940544 bytes (4.1 GB, 3.8 GiB) copied, 38 s, 107 MB/s4000317440 bytes (4.0 GB, 3.7 GiB) copied, 38 s, 105 MB/s4160749568 bytes (4.2 GB, 3.9 GiB) copied, 39 s, 107 MB/s4123000832 bytes (4.1 GB, 3.8 GiB) copied, 39 s, 106 MB/s4100980736 bytes (4.1 GB, 3.8 GiB) copied, 39 s, 105 MB/s4078960640 bytes (4.1 GB, 3.8 GiB) copied, 39 s, 105 MB/s4232052736 bytes (4.2 GB, 3.9 GiB) copied, 40 s, 106 MB/s4204789760 bytes (4.2 GB, 3.9 GiB) copied, 40 s, 105 MB/s4182769664 bytes (4.2 GB, 3.9 GiB) copied, 40 s, 105 MB/s4269801472 bytes (4.3 GB, 4.0 GiB) copied, 40 s, 107 MB/s4304404480 bytes (4.3 GB, 4.0 GiB) copied, 41 s, 105 MB/s4282384384 bytes (4.3 GB, 4.0 GiB) copied, 41 s, 104 MB/s4337958912 bytes (4.3 GB, 4.0 GiB) copied, 41 s, 106 MB/s4362076160 bytes (4.4 GB, 4.1 GiB) copied, 41 s, 106 MB/s4384096256 bytes (4.4 GB, 4.1 GiB) copied, 42 s, 104 MB/s4415553536 bytes (4.4 GB, 4.1 GiB) copied, 42 s, 105 MB/s4471128064 bytes (4.5 GB, 4.2 GiB) copied, 42 s, 106 MB/s4444913664 bytes (4.4 GB, 4.1 GiB) copied, 42 s, 106 MB/s4483710976 bytes (4.5 GB, 4.2 GiB) copied, 43 s, 104 MB/s4556062720 bytes (4.6 GB, 4.2 GiB) copied, 43 s, 106 MB/s4514119680 bytes (4.5 GB, 4.2 GiB) copied, 43 s, 105 MB/s4531945472 bytes (4.5 GB, 4.2 GiB) copied, 43 s, 105 MB/s4667211776 bytes (4.7 GB, 4.3 GiB) copied, 44 s, 106 MB/s4592762880 bytes (4.6 GB, 4.3 GiB) copied, 44 s, 104 MB/s4638900224 bytes (4.6 GB, 4.3 GiB) copied, 44 s, 105 MB/s4623171584 bytes (4.6 GB, 4.3 GiB) copied, 44 s, 105 MB/s4778360832 bytes (4.8 GB, 4.5 GiB) copied, 45 s, 106 MB/s4709154816 bytes (4.7 GB, 4.4 GiB) copied, 45 s, 105 MB/s4739563520 bytes (4.7 GB, 4.4 GiB) copied, 45 s, 105 MB/s4754243584 bytes (4.8 GB, 4.4 GiB) copied, 45 s, 106 MB/s4885315584 bytes (4.9 GB, 4.5 GiB) copied, 46 s, 106 MB/s4848615424 bytes (4.8 GB, 4.5 GiB) copied, 46 s, 105 MB/s4810866688 bytes (4.8 GB, 4.5 GiB) copied, 46 s, 105 MB/s4850712576 bytes (4.9 GB, 4.5 GiB) copied, 46 s, 105 MB/s4991221760 bytes (5.0 GB, 4.6 GiB) copied, 47 s, 106 MB/s4914675712 bytes (4.9 GB, 4.6 GiB) copied, 47 s, 105 MB/s4937744384 bytes (4.9 GB, 4.6 GiB) copied, 47 s, 105 MB/s4947181568 bytes (4.9 GB, 4.6 GiB) copied, 47 s, 105 MB/s5033164800 bytes (5.0 GB, 4.7 GiB) copied, 48 s, 105 MB/s5101322240 bytes (5.1 GB, 4.8 GiB) copied, 48 s, 106 MB/s5057282048 bytes (5.1 GB, 4.7 GiB) copied, 48 s, 105 MB/s5014290432 bytes (5.0 GB, 4.7 GiB) copied, 48 s, 104 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52504/160000 hits, 6666 MiB read, 1.008 read amp, 468133 total
[0m5196742656 bytes (5.2 GB, 4.8 GiB) copied, 49 s, 106 MB/s5108662272 bytes (5.1 GB, 4.8 GiB) copied, 49 s, 104 MB/s5136973824 bytes (5.1 GB, 4.8 GiB) copied, 49 s, 105 MB/s5155848192 bytes (5.2 GB, 4.8 GiB) copied, 49 s, 105 MB/s5257560064 bytes (5.3 GB, 4.9 GiB) copied, 50 s, 105 MB/s5236588544 bytes (5.2 GB, 4.9 GiB) copied, 50 s, 105 MB/s5220859904 bytes (5.2 GB, 4.9 GiB) copied, 50 s, 104 MB/s5311037440 bytes (5.3 GB, 4.9 GiB) copied, 50 s, 106 MB/s5352980480 bytes (5.4 GB, 5.0 GiB) copied, 51 s, 105 MB/s5328863232 bytes (5.3 GB, 5.0 GiB) copied, 51 s, 104 MB/s5417992192 bytes (5.4 GB, 5.0 GiB) copied, 51 s, 106 MB/s5372903424 bytes (5.4 GB, 5.0 GiB) copied, 51 s, 105 MB/s5517606912 bytes (5.5 GB, 5.1 GiB) copied, 52 s, 106 MB/s5430575104 bytes (5.4 GB, 5.1 GiB) copied, 52 s, 104 MB/s5476712448 bytes (5.5 GB, 5.1 GiB) copied, 52 s, 105 MB/s5455740928 bytes (5.5 GB, 5.1 GiB) copied, 52 s, 105 MB/s5618270208 bytes (5.6 GB, 5.2 GiB) copied, 53 s, 106 MB/s5578424320 bytes (5.6 GB, 5.2 GiB) copied, 53 s, 105 MB/s5530189824 bytes (5.5 GB, 5.2 GiB) copied, 53 s, 104 MB/s5564792832 bytes (5.6 GB, 5.2 GiB) copied, 53 s, 105 MB/s5659164672 bytes (5.7 GB, 5.3 GiB) copied, 54 s, 105 MB/s5683281920 bytes (5.7 GB, 5.3 GiB) copied, 54 s, 105 MB/s5635047424 bytes (5.6 GB, 5.2 GiB) copied, 54 s, 104 MB/s5724176384 bytes (5.7 GB, 5.3 GiB) copied, 54 s, 106 MB/s5827985408 bytes (5.8 GB, 5.4 GiB) copied, 55 s, 106 MB/s5755633664 bytes (5.8 GB, 5.4 GiB) copied, 55 s, 105 MB/s5742002176 bytes (5.7 GB, 5.3 GiB) copied, 55 s, 104 MB/s5786042368 bytes (5.8 GB, 5.4 GiB) copied, 55 s, 105 MB/s5843714048 bytes (5.8 GB, 5.4 GiB) copied, 56 s, 104 MB/s5938085888 bytes (5.9 GB, 5.5 GiB) copied, 56 s, 106 MB/s5845811200 bytes (5.8 GB, 5.4 GiB) copied, 56 s, 104 MB/s5877268480 bytes (5.9 GB, 5.5 GiB) copied, 56 s, 105 MB/s6050283520 bytes (6.1 GB, 5.6 GiB) copied, 57 s, 106 MB/s5965348864 bytes (6.0 GB, 5.6 GiB) copied, 57 s, 105 MB/s5956960256 bytes (6.0 GB, 5.5 GiB) copied, 57 s, 104 MB/s5986320384 bytes (6.0 GB, 5.6 GiB) copied, 57 s, 105 MB/s6158286848 bytes (6.2 GB, 5.7 GiB) copied, 58 s, 106 MB/s6053429248 bytes (6.1 GB, 5.6 GiB) copied, 58 s, 104 MB/s6066012160 bytes (6.1 GB, 5.6 GiB) copied, 58 s, 105 MB/s6088032256 bytes (6.1 GB, 5.7 GiB) copied, 58 s, 105 MB/s6158286848 bytes (6.2 GB, 5.7 GiB) copied, 59 s, 104 MB/s6201278464 bytes (6.2 GB, 5.8 GiB) copied, 59 s, 105 MB/s6170869760 bytes (6.2 GB, 5.7 GiB) copied, 59 s, 105 MB/s6269435904 bytes (6.3 GB, 5.8 GiB) copied, 59 s, 106 MB/s6311378944 bytes (6.3 GB, 5.9 GiB) copied, 60 s, 105 MB/s6264193024 bytes (6.3 GB, 5.8 GiB) copied, 60 s, 104 MB/s6371147776 bytes (6.4 GB, 5.9 GiB) copied, 60 s, 106 MB/s6276775936 bytes (6.3 GB, 5.8 GiB) copied, 60 s, 105 MB/s6471811072 bytes (6.5 GB, 6.0 GiB) copied, 61 s, 106 MB/s6413090816 bytes (6.4 GB, 6.0 GiB) copied, 61 s, 105 MB/s6388973568 bytes (6.4 GB, 6.0 GiB) copied, 61 s, 105 MB/s6377439232 bytes (6.4 GB, 5.9 GiB) copied, 61 s, 105 MB/s6585057280 bytes (6.6 GB, 6.1 GiB) copied, 62 s, 106 MB/s6524239872 bytes (6.5 GB, 6.1 GiB) copied, 62 s, 105 MB/s6496976896 bytes (6.5 GB, 6.1 GiB) copied, 62 s, 105 MB/s6485442560 bytes (6.5 GB, 6.0 GiB) copied, 62 s, 105 MB/s6590300160 bytes (6.6 GB, 6.1 GiB) copied, 63 s, 105 MB/s6591348736 bytes (6.6 GB, 6.1 GiB) copied, 63 s, 105 MB/s6633291776 bytes (6.6 GB, 6.2 GiB) copied, 63 s, 105 MB/s6683623424 bytes (6.7 GB, 6.2 GiB) copied, 63 s, 106 MB/s6702497792 bytes (6.7 GB, 6.2 GiB) copied, 64 s, 105 MB/s6697254912 bytes (6.7 GB, 6.2 GiB) copied, 64 s, 105 MB/s6782189568 bytes (6.8 GB, 6.3 GiB) copied, 64 s, 106 MB/s6740246528 bytes (6.7 GB, 6.3 GiB) copied, 64 s, 105 MB/s6894387200 bytes (6.9 GB, 6.4 GiB) copied, 65 s, 106 MB/s6805258240 bytes (6.8 GB, 6.3 GiB) copied, 65 s, 105 MB/s6805258240 bytes (6.8 GB, 6.3 GiB) copied, 65 s, 105 MB/s6838812672 bytes (6.8 GB, 6.4 GiB) copied, 65 s, 105 MB/s7006584832 bytes (7.0 GB, 6.5 GiB) copied, 66 s, 106 MB/s6914310144 bytes (6.9 GB, 6.4 GiB) copied, 66 s, 105 MB/s6953107456 bytes (7.0 GB, 6.5 GiB) copied, 66 s, 105 MB/s6915358720 bytes (6.9 GB, 6.4 GiB) copied, 66 s, 105 MB/s7067402240 bytes (7.1 GB, 6.6 GiB) copied, 67 s, 105 MB/s7024410624 bytes (7.0 GB, 6.5 GiB) copied, 67 s, 105 MB/s7120879616 bytes (7.1 GB, 6.6 GiB) copied, 67 s, 106 MB/s7025459200 bytes (7.0 GB, 6.5 GiB) copied, 67 s, 105 MB/s7135559680 bytes (7.1 GB, 6.6 GiB) copied, 68 s, 105 MB/s7232028672 bytes (7.2 GB, 6.7 GiB) copied, 68 s, 106 MB/s7182745600 bytes (7.2 GB, 6.7 GiB) copied, 68 s, 106 MB/s7139753984 bytes (7.1 GB, 6.6 GiB) copied, 68 s, 105 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52499/160000 hits, 6667 MiB read, 1.008 read amp, 662878 total
[0m7292846080 bytes (7.3 GB, 6.8 GiB) copied, 69 s, 106 MB/s7342129152 bytes (7.3 GB, 6.8 GiB) copied, 69 s, 106 MB/s7242514432 bytes (7.2 GB, 6.7 GiB) copied, 69 s, 105 MB/s7242514432 bytes (7.2 GB, 6.7 GiB) copied, 69 s, 105 MB/s7352614912 bytes (7.4 GB, 6.8 GiB) copied, 70 s, 105 MB/s7354712064 bytes (7.4 GB, 6.8 GiB) copied, 70 s, 105 MB/s7456423936 bytes (7.5 GB, 6.9 GiB) copied, 70 s, 107 MB/s7401897984 bytes (7.4 GB, 6.9 GiB) copied, 70 s, 106 MB/s7459569664 bytes (7.5 GB, 6.9 GiB) copied, 71 s, 105 MB/s7499415552 bytes (7.5 GB, 7.0 GiB) copied, 71 s, 106 MB/s7455375360 bytes (7.5 GB, 6.9 GiB) copied, 71 s, 105 MB/s7557087232 bytes (7.6 GB, 7.0 GiB) copied, 71 s, 106 MB/s7541358592 bytes (7.5 GB, 7.0 GiB) copied, 72 s, 105 MB/s7600078848 bytes (7.6 GB, 7.1 GiB) copied, 72 s, 106 MB/s7572815872 bytes (7.6 GB, 7.1 GiB) copied, 72 s, 105 MB/s7654604800 bytes (7.7 GB, 7.1 GiB) copied, 72 s, 106 MB/s7645167616 bytes (7.6 GB, 7.1 GiB) copied, 73 s, 105 MB/s7701790720 bytes (7.7 GB, 7.2 GiB) copied, 73 s, 106 MB/s7667187712 bytes (7.7 GB, 7.1 GiB) copied, 73 s, 105 MB/s7755268096 bytes (7.8 GB, 7.2 GiB) copied, 73 s, 106 MB/s7810842624 bytes (7.8 GB, 7.3 GiB) copied, 74 s, 106 MB/s7770996736 bytes (7.8 GB, 7.2 GiB) copied, 74 s, 105 MB/s7860125696 bytes (7.9 GB, 7.3 GiB) copied, 74 s, 106 MB/s7747928064 bytes (7.7 GB, 7.2 GiB) copied, 74 s, 105 MB/s7879000064 bytes (7.9 GB, 7.3 GiB) copied, 75 s, 105 MB/s7972323328 bytes (8.0 GB, 7.4 GiB) copied, 75 s, 106 MB/s7924088832 bytes (7.9 GB, 7.4 GiB) copied, 75 s, 106 MB/s7855931392 bytes (7.9 GB, 7.3 GiB) copied, 75 s, 105 MB/s7954497536 bytes (8.0 GB, 7.4 GiB) copied, 76 s, 105 MB/s8022654976 bytes (8.0 GB, 7.5 GiB) copied, 76 s, 106 MB/s7984906240 bytes (8.0 GB, 7.4 GiB) copied, 76 s, 105 MB/s8078229504 bytes (8.1 GB, 7.5 GiB) copied, 76 s, 106 MB/s8180989952 bytes (8.2 GB, 7.6 GiB) copied, 77 s, 106 MB/s8075083776 bytes (8.1 GB, 7.5 GiB) copied, 77 s, 105 MB/s8124366848 bytes (8.1 GB, 7.6 GiB) copied, 77 s, 106 MB/s8050966528 bytes (8.1 GB, 7.5 GiB) copied, 77 s, 105 MB/s8278507520 bytes (8.3 GB, 7.7 GiB) copied, 78 s, 106 MB/s8157921280 bytes (8.2 GB, 7.6 GiB) copied, 78 s, 105 MB/s8225030144 bytes (8.2 GB, 7.7 GiB) copied, 78 s, 105 MB/s8185184256 bytes (8.2 GB, 7.6 GiB) copied, 78 s, 105 MB/s8263827456 bytes (8.3 GB, 7.7 GiB) copied, 79 s, 105 MB/s8333033472 bytes (8.3 GB, 7.8 GiB) copied, 79 s, 105 MB/s8385462272 bytes (8.4 GB, 7.8 GiB) copied, 79 s, 106 MB/s8288993280 bytes (8.3 GB, 7.7 GiB) copied, 79 s, 105 MB/s8436842496 bytes (8.4 GB, 7.9 GiB) copied, 80 s, 105 MB/s8364490752 bytes (8.4 GB, 7.8 GiB) copied, 80 s, 105 MB/s8492417024 bytes (8.5 GB, 7.9 GiB) copied, 80 s, 106 MB/s8388608000 bytes (8.4 GB, 7.8 GiB) copied, 80 s, 105 MB/s8491368448 bytes (8.5 GB, 7.9 GiB) copied, 81 s, 105 MB/s8467251200 bytes (8.5 GB, 7.9 GiB) copied, 81 s, 105 MB/s8589934592 bytes (8.6 GB, 8.0 GiB) copied, 81 s, 106 MB/s8532262912 bytes (8.5 GB, 7.9 GiB) copied, 81 s, 105 MB/s8559525888 bytes (8.6 GB, 8.0 GiB) copied, 82 s, 104 MB/s8695840768 bytes (8.7 GB, 8.1 GiB) copied, 82 s, 106 MB/s8585740288 bytes (8.6 GB, 8.0 GiB) copied, 82 s, 105 MB/s8644460544 bytes (8.6 GB, 8.1 GiB) copied, 82 s, 105 MB/s8650752000 bytes (8.7 GB, 8.1 GiB) copied, 83 s, 104 MB/s8736735232 bytes (8.7 GB, 8.1 GiB) copied, 83 s, 105 MB/s8678014976 bytes (8.7 GB, 8.1 GiB) copied, 83 s, 105 MB/s8793358336 bytes (8.8 GB, 8.2 GiB) copied, 83 s, 106 MB/s8835301376 bytes (8.8 GB, 8.2 GiB) copied, 84 s, 105 MB/s8751415296 bytes (8.8 GB, 8.2 GiB) copied, 84 s, 104 MB/s8787066880 bytes (8.8 GB, 8.2 GiB) copied, 84 s, 105 MB/s8889827328 bytes (8.9 GB, 8.3 GiB) copied, 84 s, 106 MB/s8992587776 bytes (9.0 GB, 8.4 GiB) copied, 85 s, 106 MB/s8868855808 bytes (8.9 GB, 8.3 GiB) copied, 85 s, 104 MB/s8883535872 bytes (8.9 GB, 8.3 GiB) copied, 85 s, 105 MB/s8941207552 bytes (8.9 GB, 8.3 GiB) copied, 85 s, 105 MB/s8974761984 bytes (9.0 GB, 8.4 GiB) copied, 86 s, 104 MB/s9089056768 bytes (9.1 GB, 8.5 GiB) copied, 86 s, 106 MB/s9056550912 bytes (9.1 GB, 8.4 GiB) copied, 86 s, 105 MB/s8981053440 bytes (9.0 GB, 8.4 GiB) copied, 86 s, 104 MB/s9166651392 bytes (9.2 GB, 8.5 GiB) copied, 87 s, 105 MB/s9085911040 bytes (9.1 GB, 8.5 GiB) copied, 87 s, 104 MB/s9083813888 bytes (9.1 GB, 8.5 GiB) copied, 87 s, 104 MB/s9189720064 bytes (9.2 GB, 8.6 GiB) copied, 87 s, 106 MB/s9275703296 bytes (9.3 GB, 8.6 GiB) copied, 88 s, 105 MB/s9200205824 bytes (9.2 GB, 8.6 GiB) copied, 88 s, 105 MB/s9296674816 bytes (9.3 GB, 8.7 GiB) copied, 88 s, 106 MB/s9190768640 bytes (9.2 GB, 8.6 GiB) copied, 88 s, 104 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52504/160000 hits, 6666 MiB read, 1.008 read amp, 852154 total
[0m9296674816 bytes (9.3 GB, 8.7 GiB) copied, 89 s, 104 MB/s9404678144 bytes (9.4 GB, 8.8 GiB) copied, 89 s, 106 MB/s9296674816 bytes (9.3 GB, 8.7 GiB) copied, 89 s, 104 MB/s9384755200 bytes (9.4 GB, 8.7 GiB) copied, 89 s, 105 MB/s9491709952 bytes (9.5 GB, 8.8 GiB) copied, 90 s, 105 MB/s9401532416 bytes (9.4 GB, 8.8 GiB) copied, 90 s, 104 MB/s9504292864 bytes (9.5 GB, 8.9 GiB) copied, 90 s, 106 MB/s9402580992 bytes (9.4 GB, 8.8 GiB) copied, 90 s, 104 MB/s9500098560 bytes (9.5 GB, 8.8 GiB) copied, 91 s, 104 MB/s9606004736 bytes (9.6 GB, 8.9 GiB) copied, 91 s, 106 MB/s9509535744 bytes (9.5 GB, 8.9 GiB) copied, 91 s, 104 MB/s9600761856 bytes (9.6 GB, 8.9 GiB) copied, 91 s, 105 MB/s9618587648 bytes (9.6 GB, 9.0 GiB) copied, 92 s, 105 MB/s9715056640 bytes (9.7 GB, 9.0 GiB) copied, 92 s, 106 MB/s9707716608 bytes (9.7 GB, 9.0 GiB) copied, 92 s, 106 MB/s9609150464 bytes (9.6 GB, 8.9 GiB) copied, 92 s, 104 MB/s9815719936 bytes (9.8 GB, 9.1 GiB) copied, 93 s, 106 MB/s9829351424 bytes (9.8 GB, 9.2 GiB) copied, 93 s, 106 MB/s9725542400 bytes (9.7 GB, 9.1 GiB) copied, 93 s, 105 MB/s9722396672 bytes (9.7 GB, 9.1 GiB) copied, 93 s, 105 MB/s9831448576 bytes (9.8 GB, 9.2 GiB) copied, 94 s, 105 MB/s9927917568 bytes (9.9 GB, 9.2 GiB) copied, 94 s, 106 MB/s9829351424 bytes (9.8 GB, 9.2 GiB) copied, 94 s, 105 MB/s9919528960 bytes (9.9 GB, 9.2 GiB) copied, 94 s, 106 MB/s9927917568 bytes (9.9 GB, 9.2 GiB) copied, 95 s, 105 MB/s10019143680 bytes (10 GB, 9.3 GiB) copied, 95 s, 105 MB/s10034872320 bytes (10 GB, 9.3 GiB) copied, 95 s, 106 MB/s9934209024 bytes (9.9 GB, 9.3 GiB) copied, 95 s, 105 MB/s10036969472 bytes (10 GB, 9.3 GiB) copied, 96 s, 105 MB/s10109321216 bytes (10 GB, 9.4 GiB) copied, 96 s, 105 MB/s10141827072 bytes (10 GB, 9.4 GiB) copied, 96 s, 106 MB/s10024386560 bytes (10 GB, 9.3 GiB) copied, 96 s, 104 MB/s10132389888 bytes (10 GB, 9.4 GiB) copied, 97 s, 104 MB/s10250878976 bytes (10 GB, 9.5 GiB) copied, 97 s, 106 MB/s10221518848 bytes (10 GB, 9.5 GiB) copied, 97 s, 105 MB/s10140778496 bytes (10 GB, 9.4 GiB) copied, 97 s, 105 MB/s10360979456 bytes (10 GB, 9.6 GiB) copied, 98 s, 106 MB/s10237247488 bytes (10 GB, 9.5 GiB) copied, 98 s, 104 MB/s10251927552 bytes (10 GB, 9.5 GiB) copied, 98 s, 105 MB/s10324279296 bytes (10 GB, 9.6 GiB) copied, 98 s, 105 MB/s10432282624 bytes (10 GB, 9.7 GiB) copied, 99 s, 105 MB/s10354688000 bytes (10 GB, 9.6 GiB) copied, 99 s, 105 MB/s10467934208 bytes (10 GB, 9.7 GiB) copied, 99 s, 106 MB/s10333716480 bytes (10 GB, 9.6 GiB) copied, 99 s, 104 MB/s10568597504 bytes (11 GB, 9.8 GiB) copied, 100 s, 106 MB/s10434379776 bytes (10 GB, 9.7 GiB) copied, 100 s, 104 MB/s10535043072 bytes (11 GB, 9.8 GiB) copied, 100 s, 105 MB/s10453254144 bytes (10 GB, 9.7 GiB) copied, 100 s, 105 MB/s10551820288 bytes (11 GB, 9.8 GiB) copied, 101 s, 104 MB/s10644094976 bytes (11 GB, 9.9 GiB) copied, 101 s, 105 MB/s10544480256 bytes (11 GB, 9.8 GiB) copied, 101 s, 104 MB/s10668212224 bytes (11 GB, 9.9 GiB) copied, 101 s, 106 MB/s10662969344 bytes (11 GB, 9.9 GiB) copied, 102 s, 105 MB/s10646192128 bytes (11 GB, 9.9 GiB) copied, 102 s, 104 MB/s
10240+0 records in
10240+0 records out
10737418240 bytes (11 GB, 10 GiB) copied, 102.937 s, 104 MB/s

10240+0 records in
10240+0 records out
10737418240 bytes (11 GB, 10 GiB) copied, 103.155 s, 104 MB/s

10240+0 records in
10240+0 records out
10737418240 bytes (11 GB, 10 GiB) copied, 103.95 s, 103 MB/s

10240+0 records in
10240+0 records out
10737418240 bytes (11 GB, 10 GiB) copied, 104.056 s, 103 MB/s


===Fio: workload=randread, time=180, iodepth=256, bs=4ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 1746898 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 5334931 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 589 MiB read, 0.000 read amp, 8777131 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 12437393 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 16325891 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 589 MiB read, 0.000 read amp, 20242883 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 24065629 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 27573669 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 31245103 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6074: Fri Jan 12 17:06:07 2024
  read: IOPS=173k, BW=674MiB/s (707MB/s)(118GiB/180001msec)
    slat (usec): min=3, max=8623, avg=21.01, stdev=56.43
    clat (usec): min=220, max=24385, avg=5910.73, stdev=2289.24
     lat (usec): min=313, max=24396, avg=5932.01, stdev=2297.87
    clat percentiles (usec):
     |  1.00th=[ 3687],  5.00th=[ 3851], 10.00th=[ 3949], 20.00th=[ 4146],
     | 30.00th=[ 4293], 40.00th=[ 4490], 50.00th=[ 4686], 60.00th=[ 5014],
     | 70.00th=[ 7570], 80.00th=[ 8225], 90.00th=[ 8979], 95.00th=[ 9765],
     | 99.00th=[13042], 99.50th=[13566], 99.90th=[15270], 99.95th=[16909],
     | 99.99th=[17957]
   bw (  KiB/s): min=300576, max=1066984, per=100.00%, avg=690739.42, stdev=48056.12, samples=1436
   iops        : min=75144, max=266746, avg=172684.69, stdev=12014.03, samples=1436
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=12.11%, 10=83.63%, 20=4.26%, 50=0.01%
  cpu          : usr=11.45%, sys=32.90%, ctx=3520011, majf=0, minf=2664
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=31063140,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=674MiB/s (707MB/s), 674MiB/s-674MiB/s (707MB/s-707MB/s), io=118GiB (127GB), run=180001-180001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4ki) randread:  read: IOPS=173k, BW=674MiB/s (707MB/s)(118GiB/180001msec)


===Fio: workload=randread, time=60, iodepth=128, bs=4ki, disks=1 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 1 process
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 34106630 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 35477971 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 36845303 total
[0m
j1: (groupid=0, jobs=1): err= 0: pid=6133: Fri Jan 12 17:07:10 2024
  read: IOPS=64.4k, BW=252MiB/s (264MB/s)(14.7GiB/60001msec)
    slat (usec): min=3, max=2512, avg=13.26, stdev=29.56
    clat (usec): min=215, max=5601, avg=1972.17, stdev=198.17
     lat (usec): min=224, max=5606, avg=1985.69, stdev=197.82
    clat percentiles (usec):
     |  1.00th=[ 1336],  5.00th=[ 1647], 10.00th=[ 1762], 20.00th=[ 1860],
     | 30.00th=[ 1909], 40.00th=[ 1942], 50.00th=[ 1975], 60.00th=[ 2008],
     | 70.00th=[ 2040], 80.00th=[ 2089], 90.00th=[ 2180], 95.00th=[ 2278],
     | 99.00th=[ 2507], 99.50th=[ 2606], 99.90th=[ 2769], 99.95th=[ 2868],
     | 99.99th=[ 3228]
   bw (  KiB/s): min=236168, max=265608, per=100.00%, avg=257820.45, stdev=3718.81, samples=119
   iops        : min=59042, max=66402, avg=64455.08, stdev=929.69, samples=119
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.20%
  lat (msec)   : 2=55.55%, 4=44.25%, 10=0.01%
  cpu          : usr=18.84%, sys=50.05%, ctx=222427, majf=0, minf=137
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=3864402,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=252MiB/s (264MB/s), 252MiB/s-252MiB/s (264MB/s-264MB/s), io=14.7GiB (15.8GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=1, iodepth=128; bs=4ki) randread:  read: IOPS=64.4k, BW=252MiB/s (264MB/s)(14.7GiB/60001msec)
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 38093716 total
[0m

===Fio: workload=randread, time=60, iodepth=128, bs=4ki, disks=2 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 2 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 40747717 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 43464364 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 46191316 total
[0m
j1: (groupid=0, jobs=2): err= 0: pid=6181: Fri Jan 12 17:08:12 2024
  read: IOPS=128k, BW=501MiB/s (525MB/s)(29.3GiB/60001msec)
    slat (usec): min=3, max=7783, avg=13.61, stdev=34.13
    clat (usec): min=168, max=10249, avg=1981.06, stdev=325.39
     lat (usec): min=179, max=10255, avg=1994.91, stdev=326.73
    clat percentiles (usec):
     |  1.00th=[ 1483],  5.00th=[ 1631], 10.00th=[ 1713], 20.00th=[ 1811],
     | 30.00th=[ 1876], 40.00th=[ 1926], 50.00th=[ 1975], 60.00th=[ 2008],
     | 70.00th=[ 2057], 80.00th=[ 2114], 90.00th=[ 2212], 95.00th=[ 2311],
     | 99.00th=[ 2737], 99.50th=[ 3294], 99.90th=[ 6325], 99.95th=[ 6521],
     | 99.99th=[ 6980]
   bw (  KiB/s): min=246208, max=578584, per=100.00%, avg=513325.93, stdev=18530.85, samples=238
   iops        : min=61552, max=144646, avg=128331.47, stdev=4632.71, samples=238
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.05%
  lat (msec)   : 2=57.53%, 4=42.08%, 10=0.33%, 20=0.01%
  cpu          : usr=15.65%, sys=44.92%, ctx=516729, majf=0, minf=281
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=7693913,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=501MiB/s (525MB/s), 501MiB/s-501MiB/s (525MB/s-525MB/s), io=29.3GiB (31.5GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=2, iodepth=128; bs=4ki) randread:  read: IOPS=128k, BW=501MiB/s (525MB/s)(29.3GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=128, bs=4ki, disks=3 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 3 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 49298648 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 52564342 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 55931868 total
[0m
j1: (groupid=0, jobs=3): err= 0: pid=6228: Fri Jan 12 17:09:14 2024
  read: IOPS=161k, BW=628MiB/s (658MB/s)(36.8GiB/60001msec)
    slat (usec): min=3, max=2883, avg=16.57, stdev=41.78
    clat (usec): min=240, max=9077, avg=2370.86, stdev=807.56
     lat (usec): min=294, max=9088, avg=2387.69, stdev=813.29
    clat percentiles (usec):
     |  1.00th=[ 1565],  5.00th=[ 1713], 10.00th=[ 1795], 20.00th=[ 1909],
     | 30.00th=[ 1975], 40.00th=[ 2024], 50.00th=[ 2089], 60.00th=[ 2147],
     | 70.00th=[ 2212], 80.00th=[ 2409], 90.00th=[ 3884], 95.00th=[ 4146],
     | 99.00th=[ 4883], 99.50th=[ 5669], 99.90th=[ 6718], 99.95th=[ 6915],
     | 99.99th=[ 7439]
   bw (  KiB/s): min=290992, max=856682, per=99.95%, avg=642553.81, stdev=49593.44, samples=357
   iops        : min=72748, max=214170, avg=160638.34, stdev=12398.34, samples=357
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=34.71%, 4=57.82%, 10=7.46%
  cpu          : usr=13.86%, sys=38.61%, ctx=881404, majf=0, minf=426
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=9643263,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=628MiB/s (658MB/s), 628MiB/s-628MiB/s (658MB/s-658MB/s), io=36.8GiB (39.5GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=3, iodepth=128; bs=4ki) randread:  read: IOPS=161k, BW=628MiB/s (658MB/s)(36.8GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=128, bs=4ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 59216470 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 62897910 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 66657474 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6278: Fri Jan 12 17:10:17 2024
  read: IOPS=175k, BW=683MiB/s (716MB/s)(40.0GiB/60001msec)
    slat (usec): min=3, max=8423, avg=20.71, stdev=56.64
    clat (usec): min=184, max=16206, avg=2906.71, stdev=1197.75
     lat (usec): min=292, max=16219, avg=2927.68, stdev=1206.63
    clat percentiles (usec):
     |  1.00th=[ 1713],  5.00th=[ 1827], 10.00th=[ 1893], 20.00th=[ 1991],
     | 30.00th=[ 2057], 40.00th=[ 2147], 50.00th=[ 2245], 60.00th=[ 2474],
     | 70.00th=[ 3654], 80.00th=[ 4080], 90.00th=[ 4621], 95.00th=[ 5145],
     | 99.00th=[ 6456], 99.50th=[ 6783], 99.90th=[ 7832], 99.95th=[ 8356],
     | 99.99th=[ 9110]
   bw (  KiB/s): min=326534, max=1077416, per=100.00%, avg=700837.21, stdev=51791.48, samples=476
   iops        : min=81633, max=269354, avg=175209.11, stdev=12947.88, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=22.04%, 4=56.20%, 10=21.75%, 20=0.01%
  cpu          : usr=11.48%, sys=33.59%, ctx=1119018, majf=0, minf=562
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=10487021,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=683MiB/s (716MB/s), 683MiB/s-683MiB/s (716MB/s-716MB/s), io=40.0GiB (43.0GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4ki) randread:  read: IOPS=175k, BW=683MiB/s (716MB/s)(40.0GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4ki, disks=1 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 1 process
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 68633240 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 70328727 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 71914558 total
[0m
j1: (groupid=0, jobs=1): err= 0: pid=6327: Fri Jan 12 17:11:19 2024
  read: IOPS=76.5k, BW=299MiB/s (313MB/s)(17.5GiB/60001msec)
    slat (usec): min=3, max=7375, avg=11.19, stdev=22.39
    clat (usec): min=289, max=9051, avg=1661.42, stdev=206.16
     lat (usec): min=358, max=9058, avg=1672.87, stdev=206.47
    clat percentiles (usec):
     |  1.00th=[ 1045],  5.00th=[ 1336], 10.00th=[ 1418], 20.00th=[ 1516],
     | 30.00th=[ 1565], 40.00th=[ 1631], 50.00th=[ 1680], 60.00th=[ 1729],
     | 70.00th=[ 1778], 80.00th=[ 1811], 90.00th=[ 1860], 95.00th=[ 1942],
     | 99.00th=[ 2180], 99.50th=[ 2278], 99.90th=[ 2507], 99.95th=[ 2573],
     | 99.99th=[ 2802]
   bw (  KiB/s): min=283360, max=344584, per=100.00%, avg=306094.59, stdev=17051.28, samples=119
   iops        : min=70840, max=86146, avg=76523.63, stdev=4262.85, samples=119
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.68%
  lat (msec)   : 2=96.22%, 4=3.10%, 10=0.01%
  cpu          : usr=19.03%, sys=57.69%, ctx=179529, majf=0, minf=141
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=4587232,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=299MiB/s (313MB/s), 299MiB/s-299MiB/s (313MB/s-313MB/s), io=17.5GiB (18.8GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=1, iodepth=128; bs=4ki) read:  read: IOPS=76.5k, BW=299MiB/s (313MB/s)(17.5GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4ki, disks=2 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 2 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 73977508 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 76862102 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 80017138 total
[0m
j1: (groupid=0, jobs=2): err= 0: pid=6374: Fri Jan 12 17:12:22 2024
  read: IOPS=139k, BW=543MiB/s (569MB/s)(31.8GiB/60001msec)
    slat (usec): min=3, max=7990, avg=12.61, stdev=32.07
    clat (usec): min=198, max=9801, avg=1827.35, stdev=550.62
     lat (usec): min=204, max=9824, avg=1840.20, stdev=554.40
    clat percentiles (usec):
     |  1.00th=[ 1188],  5.00th=[ 1385], 10.00th=[ 1450], 20.00th=[ 1516],
     | 30.00th=[ 1582], 40.00th=[ 1647], 50.00th=[ 1696], 60.00th=[ 1745],
     | 70.00th=[ 1811], 80.00th=[ 1893], 90.00th=[ 2245], 95.00th=[ 3228],
     | 99.00th=[ 3752], 99.50th=[ 4113], 99.90th=[ 5735], 99.95th=[ 5866],
     | 99.99th=[ 6325]
   bw (  KiB/s): min=255352, max=678616, per=99.96%, avg=555831.72, stdev=53453.60, samples=238
   iops        : min=63838, max=169652, avg=138957.92, stdev=13363.37, samples=238
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.22%
  lat (msec)   : 2=85.51%, 4=13.71%, 10=0.56%
  cpu          : usr=16.99%, sys=46.85%, ctx=514089, majf=0, minf=288
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=8341249,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=543MiB/s (569MB/s), 543MiB/s-543MiB/s (569MB/s-569MB/s), io=31.8GiB (34.2GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=2, iodepth=128; bs=4ki) read:  read: IOPS=139k, BW=543MiB/s (569MB/s)(31.8GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4ki, disks=3 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 3 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 82674515 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 86541325 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 90543745 total
[0m
j1: (groupid=0, jobs=3): err= 0: pid=6422: Fri Jan 12 17:13:24 2024
  read: IOPS=182k, BW=712MiB/s (746MB/s)(41.7GiB/60001msec)
    slat (usec): min=3, max=7707, avg=14.73, stdev=39.78
    clat (usec): min=157, max=11129, avg=2091.28, stdev=882.47
     lat (usec): min=168, max=11135, avg=2106.25, stdev=888.96
    clat percentiles (usec):
     |  1.00th=[ 1336],  5.00th=[ 1467], 10.00th=[ 1549], 20.00th=[ 1631],
     | 30.00th=[ 1696], 40.00th=[ 1762], 50.00th=[ 1811], 60.00th=[ 1876],
     | 70.00th=[ 1975], 80.00th=[ 2180], 90.00th=[ 3326], 95.00th=[ 3916],
     | 99.00th=[ 5145], 99.50th=[ 7570], 99.90th=[ 9372], 99.95th=[ 9634],
     | 99.99th=[10159]
   bw (  KiB/s): min=216672, max=978712, per=99.88%, avg=727895.08, stdev=62305.13, samples=357
   iops        : min=54168, max=244678, avg=181973.68, stdev=15576.32, samples=357
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.09%
  lat (msec)   : 2=71.71%, 4=24.04%, 10=4.15%, 20=0.02%
  cpu          : usr=13.43%, sys=41.70%, ctx=821189, majf=0, minf=608
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=10932135,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=712MiB/s (746MB/s), 712MiB/s-712MiB/s (746MB/s-746MB/s), io=41.7GiB (44.8GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=3, iodepth=128; bs=4ki) read:  read: IOPS=182k, BW=712MiB/s (746MB/s)(41.7GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 94227739 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 98767210 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 102817563 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6471: Fri Jan 12 17:14:26 2024
  read: IOPS=201k, BW=787MiB/s (825MB/s)(46.1GiB/60001msec)
    slat (usec): min=3, max=8134, avg=18.06, stdev=46.23
    clat (usec): min=139, max=13012, avg=2522.98, stdev=1028.63
     lat (usec): min=160, max=13017, avg=2541.30, stdev=1036.19
    clat percentiles (usec):
     |  1.00th=[ 1369],  5.00th=[ 1532], 10.00th=[ 1598], 20.00th=[ 1713],
     | 30.00th=[ 1795], 40.00th=[ 1876], 50.00th=[ 2008], 60.00th=[ 2278],
     | 70.00th=[ 3195], 80.00th=[ 3523], 90.00th=[ 3851], 95.00th=[ 4359],
     | 99.00th=[ 5604], 99.50th=[ 5997], 99.90th=[ 7111], 99.95th=[ 7701],
     | 99.99th=[ 9110]
   bw (  KiB/s): min=377056, max=1285168, per=100.00%, avg=805751.83, stdev=63165.18, samples=476
   iops        : min=94264, max=321292, avg=201437.54, stdev=15791.30, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.10%
  lat (msec)   : 2=49.80%, 4=42.33%, 10=7.77%, 20=0.01%
  cpu          : usr=11.46%, sys=36.22%, ctx=1291647, majf=0, minf=562
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=12082126,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=787MiB/s (825MB/s), 787MiB/s-787MiB/s (825MB/s-825MB/s), io=46.1GiB (49.5GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4ki) read:  read: IOPS=201k, BW=787MiB/s (825MB/s)(46.1GiB/60001msec)


===Fio: workload=randread, time=30, iodepth=128, bs=4ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 106370173 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 109906719 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6521: Fri Jan 12 17:14:59 2024
  read: IOPS=166k, BW=647MiB/s (678MB/s)(18.9GiB/30001msec)
    slat (usec): min=3, max=7372, avg=22.03, stdev=61.96
    clat (usec): min=160, max=11961, avg=3068.59, stdev=1337.79
     lat (usec): min=170, max=11968, avg=3090.87, stdev=1347.66
    clat percentiles (usec):
     |  1.00th=[ 1663],  5.00th=[ 1844], 10.00th=[ 1926], 20.00th=[ 2008],
     | 30.00th=[ 2089], 40.00th=[ 2180], 50.00th=[ 2311], 60.00th=[ 3163],
     | 70.00th=[ 3687], 80.00th=[ 4178], 90.00th=[ 5211], 95.00th=[ 5735],
     | 99.00th=[ 6718], 99.50th=[ 7242], 99.90th=[ 8979], 99.95th=[10159],
     | 99.99th=[10945]
   bw (  KiB/s): min=322896, max=1041712, per=99.48%, avg=658814.73, stdev=52787.37, samples=236
   iops        : min=80724, max=260426, avg=164703.75, stdev=13196.82, samples=236
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=18.24%, 4=58.49%, 10=23.20%, 20=0.06%
  cpu          : usr=10.79%, sys=31.27%, ctx=554453, majf=0, minf=553
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=4966928,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=647MiB/s (678MB/s), 647MiB/s-647MiB/s (678MB/s-678MB/s), io=18.9GiB (20.3GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4ki) randread:  read: IOPS=166k, BW=647MiB/s (678MB/s)(18.9GiB/30001msec)


===Fio: workload=randread, time=30, iodepth=128, bs=8ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1110 MiB read, 0.000 read amp, 113002915 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6573: Fri Jan 12 17:15:31 2024
  read: IOPS=156k, BW=1221MiB/s (1280MB/s)(35.8GiB/30001msec)
    slat (usec): min=4, max=6580, avg=23.24, stdev=65.04
    clat (usec): min=170, max=15018, avg=3250.93, stdev=1307.67
     lat (usec): min=183, max=15039, avg=3274.46, stdev=1317.26
    clat percentiles (usec):
     |  1.00th=[ 1893],  5.00th=[ 2114], 10.00th=[ 2212], 20.00th=[ 2311],
     | 30.00th=[ 2409], 40.00th=[ 2507], 50.00th=[ 2638], 60.00th=[ 2868],
     | 70.00th=[ 3851], 80.00th=[ 4424], 90.00th=[ 4883], 95.00th=[ 5407],
     | 99.00th=[ 7898], 99.50th=[ 9241], 99.90th=[11469], 99.95th=[11863],
     | 99.99th=[12649]
   bw (  MiB/s): min=  603, max= 1782, per=100.00%, avg=1224.01, stdev=77.11, samples=236
   iops        : min=77284, max=228184, avg=156673.83, stdev=9869.78, samples=236
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=2.39%, 4=69.09%, 10=28.16%, 20=0.35%
  cpu          : usr=10.79%, sys=32.32%, ctx=617204, majf=0, minf=1072
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=4688327,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1221MiB/s (1280MB/s), 1221MiB/s-1221MiB/s (1280MB/s-1280MB/s), io=35.8GiB (38.4GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=8ki) randread:  read: IOPS=156k, BW=1221MiB/s (1280MB/s)(35.8GiB/30001msec)
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1111 MiB read, 0.000 read amp, 116398695 total
[0m

===Fio: workload=randread, time=30, iodepth=128, bs=16ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 118874234 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6622: Fri Jan 12 17:16:04 2024
  read: IOPS=114k, BW=1775MiB/s (1862MB/s)(52.0GiB/30002msec)
    slat (usec): min=4, max=7146, avg=32.54, stdev=80.20
    clat (usec): min=265, max=18954, avg=4470.87, stdev=2157.48
     lat (usec): min=274, max=19014, avg=4503.75, stdev=2173.64
    clat percentiles (usec):
     |  1.00th=[ 2507],  5.00th=[ 2671], 10.00th=[ 2769], 20.00th=[ 2900],
     | 30.00th=[ 3032], 40.00th=[ 3163], 50.00th=[ 3392], 60.00th=[ 3982],
     | 70.00th=[ 5473], 80.00th=[ 5866], 90.00th=[ 7308], 95.00th=[ 8717],
     | 99.00th=[11469], 99.50th=[13829], 99.90th=[17433], 99.95th=[17695],
     | 99.99th=[18220]
   bw (  MiB/s): min=  627, max= 2837, per=100.00%, avg=1776.35, stdev=151.84, samples=236
   iops        : min=40178, max=181607, avg=113686.64, stdev=9717.94, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.02%, 4=60.07%, 10=37.54%, 20=2.37%
  cpu          : usr=9.40%, sys=29.04%, ctx=987202, majf=0, minf=2097
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=3408901,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1775MiB/s (1862MB/s), 1775MiB/s-1775MiB/s (1862MB/s-1862MB/s), io=52.0GiB (55.9GB), run=30002-30002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=16ki) randread:  read: IOPS=114k, BW=1775MiB/s (1862MB/s)(52.0GiB/30002msec)


===Fio: workload=randread, time=30, iodepth=128, bs=32ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 3332 MiB read, 0.000 read amp, 121155046 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 3339 MiB read, 0.000 read amp, 123111833 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6672: Fri Jan 12 17:16:36 2024
  read: IOPS=65.6k, BW=2049MiB/s (2149MB/s)(60.0GiB/30005msec)
    slat (usec): min=5, max=14388, avg=58.41, stdev=139.84
    clat (usec): min=247, max=30342, avg=7746.12, stdev=4202.75
     lat (usec): min=259, max=32134, avg=7804.87, stdev=4234.20
    clat percentiles (usec):
     |  1.00th=[ 3884],  5.00th=[ 4080], 10.00th=[ 4228], 20.00th=[ 4555],
     | 30.00th=[ 5080], 40.00th=[ 5932], 50.00th=[ 6587], 60.00th=[ 6849],
     | 70.00th=[ 8094], 80.00th=[ 9896], 90.00th=[13566], 95.00th=[15926],
     | 99.00th=[24249], 99.50th=[24773], 99.90th=[25822], 99.95th=[26084],
     | 99.99th=[26608]
   bw (  MiB/s): min=  763, max= 3655, per=100.00%, avg=2051.14, stdev=217.96, samples=236
   iops        : min=24446, max=116972, avg=65636.58, stdev=6974.72, samples=236
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.02%, 4=2.94%, 10=77.80%, 20=16.59%, 50=2.64%
  cpu          : usr=6.34%, sys=19.69%, ctx=1586503, majf=0, minf=4141
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=1967588,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=2049MiB/s (2149MB/s), 2049MiB/s-2049MiB/s (2149MB/s-2149MB/s), io=60.0GiB (64.5GB), run=30005-30005msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=32ki) randread:  read: IOPS=65.6k, BW=2049MiB/s (2149MB/s)(60.0GiB/30005msec)


===Fio: workload=randread, time=30, iodepth=128, bs=64ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5001 MiB read, 0.000 read amp, 124666569 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6721: Fri Jan 12 17:17:09 2024
  read: IOPS=39.2k, BW=2451MiB/s (2570MB/s)(71.8GiB/30007msec)
    slat (usec): min=5, max=6780, avg=98.80, stdev=153.71
    clat (usec): min=329, max=38389, avg=12951.06, stdev=3581.06
     lat (usec): min=347, max=38398, avg=13050.31, stdev=3606.08
    clat percentiles (usec):
     |  1.00th=[ 8291],  5.00th=[ 8717], 10.00th=[ 8979], 20.00th=[ 9372],
     | 30.00th=[ 9896], 40.00th=[11994], 50.00th=[12518], 60.00th=[13042],
     | 70.00th=[14222], 80.00th=[15664], 90.00th=[18220], 95.00th=[20055],
     | 99.00th=[22152], 99.50th=[22676], 99.90th=[30540], 99.95th=[31851],
     | 99.99th=[32900]
   bw (  MiB/s): min= 1569, max= 3561, per=100.00%, avg=2460.84, stdev=144.31, samples=236
   iops        : min=25106, max=56979, avg=39372.98, stdev=2308.94, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.04%, 10=30.61%, 20=64.23%, 50=5.10%
  cpu          : usr=4.88%, sys=15.01%, ctx=1186029, majf=0, minf=8230
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=1176824,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=2451MiB/s (2570MB/s), 2451MiB/s-2451MiB/s (2570MB/s-2570MB/s), io=71.8GiB (77.1GB), run=30007-30007msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=64ki) randread:  read: IOPS=39.2k, BW=2451MiB/s (2570MB/s)(71.8GiB/30007msec)


===Fio: workload=read, time=30, iodepth=128, bs=4ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1877 MiB read, 0.000 read amp, 126078018 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 130203096 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6773: Fri Jan 12 17:17:41 2024
  read: IOPS=197k, BW=769MiB/s (806MB/s)(22.5GiB/30001msec)
    slat (usec): min=3, max=5761, avg=18.54, stdev=49.63
    clat (usec): min=87, max=8819, avg=2581.55, stdev=1189.47
     lat (usec): min=107, max=8995, avg=2600.34, stdev=1198.33
    clat percentiles (usec):
     |  1.00th=[ 1450],  5.00th=[ 1565], 10.00th=[ 1631], 20.00th=[ 1729],
     | 30.00th=[ 1811], 40.00th=[ 1893], 50.00th=[ 1991], 60.00th=[ 2180],
     | 70.00th=[ 2999], 80.00th=[ 3556], 90.00th=[ 4293], 95.00th=[ 5145],
     | 99.00th=[ 6456], 99.50th=[ 6652], 99.90th=[ 7701], 99.95th=[ 7898],
     | 99.99th=[ 8160]
   bw (  KiB/s): min=339672, max=1206672, per=100.00%, avg=787207.19, stdev=61849.14, samples=236
   iops        : min=84918, max=301668, avg=196801.80, stdev=15462.28, samples=236
  lat (usec)   : 100=0.01%, 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.03%
  lat (msec)   : 2=50.85%, 4=36.49%, 10=12.62%
  cpu          : usr=11.21%, sys=35.87%, ctx=602766, majf=0, minf=570
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=5903976,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=769MiB/s (806MB/s), 769MiB/s-769MiB/s (806MB/s-806MB/s), io=22.5GiB (24.2GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4ki) read:  read: IOPS=197k, BW=769MiB/s (806MB/s)(22.5GiB/30001msec)


===Fio: workload=read, time=30, iodepth=128, bs=8ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1111 MiB read, 0.000 read amp, 133857432 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1111 MiB read, 0.000 read amp, 138073854 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6822: Fri Jan 12 17:18:13 2024
  read: IOPS=184k, BW=1435MiB/s (1504MB/s)(42.0GiB/30002msec)
    slat (usec): min=4, max=6821, avg=19.67, stdev=52.57
    clat (usec): min=229, max=11471, avg=2765.98, stdev=977.48
     lat (usec): min=249, max=11553, avg=2785.92, stdev=984.58
    clat percentiles (usec):
     |  1.00th=[ 1680],  5.00th=[ 1876], 10.00th=[ 1991], 20.00th=[ 2114],
     | 30.00th=[ 2212], 40.00th=[ 2311], 50.00th=[ 2409], 60.00th=[ 2573],
     | 70.00th=[ 2802], 80.00th=[ 3326], 90.00th=[ 4228], 95.00th=[ 4686],
     | 99.00th=[ 6194], 99.50th=[ 7046], 99.90th=[ 8848], 99.95th=[ 9372],
     | 99.99th=[10028]
   bw (  MiB/s): min=  778, max= 2021, per=100.00%, avg=1438.07, stdev=77.92, samples=236
   iops        : min=99658, max=258704, avg=184073.12, stdev=9973.29, samples=236
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=11.14%, 4=75.99%, 10=12.85%, 20=0.01%
  cpu          : usr=11.53%, sys=36.51%, ctx=715691, majf=0, minf=1367
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=5510002,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1435MiB/s (1504MB/s), 1435MiB/s-1435MiB/s (1504MB/s-1504MB/s), io=42.0GiB (45.1GB), run=30002-30002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=8ki) read:  read: IOPS=184k, BW=1435MiB/s (1504MB/s)(42.0GiB/30002msec)


===Fio: workload=read, time=30, iodepth=128, bs=16ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 140869228 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6872: Fri Jan 12 17:18:46 2024
  read: IOPS=126k, BW=1969MiB/s (2065MB/s)(57.7GiB/30001msec)
    slat (usec): min=4, max=7987, avg=29.66, stdev=74.42
    clat (usec): min=223, max=16986, avg=4030.15, stdev=1835.26
     lat (usec): min=236, max=16997, avg=4060.13, stdev=1848.92
    clat percentiles (usec):
     |  1.00th=[ 2245],  5.00th=[ 2442], 10.00th=[ 2540], 20.00th=[ 2704],
     | 30.00th=[ 2868], 40.00th=[ 3064], 50.00th=[ 3490], 60.00th=[ 3949],
     | 70.00th=[ 4686], 80.00th=[ 5145], 90.00th=[ 5604], 95.00th=[ 6718],
     | 99.00th=[12780], 99.50th=[14615], 99.90th=[15533], 99.95th=[15795],
     | 99.99th=[16319]
   bw (  MiB/s): min=  848, max= 3058, per=100.00%, avg=1974.53, stdev=141.86, samples=236
   iops        : min=54272, max=195744, avg=126369.54, stdev=9079.24, samples=236
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.05%, 4=60.70%, 10=37.03%, 20=2.21%
  cpu          : usr=8.47%, sys=29.95%, ctx=1049048, majf=0, minf=2097
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=3781486,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1969MiB/s (2065MB/s), 1969MiB/s-1969MiB/s (2065MB/s-2065MB/s), io=57.7GiB (62.0GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=16ki) read:  read: IOPS=126k, BW=1969MiB/s (2065MB/s)(57.7GiB/30001msec)


===Fio: workload=read, time=30, iodepth=128, bs=32ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 3333 MiB read, 0.000 read amp, 143548358 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 3333 MiB read, 0.000 read amp, 145866449 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6921: Fri Jan 12 17:19:18 2024
  read: IOPS=76.0k, BW=2376MiB/s (2492MB/s)(69.6GiB/30003msec)
    slat (usec): min=4, max=9023, avg=50.62, stdev=87.98
    clat (usec): min=398, max=28054, avg=6679.83, stdev=2107.89
     lat (usec): min=420, max=30422, avg=6730.77, stdev=2123.49
    clat percentiles (usec):
     |  1.00th=[ 3720],  5.00th=[ 4080], 10.00th=[ 4359], 20.00th=[ 4883],
     | 30.00th=[ 5669], 40.00th=[ 6063], 50.00th=[ 6521], 60.00th=[ 6849],
     | 70.00th=[ 7242], 80.00th=[ 7832], 90.00th=[ 8586], 95.00th=[11338],
     | 99.00th=[13960], 99.50th=[15664], 99.90th=[16450], 99.95th=[16909],
     | 99.99th=[23987]
   bw (  MiB/s): min= 1081, max= 3711, per=100.00%, avg=2379.17, stdev=149.97, samples=236
   iops        : min=34592, max=118776, avg=76133.56, stdev=4799.07, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=3.67%, 10=90.47%, 20=5.82%, 50=0.02%
  cpu          : usr=6.29%, sys=21.60%, ctx=2124404, majf=0, minf=4138
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=2281485,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=2376MiB/s (2492MB/s), 2376MiB/s-2376MiB/s (2492MB/s-2492MB/s), io=69.6GiB (74.8GB), run=30003-30003msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=32ki) read:  read: IOPS=76.0k, BW=2376MiB/s (2492MB/s)(69.6GiB/30003msec)


===Fio: workload=read, time=30, iodepth=128, bs=64ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 147633376 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=6970: Fri Jan 12 17:19:51 2024
  read: IOPS=45.2k, BW=2825MiB/s (2962MB/s)(82.8GiB/30006msec)
    slat (usec): min=5, max=371641, avg=86.07, stdev=344.94
    clat (usec): min=396, max=391772, avg=11237.61, stdev=4904.73
     lat (usec): min=548, max=391959, avg=11324.08, stdev=4931.59
    clat percentiles (usec):
     |  1.00th=[ 8094],  5.00th=[ 8586], 10.00th=[ 8717], 20.00th=[ 8979],
     | 30.00th=[ 9241], 40.00th=[ 9372], 50.00th=[ 9634], 60.00th=[10159],
     | 70.00th=[12125], 80.00th=[13566], 90.00th=[15008], 95.00th=[17695],
     | 99.00th=[23200], 99.50th=[23462], 99.90th=[24249], 99.95th=[24511],
     | 99.99th=[26608]
   bw (  MiB/s): min= 1414, max= 3618, per=100.00%, avg=2826.41, stdev=142.57, samples=236
   iops        : min=22632, max=57898, avg=45222.54, stdev=2281.15, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.02%, 10=58.50%, 20=37.75%, 50=3.71%
  lat (msec)   : 500=0.01%
  cpu          : usr=4.78%, sys=15.45%, ctx=1361058, majf=0, minf=8249
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=1356071,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=2825MiB/s (2962MB/s), 2825MiB/s-2825MiB/s (2962MB/s-2962MB/s), io=82.8GiB (88.9GB), run=30006-30006msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=64ki) read:  read: IOPS=45.2k, BW=2825MiB/s (2962MB/s)(82.8GiB/30006msec)
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 149297732 total
[0m

===Fio: workload=randread, time=60, iodepth=256, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 152596422 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 156250252 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 159906753 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7020: Fri Jan 12 17:20:53 2024
  read: IOPS=170k, BW=666MiB/s (698MB/s)(39.0GiB/60001msec)
    slat (usec): min=3, max=7432, avg=21.28, stdev=56.47
    clat (usec): min=323, max=27595, avg=5983.65, stdev=2381.98
     lat (usec): min=456, max=27748, avg=6005.20, stdev=2390.95
    clat percentiles (usec):
     |  1.00th=[ 3556],  5.00th=[ 3785], 10.00th=[ 3982], 20.00th=[ 4178],
     | 30.00th=[ 4293], 40.00th=[ 4424], 50.00th=[ 4621], 60.00th=[ 5407],
     | 70.00th=[ 7570], 80.00th=[ 8160], 90.00th=[ 9110], 95.00th=[10159],
     | 99.00th=[13042], 99.50th=[14615], 99.90th=[19792], 99.95th=[21627],
     | 99.99th=[25035]
   bw (  KiB/s): min=293682, max=1091025, per=100.00%, avg=683920.13, stdev=48032.58, samples=476
   iops        : min=73420, max=272756, avg=170979.30, stdev=12008.14, samples=476
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=10.38%, 10=84.26%, 20=5.26%, 50=0.10%
  cpu          : usr=11.24%, sys=32.95%, ctx=1185340, majf=0, minf=1071
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=10228050,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=666MiB/s (698MB/s), 666MiB/s-666MiB/s (698MB/s-698MB/s), io=39.0GiB (41.9GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4k) randread:  read: IOPS=170k, BW=666MiB/s (698MB/s)(39.0GiB/60001msec)


===Fio: workload=read, time=60, iodepth=256, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 163615719 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 167428455 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 171708622 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7070: Fri Jan 12 17:21:55 2024
  read: IOPS=194k, BW=758MiB/s (795MB/s)(44.4GiB/60001msec)
    slat (usec): min=3, max=5140, avg=18.80, stdev=50.05
    clat (usec): min=167, max=19842, avg=5258.14, stdev=2262.11
     lat (usec): min=296, max=19866, avg=5277.20, stdev=2270.72
    clat percentiles (usec):
     |  1.00th=[ 3032],  5.00th=[ 3261], 10.00th=[ 3392], 20.00th=[ 3556],
     | 30.00th=[ 3687], 40.00th=[ 3851], 50.00th=[ 4015], 60.00th=[ 4424],
     | 70.00th=[ 6587], 80.00th=[ 7373], 90.00th=[ 8225], 95.00th=[ 9765],
     | 99.00th=[11731], 99.50th=[12387], 99.90th=[16712], 99.95th=[18744],
     | 99.99th=[19268]
   bw (  KiB/s): min=328532, max=1249649, per=100.00%, avg=776969.44, stdev=63537.34, samples=476
   iops        : min=82133, max=312412, avg=194242.11, stdev=15884.33, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=48.75%, 10=46.78%, 20=4.46%
  cpu          : usr=11.10%, sys=35.89%, ctx=1204585, majf=0, minf=1080
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=11638916,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=758MiB/s (795MB/s), 758MiB/s-758MiB/s (795MB/s-795MB/s), io=44.4GiB (47.7GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4k) read:  read: IOPS=194k, BW=758MiB/s (795MB/s)(44.4GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=1, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 172967973 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 173625972 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 174280411 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7119: Fri Jan 12 17:22:58 2024
  read: IOPS=30.8k, BW=120MiB/s (126MB/s)(7213MiB/60001msec)
    slat (usec): min=5, max=550, avg= 9.20, stdev= 4.64
    clat (nsec): min=636, max=8540.6k, avg=118062.38, stdev=40562.90
     lat (usec): min=85, max=8547, avg=127.54, stdev=41.37
    clat percentiles (usec):
     |  1.00th=[   87],  5.00th=[   91], 10.00th=[   94], 20.00th=[   97],
     | 30.00th=[  100], 40.00th=[  103], 50.00th=[  109], 60.00th=[  114],
     | 70.00th=[  119], 80.00th=[  127], 90.00th=[  145], 95.00th=[  182],
     | 99.00th=[  293], 99.50th=[  330], 99.90th=[  486], 99.95th=[  529],
     | 99.99th=[  619]
   bw (  KiB/s): min=106504, max=138800, per=100.00%, avg=123213.71, stdev=1736.49, samples=476
   iops        : min=26626, max=34700, avg=30803.45, stdev=434.13, samples=476
  lat (nsec)   : 750=0.01%, 1000=0.01%
  lat (usec)   : 2=0.01%, 50=0.01%, 100=30.48%, 250=67.25%, 500=2.19%
  lat (usec)   : 750=0.08%, 1000=0.01%
  lat (msec)   : 2=0.01%, 10=0.01%
  cpu          : usr=4.48%, sys=10.99%, ctx=1846477, majf=0, minf=61
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwts: total=1846433,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=1

Run status group 0 (all jobs):
   READ: bw=120MiB/s (126MB/s), 120MiB/s-120MiB/s (126MB/s-126MB/s), io=7213MiB (7563MB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=1; bs=4k) randread:  read: IOPS=30.8k, BW=120MiB/s (126MB/s)(7213MiB/60001msec)


===Fio: workload=randread, time=60, iodepth=32, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 176566487 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 180316265 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 184010492 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7168: Fri Jan 12 17:24:00 2024
  read: IOPS=173k, BW=675MiB/s (708MB/s)(39.5GiB/60001msec)
    slat (usec): min=3, max=1110, avg= 7.02, stdev= 7.02
    clat (usec): min=73, max=9194, avg=731.93, stdev=319.73
     lat (usec): min=104, max=9200, avg=739.16, stdev=319.77
    clat percentiles (usec):
     |  1.00th=[  293],  5.00th=[  363], 10.00th=[  408], 20.00th=[  465],
     | 30.00th=[  519], 40.00th=[  570], 50.00th=[  619], 60.00th=[  701],
     | 70.00th=[  898], 80.00th=[ 1037], 90.00th=[ 1172], 95.00th=[ 1319],
     | 99.00th=[ 1647], 99.50th=[ 1762], 99.90th=[ 2024], 99.95th=[ 2147],
     | 99.99th=[ 2311]
   bw (  KiB/s): min=333168, max=1016496, per=100.00%, avg=691600.10, stdev=46931.22, samples=476
   iops        : min=83292, max=254124, avg=172899.92, stdev=11732.81, samples=476
  lat (usec)   : 100=0.01%, 250=0.15%, 500=26.42%, 750=37.07%, 1000=13.12%
  lat (msec)   : 2=23.13%, 4=0.11%, 10=0.01%
  cpu          : usr=11.38%, sys=31.77%, ctx=1154729, majf=0, minf=190
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued rwts: total=10367921,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32

Run status group 0 (all jobs):
   READ: bw=675MiB/s (708MB/s), 675MiB/s-675MiB/s (708MB/s-708MB/s), io=39.5GiB (42.5GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=32; bs=4k) randread:  read: IOPS=173k, BW=675MiB/s (708MB/s)(39.5GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=64, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 187226861 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 190956711 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 194608358 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7218: Fri Jan 12 17:25:03 2024
  read: IOPS=178k, BW=695MiB/s (728MB/s)(40.7GiB/60002msec)
    slat (usec): min=3, max=6386, avg=18.69, stdev=51.03
    clat (usec): min=94, max=7771, avg=1419.01, stdev=591.18
     lat (usec): min=186, max=7777, avg=1437.96, stdev=598.63
    clat percentiles (usec):
     |  1.00th=[  685],  5.00th=[  889], 10.00th=[  938], 20.00th=[  996],
     | 30.00th=[ 1037], 40.00th=[ 1074], 50.00th=[ 1139], 60.00th=[ 1237],
     | 70.00th=[ 1631], 80.00th=[ 1975], 90.00th=[ 2245], 95.00th=[ 2540],
     | 99.00th=[ 3326], 99.50th=[ 3589], 99.90th=[ 4047], 99.95th=[ 4228],
     | 99.99th=[ 5014]
   bw (  KiB/s): min=301752, max=1038864, per=100.00%, avg=712253.29, stdev=49376.77, samples=476
   iops        : min=75438, max=259716, avg=178062.92, stdev=12344.20, samples=476
  lat (usec)   : 100=0.01%, 250=0.01%, 500=0.10%, 750=1.33%, 1000=20.27%
  lat (msec)   : 2=59.67%, 4=18.51%, 10=0.12%
  cpu          : usr=11.57%, sys=33.81%, ctx=1145515, majf=0, minf=305
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=10670102,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=695MiB/s (728MB/s), 695MiB/s-695MiB/s (728MB/s-728MB/s), io=40.7GiB (43.7GB), run=60002-60002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=64; bs=4k) randread:  read: IOPS=178k, BW=695MiB/s (728MB/s)(40.7GiB/60002msec)


===Fio: workload=randread, time=60, iodepth=128, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 198038368 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 201699074 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 205315210 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7271: Fri Jan 12 17:26:05 2024
  read: IOPS=172k, BW=671MiB/s (704MB/s)(39.3GiB/60001msec)
    slat (usec): min=3, max=10307, avg=21.11, stdev=58.95
    clat (usec): min=165, max=14861, avg=2957.38, stdev=1218.98
     lat (usec): min=183, max=14867, avg=2978.76, stdev=1227.91
    clat percentiles (usec):
     |  1.00th=[ 1745],  5.00th=[ 1909], 10.00th=[ 1991], 20.00th=[ 2073],
     | 30.00th=[ 2147], 40.00th=[ 2212], 50.00th=[ 2278], 60.00th=[ 2442],
     | 70.00th=[ 3687], 80.00th=[ 4178], 90.00th=[ 4621], 95.00th=[ 5342],
     | 99.00th=[ 6652], 99.50th=[ 6849], 99.90th=[ 7373], 99.95th=[ 7767],
     | 99.99th=[ 9241]
   bw (  KiB/s): min=319696, max=1006872, per=99.98%, avg=687039.45, stdev=49305.13, samples=476
   iops        : min=79924, max=251718, avg=171759.61, stdev=12326.27, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=11.06%, 4=64.67%, 10=24.25%, 20=0.01%
  cpu          : usr=11.16%, sys=32.57%, ctx=1130152, majf=0, minf=566
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=10307520,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=671MiB/s (704MB/s), 671MiB/s-671MiB/s (704MB/s-704MB/s), io=39.3GiB (42.2GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4k) randread:  read: IOPS=172k, BW=671MiB/s (704MB/s)(39.3GiB/60001msec)


===Fio: workload=read, time=60, iodepth=1, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 207930504 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 208607474 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 209286080 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7321: Fri Jan 12 17:27:08 2024
  read: IOPS=32.0k, BW=125MiB/s (131MB/s)(7496MiB/60001msec)
    slat (usec): min=5, max=498, avg= 8.92, stdev= 4.16
    clat (nsec): min=552, max=9883.2k, avg=114040.62, stdev=43292.40
     lat (usec): min=82, max=9896, avg=123.23, stdev=43.96
    clat percentiles (usec):
     |  1.00th=[   85],  5.00th=[   89], 10.00th=[   91], 20.00th=[   95],
     | 30.00th=[   98], 40.00th=[  101], 50.00th=[  105], 60.00th=[  110],
     | 70.00th=[  114], 80.00th=[  122], 90.00th=[  141], 95.00th=[  182],
     | 99.00th=[  265], 99.50th=[  306], 99.90th=[  482], 99.95th=[  529],
     | 99.99th=[  611]
   bw (  KiB/s): min=115314, max=141120, per=100.00%, avg=128013.61, stdev=1413.50, samples=476
   iops        : min=28828, max=35280, avg=32003.25, stdev=353.37, samples=476
  lat (nsec)   : 750=0.01%, 1000=0.01%
  lat (usec)   : 2=0.01%, 20=0.01%, 50=0.01%, 100=37.07%, 250=61.67%
  lat (usec)   : 500=1.18%, 750=0.07%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.01%
  cpu          : usr=4.34%, sys=10.82%, ctx=1919102, majf=0, minf=61
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwts: total=1919078,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=1

Run status group 0 (all jobs):
   READ: bw=125MiB/s (131MB/s), 125MiB/s-125MiB/s (131MB/s-131MB/s), io=7496MiB (7861MB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=1; bs=4k) read:  read: IOPS=32.0k, BW=125MiB/s (131MB/s)(7496MiB/60001msec)


===Fio: workload=read, time=60, iodepth=32, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 210104380 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 213980271 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 217927690 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7371: Fri Jan 12 17:28:10 2024
  read: IOPS=186k, BW=726MiB/s (761MB/s)(42.5GiB/60001msec)
    slat (usec): min=3, max=1800, avg= 7.10, stdev= 7.78
    clat (usec): min=86, max=9429, avg=680.06, stdev=307.73
     lat (usec): min=95, max=9435, avg=687.39, stdev=307.58
    clat percentiles (usec):
     |  1.00th=[  269],  5.00th=[  330], 10.00th=[  363], 20.00th=[  416],
     | 30.00th=[  465], 40.00th=[  515], 50.00th=[  578], 60.00th=[  693],
     | 70.00th=[  848], 80.00th=[  955], 90.00th=[ 1090], 95.00th=[ 1237],
     | 99.00th=[ 1565], 99.50th=[ 1696], 99.90th=[ 2008], 99.95th=[ 2147],
     | 99.99th=[ 2540]
   bw (  KiB/s): min=297928, max=1156328, per=100.00%, avg=743712.61, stdev=55463.46, samples=476
   iops        : min=74482, max=289084, avg=185928.18, stdev=13865.88, samples=476
  lat (usec)   : 100=0.01%, 250=0.39%, 500=36.91%, 750=25.73%, 1000=21.32%
  lat (msec)   : 2=15.54%, 4=0.10%, 10=0.01%
  cpu          : usr=11.29%, sys=34.08%, ctx=1220103, majf=0, minf=187
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued rwts: total=11151628,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32

Run status group 0 (all jobs):
   READ: bw=726MiB/s (761MB/s), 726MiB/s-726MiB/s (761MB/s-761MB/s), io=42.5GiB (45.7GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=32; bs=4k) read:  read: IOPS=186k, BW=726MiB/s (761MB/s)(42.5GiB/60001msec)
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 221686349 total
[0m

===Fio: workload=read, time=60, iodepth=64, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 225967389 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 230086023 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 234145739 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7420: Fri Jan 12 17:29:12 2024
  read: IOPS=199k, BW=778MiB/s (816MB/s)(45.6GiB/60001msec)
    slat (usec): min=4, max=7443, avg=16.95, stdev=45.18
    clat (usec): min=86, max=9549, avg=1266.88, stdev=541.10
     lat (usec): min=115, max=9556, avg=1284.10, stdev=548.40
    clat percentiles (usec):
     |  1.00th=[  586],  5.00th=[  742], 10.00th=[  799], 20.00th=[  857],
     | 30.00th=[  914], 40.00th=[  963], 50.00th=[ 1029], 60.00th=[ 1156],
     | 70.00th=[ 1467], 80.00th=[ 1745], 90.00th=[ 2024], 95.00th=[ 2245],
     | 99.00th=[ 3064], 99.50th=[ 3458], 99.90th=[ 3916], 99.95th=[ 4047],
     | 99.99th=[ 4359]
   bw (  KiB/s): min=280864, max=1183868, per=99.93%, avg=796040.75, stdev=57010.38, samples=476
   iops        : min=70216, max=295967, avg=199009.93, stdev=14252.60, samples=476
  lat (usec)   : 100=0.01%, 250=0.01%, 500=0.15%, 750=5.20%, 1000=40.55%
  lat (msec)   : 2=43.57%, 4=10.45%, 10=0.07%
  cpu          : usr=12.02%, sys=38.12%, ctx=1137248, majf=0, minf=302
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=11949408,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=778MiB/s (816MB/s), 778MiB/s-778MiB/s (816MB/s-816MB/s), io=45.6GiB (48.9GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=64; bs=4k) read:  read: IOPS=199k, BW=778MiB/s (816MB/s)(45.6GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 238076425 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 241914345 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 245825940 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7470: Fri Jan 12 17:30:15 2024
  read: IOPS=190k, BW=744MiB/s (780MB/s)(43.6GiB/60001msec)
    slat (usec): min=3, max=8471, avg=19.17, stdev=50.13
    clat (usec): min=184, max=13738, avg=2669.03, stdev=1065.54
     lat (usec): min=191, max=13750, avg=2688.45, stdev=1073.34
    clat percentiles (usec):
     |  1.00th=[ 1450],  5.00th=[ 1614], 10.00th=[ 1696], 20.00th=[ 1795],
     | 30.00th=[ 1876], 40.00th=[ 1975], 50.00th=[ 2147], 60.00th=[ 2704],
     | 70.00th=[ 3359], 80.00th=[ 3589], 90.00th=[ 3982], 95.00th=[ 4686],
     | 99.00th=[ 5866], 99.50th=[ 6063], 99.90th=[ 6587], 99.95th=[ 7111],
     | 99.99th=[10945]
   bw (  KiB/s): min=368303, max=1215320, per=100.00%, avg=761525.50, stdev=53808.84, samples=476
   iops        : min=92074, max=303830, avg=190380.92, stdev=13452.22, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.02%
  lat (msec)   : 2=41.68%, 4=48.45%, 10=9.84%, 20=0.01%
  cpu          : usr=11.08%, sys=35.46%, ctx=1245987, majf=0, minf=572
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=11420971,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=744MiB/s (780MB/s), 744MiB/s-744MiB/s (780MB/s-780MB/s), io=43.6GiB (46.8GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4k) read:  read: IOPS=190k, BW=744MiB/s (780MB/s)(43.6GiB/60001msec)


===Fio: workload=read, time=60, iodepth=256, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 249568200 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 253388817 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 257529911 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7521: Fri Jan 12 17:31:17 2024
  read: IOPS=193k, BW=754MiB/s (791MB/s)(44.2GiB/60001msec)
    slat (usec): min=3, max=7844, avg=18.91, stdev=49.47
    clat (usec): min=270, max=18426, avg=5284.86, stdev=2078.38
     lat (usec): min=274, max=18436, avg=5304.03, stdev=2086.26
    clat percentiles (usec):
     |  1.00th=[ 3130],  5.00th=[ 3392], 10.00th=[ 3490], 20.00th=[ 3654],
     | 30.00th=[ 3785], 40.00th=[ 3916], 50.00th=[ 4146], 60.00th=[ 4686],
     | 70.00th=[ 6587], 80.00th=[ 7373], 90.00th=[ 8094], 95.00th=[ 9110],
     | 99.00th=[11469], 99.50th=[11731], 99.90th=[12387], 99.95th=[13960],
     | 99.99th=[15664]
   bw (  KiB/s): min=375800, max=1175536, per=100.00%, avg=773751.06, stdev=54381.75, samples=476
   iops        : min=93950, max=293884, avg=193437.60, stdev=13595.45, samples=476
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=44.13%, 10=52.15%, 20=3.72%
  cpu          : usr=11.09%, sys=35.39%, ctx=1226115, majf=0, minf=1076
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=11579871,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=754MiB/s (791MB/s), 754MiB/s-754MiB/s (791MB/s-791MB/s), io=44.2GiB (47.4GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4k) read:  read: IOPS=193k, BW=754MiB/s (791MB/s)(44.2GiB/60001msec)


===Fio: workload=read, time=60, iodepth=256, bs=16k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j2: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j3: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j4: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 260691481 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 263747255 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 266775947 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7571: Fri Jan 12 17:32:20 2024
  read: IOPS=122k, BW=1910MiB/s (2002MB/s)(112GiB/60002msec)
    slat (usec): min=4, max=8895, avg=30.42, stdev=81.57
    clat (usec): min=554, max=24457, avg=8345.17, stdev=2776.82
     lat (usec): min=564, max=24513, avg=8375.94, stdev=2787.23
    clat percentiles (usec):
     |  1.00th=[ 4948],  5.00th=[ 5473], 10.00th=[ 5800], 20.00th=[ 6325],
     | 30.00th=[ 6652], 40.00th=[ 6849], 50.00th=[ 7046], 60.00th=[ 7832],
     | 70.00th=[ 9503], 80.00th=[10683], 90.00th=[12256], 95.00th=[13698],
     | 99.00th=[19268], 99.50th=[20579], 99.90th=[21627], 99.95th=[22152],
     | 99.99th=[22938]
   bw (  MiB/s): min=  796, max= 2976, per=100.00%, avg=1913.11, stdev=122.73, samples=476
   iops        : min=50976, max=190478, avg=122438.73, stdev=7854.77, samples=476
  lat (usec)   : 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.01%, 10=74.43%, 20=24.84%, 50=0.72%
  cpu          : usr=8.65%, sys=29.84%, ctx=2393532, majf=0, minf=4151
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=7332783,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=1910MiB/s (2002MB/s), 1910MiB/s-1910MiB/s (2002MB/s-2002MB/s), io=112GiB (120GB), run=60002-60002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=16k) read:  read: IOPS=122k, BW=1910MiB/s (2002MB/s)(112GiB/60002msec)


===Fio: workload=read, time=60, iodepth=256, bs=64k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j2: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j3: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j4: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 268684995 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 270232611 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 271883711 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7620: Fri Jan 12 17:33:22 2024
  read: IOPS=40.1k, BW=2504MiB/s (2625MB/s)(147GiB/60006msec)
    slat (usec): min=5, max=108241, avg=97.37, stdev=197.07
    clat (msec): min=2, max=162, avg=25.45, stdev= 9.85
     lat (msec): min=2, max=162, avg=25.54, stdev= 9.89
    clat percentiles (msec):
     |  1.00th=[   17],  5.00th=[   18], 10.00th=[   18], 20.00th=[   19],
     | 30.00th=[   19], 40.00th=[   20], 50.00th=[   22], 60.00th=[   25],
     | 70.00th=[   28], 80.00th=[   34], 90.00th=[   37], 95.00th=[   40],
     | 99.00th=[   65], 99.50th=[   65], 99.90th=[   95], 99.95th=[   96],
     | 99.99th=[  140]
   bw (  MiB/s): min=  875, max= 3651, per=100.00%, avg=2504.64, stdev=187.13, samples=476
   iops        : min=14010, max=58422, avg=40073.96, stdev=2994.10, samples=476
  lat (msec)   : 4=0.01%, 10=0.04%, 20=47.58%, 50=49.23%, 100=3.14%
  lat (msec)   : 250=0.01%
  cpu          : usr=4.34%, sys=14.21%, ctx=2421823, majf=0, minf=16433
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=2403781,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=2504MiB/s (2625MB/s), 2504MiB/s-2504MiB/s (2625MB/s-2625MB/s), io=147GiB (158GB), run=60006-60006msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=64k) read:  read: IOPS=40.1k, BW=2504MiB/s (2625MB/s)(147GiB/60006msec)


===Fio: workload=randread, time=60, iodepth=256, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 274118322 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 277736087 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 282070933 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7670: Fri Jan 12 17:34:25 2024
  read: IOPS=188k, BW=734MiB/s (770MB/s)(43.0GiB/60001msec)
    slat (usec): min=3, max=8961, avg=19.11, stdev=51.66
    clat (usec): min=349, max=27723, avg=5426.64, stdev=2251.71
     lat (usec): min=355, max=27734, avg=5446.01, stdev=2260.20
    clat percentiles (usec):
     |  1.00th=[ 3621],  5.00th=[ 3851], 10.00th=[ 4015], 20.00th=[ 4146],
     | 30.00th=[ 4228], 40.00th=[ 4359], 50.00th=[ 4424], 60.00th=[ 4555],
     | 70.00th=[ 4883], 80.00th=[ 7504], 90.00th=[ 8291], 95.00th=[ 9110],
     | 99.00th=[13042], 99.50th=[17433], 99.90th=[25035], 99.95th=[25822],
     | 99.99th=[26608]
   bw (  KiB/s): min=216912, max=1064288, per=100.00%, avg=752325.31, stdev=49934.26, samples=476
   iops        : min=54228, max=266072, avg=188081.31, stdev=12483.57, samples=476
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=10.10%, 10=86.94%, 20=2.57%, 50=0.39%
  cpu          : usr=12.29%, sys=34.60%, ctx=1222416, majf=0, minf=1492
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=11277790,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=734MiB/s (770MB/s), 734MiB/s-734MiB/s (770MB/s-770MB/s), io=43.0GiB (46.2GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4k) randread:  read: IOPS=188k, BW=734MiB/s (770MB/s)(43.0GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=256, bs=16k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1997 MiB read, 0.000 read amp, 285418539 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1999 MiB read, 0.000 read amp, 288143388 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2001 MiB read, 0.000 read amp, 291045741 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7720: Fri Jan 12 17:35:27 2024
  read: IOPS=111k, BW=1734MiB/s (1818MB/s)(102GiB/60002msec)
    slat (usec): min=4, max=4461, avg=33.23, stdev=96.73
    clat (usec): min=614, max=30835, avg=9193.44, stdev=3419.28
     lat (usec): min=640, max=30841, avg=9227.02, stdev=3431.97
    clat percentiles (usec):
     |  1.00th=[ 5538],  5.00th=[ 5866], 10.00th=[ 6128], 20.00th=[ 6456],
     | 30.00th=[ 6783], 40.00th=[ 7046], 50.00th=[ 7439], 60.00th=[ 8848],
     | 70.00th=[10945], 80.00th=[12518], 90.00th=[13829], 95.00th=[15401],
     | 99.00th=[19530], 99.50th=[21890], 99.90th=[23987], 99.95th=[25035],
     | 99.99th=[28967]
   bw (  MiB/s): min=  790, max= 2622, per=100.00%, avg=1734.54, stdev=122.14, samples=476
   iops        : min=50622, max=167823, avg=111010.34, stdev=7817.08, samples=476
  lat (usec)   : 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.01%, 10=65.67%, 20=33.49%, 50=0.83%
  cpu          : usr=9.19%, sys=28.78%, ctx=1995764, majf=0, minf=4144
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=6656921,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=1734MiB/s (1818MB/s), 1734MiB/s-1734MiB/s (1818MB/s-1818MB/s), io=102GiB (109GB), run=60002-60002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=16k) randread:  read: IOPS=111k, BW=1734MiB/s (1818MB/s)(102GiB/60002msec)


===Fio: workload=randread, time=60, iodepth=256, bs=64k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 4298 MiB read, 0.000 read amp, 293220489 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 294580653 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5001 MiB read, 0.000 read amp, 296155581 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=7773: Fri Jan 12 17:36:29 2024
  read: IOPS=37.3k, BW=2329MiB/s (2442MB/s)(136GiB/60011msec)
    slat (usec): min=5, max=324060, avg=104.61, stdev=290.29
    clat (msec): min=2, max=371, avg=27.36, stdev=10.01
     lat (msec): min=2, max=371, avg=27.47, stdev=10.04
    clat percentiles (msec):
     |  1.00th=[   18],  5.00th=[   18], 10.00th=[   18], 20.00th=[   19],
     | 30.00th=[   20], 40.00th=[   23], 50.00th=[   24], 60.00th=[   28],
     | 70.00th=[   34], 80.00th=[   36], 90.00th=[   39], 95.00th=[   45],
     | 99.00th=[   55], 99.50th=[   59], 99.90th=[   70], 99.95th=[   71],
     | 99.99th=[  347]
   bw (  MiB/s): min=  965, max= 3575, per=100.00%, avg=2330.20, stdev=152.14, samples=480
   iops        : min=15453, max=57212, avg=37282.43, stdev=2434.30, samples=480
  lat (msec)   : 4=0.01%, 10=0.01%, 20=32.97%, 50=64.68%, 100=2.33%
  lat (msec)   : 500=0.01%
  cpu          : usr=4.29%, sys=12.53%, ctx=2276650, majf=0, minf=16440
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=2236371,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=2329MiB/s (2442MB/s), 2329MiB/s-2329MiB/s (2442MB/s-2442MB/s), io=136GiB (147GB), run=60011-60011msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=64k) randread:  read: IOPS=37.3k, BW=2329MiB/s (2442MB/s)(136GiB/60011msec)
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 4999 MiB read, 0.000 read amp, 297570599 total
[0mumount: /mnt/fsbench: not mounted.
NQN:nqn.2016-06.io.spdk:cnode1 disconnected 1 controller(s)
+ perl -lane 'print if s/^RESULT: //' /home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T16:59:27.lsvd-multi.rssd2.txt
+ tee -a /home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T16:59:27.lsvd-multi.rssd2.txt
Fio (disks=4, iodepth=256; bs=4ki) randread:  read: IOPS=173k, BW=674MiB/s (707MB/s)(118GiB/180001msec)
Fio (disks=1, iodepth=128; bs=4ki) randread:  read: IOPS=64.4k, BW=252MiB/s (264MB/s)(14.7GiB/60001msec)
Fio (disks=2, iodepth=128; bs=4ki) randread:  read: IOPS=128k, BW=501MiB/s (525MB/s)(29.3GiB/60001msec)
Fio (disks=3, iodepth=128; bs=4ki) randread:  read: IOPS=161k, BW=628MiB/s (658MB/s)(36.8GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4ki) randread:  read: IOPS=175k, BW=683MiB/s (716MB/s)(40.0GiB/60001msec)
Fio (disks=1, iodepth=128; bs=4ki) read:  read: IOPS=76.5k, BW=299MiB/s (313MB/s)(17.5GiB/60001msec)
Fio (disks=2, iodepth=128; bs=4ki) read:  read: IOPS=139k, BW=543MiB/s (569MB/s)(31.8GiB/60001msec)
Fio (disks=3, iodepth=128; bs=4ki) read:  read: IOPS=182k, BW=712MiB/s (746MB/s)(41.7GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4ki) read:  read: IOPS=201k, BW=787MiB/s (825MB/s)(46.1GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4ki) randread:  read: IOPS=166k, BW=647MiB/s (678MB/s)(18.9GiB/30001msec)
Fio (disks=4, iodepth=128; bs=8ki) randread:  read: IOPS=156k, BW=1221MiB/s (1280MB/s)(35.8GiB/30001msec)
Fio (disks=4, iodepth=128; bs=16ki) randread:  read: IOPS=114k, BW=1775MiB/s (1862MB/s)(52.0GiB/30002msec)
Fio (disks=4, iodepth=128; bs=32ki) randread:  read: IOPS=65.6k, BW=2049MiB/s (2149MB/s)(60.0GiB/30005msec)
Fio (disks=4, iodepth=128; bs=64ki) randread:  read: IOPS=39.2k, BW=2451MiB/s (2570MB/s)(71.8GiB/30007msec)
Fio (disks=4, iodepth=128; bs=4ki) read:  read: IOPS=197k, BW=769MiB/s (806MB/s)(22.5GiB/30001msec)
Fio (disks=4, iodepth=128; bs=8ki) read:  read: IOPS=184k, BW=1435MiB/s (1504MB/s)(42.0GiB/30002msec)
Fio (disks=4, iodepth=128; bs=16ki) read:  read: IOPS=126k, BW=1969MiB/s (2065MB/s)(57.7GiB/30001msec)
Fio (disks=4, iodepth=128; bs=32ki) read:  read: IOPS=76.0k, BW=2376MiB/s (2492MB/s)(69.6GiB/30003msec)
Fio (disks=4, iodepth=128; bs=64ki) read:  read: IOPS=45.2k, BW=2825MiB/s (2962MB/s)(82.8GiB/30006msec)
Fio (disks=4, iodepth=256; bs=4k) randread:  read: IOPS=170k, BW=666MiB/s (698MB/s)(39.0GiB/60001msec)
Fio (disks=4, iodepth=256; bs=4k) read:  read: IOPS=194k, BW=758MiB/s (795MB/s)(44.4GiB/60001msec)
Fio (disks=4, iodepth=1; bs=4k) randread:  read: IOPS=30.8k, BW=120MiB/s (126MB/s)(7213MiB/60001msec)
Fio (disks=4, iodepth=32; bs=4k) randread:  read: IOPS=173k, BW=675MiB/s (708MB/s)(39.5GiB/60001msec)
Fio (disks=4, iodepth=64; bs=4k) randread:  read: IOPS=178k, BW=695MiB/s (728MB/s)(40.7GiB/60002msec)
Fio (disks=4, iodepth=128; bs=4k) randread:  read: IOPS=172k, BW=671MiB/s (704MB/s)(39.3GiB/60001msec)
Fio (disks=4, iodepth=1; bs=4k) read:  read: IOPS=32.0k, BW=125MiB/s (131MB/s)(7496MiB/60001msec)
Fio (disks=4, iodepth=32; bs=4k) read:  read: IOPS=186k, BW=726MiB/s (761MB/s)(42.5GiB/60001msec)
Fio (disks=4, iodepth=64; bs=4k) read:  read: IOPS=199k, BW=778MiB/s (816MB/s)(45.6GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4k) read:  read: IOPS=190k, BW=744MiB/s (780MB/s)(43.6GiB/60001msec)
Fio (disks=4, iodepth=256; bs=4k) read:  read: IOPS=193k, BW=754MiB/s (791MB/s)(44.2GiB/60001msec)
Fio (disks=4, iodepth=256; bs=16k) read:  read: IOPS=122k, BW=1910MiB/s (2002MB/s)(112GiB/60002msec)
Fio (disks=4, iodepth=256; bs=64k) read:  read: IOPS=40.1k, BW=2504MiB/s (2625MB/s)(147GiB/60006msec)
Fio (disks=4, iodepth=256; bs=4k) randread:  read: IOPS=188k, BW=734MiB/s (770MB/s)(43.0GiB/60001msec)
Fio (disks=4, iodepth=256; bs=16k) randread:  read: IOPS=111k, BW=1734MiB/s (1818MB/s)(102GiB/60002msec)
Fio (disks=4, iodepth=256; bs=64k) randread:  read: IOPS=37.3k, BW=2329MiB/s (2442MB/s)(136GiB/60011msec)
+ cleanup_nvmf
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ scripts/rpc.py spdk_kill_instance SIGTERM
[1m[36m[INFO liblsvd.cc:287 rbd_close] Closing image lsvd-benchmark.multi.4
[0m[1m[36m[INFO liblsvd.cc:287 rbd_close] Closing image lsvd-benchmark.multi.3
[0m+ exit
[1m[36m[INFO liblsvd.cc:287 rbd_close] Closing image lsvd-benchmark.multi.2
[0m[1m[36m[INFO liblsvd.cc:287 rbd_close] Closing image lsvd-benchmark.multi.1
[0m[35m[DBG shared_read_cache.cc:808 report_cache_stats] cache stats reporter exiting
[0mflush thread (7fc21bfff640) exiting
flush thread (7fc245ff3640) exiting
flush thread (7fc26b7fe640) exiting
flush thread (7fc27cff1640) exiting
+ ulimit -c
unlimited
+ '[' -z triple-hdd ']'
+ pool_name=triple-hdd
++ date +%FT%T
+ cur_time=2024-01-12T17:36:41
+ default_cache_size=128849018880
+ cache_size=128849018880
++ git rev-parse --show-toplevel
+ lsvd_dir=/home/isaackhor/code/lsvd-rbd
++ ip addr
++ perl -lane 'print $1 if /inet (10\.1\.[0-9.]+)\/24/'
++ head -n 1
+ gw_ip=10.1.0.5
+ client_ip=10.1.0.6
+ rcache=/mnt/nvme/
+ wlog=/mnt/nvme-remote/
+ cache_size_gb=120
+ outfile=/home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T17:36:41.lsvd-multi.triple-hdd.txt
+ echo 'Running gateway on 10.1.0.5, client on 10.1.0.6'
Running gateway on 10.1.0.5, client on 10.1.0.6
+ imgname=lsvd-benchmark
+ imgsize=10g
+ blocksize=4096
+ source /home/isaackhor/code/lsvd-rbd/experiments/common.bash
++ set -xeuo pipefail
++ '[' 0 -ne 0 ']'
+ echo '===Building LSVD...'
===Building LSVD...
+ cd /home/isaackhor/code/lsvd-rbd
+ make clean
make[1]: Entering directory '/home/isaackhor/code/lsvd-rbd/atc2024'
latexmk -C
Rc files read:
  /etc/LatexMk
  latexmkrc
Latexmk: This is Latexmk, John Collins, 20 November 2021, version: 4.76.
rm -f main.pdf
make[1]: Leaving directory '/home/isaackhor/code/lsvd-rbd/atc2024'
+ make -j20 release
CC objects.cc
CC translate.cc
CC io.cc
CC img_reader.cc
CC config.cc
CC mkcache.cc
CC nvme.cc
CC write_cache.cc
CC file_backend.cc
CC shared_read_cache.cc
CC rados_backend.cc
CC lsvd_debug.cc
CC liblsvd.cc
CC image.cc
CC imgtool.cc
CC thick-image.cc
In file included from translate.cc:28:
./extent.h:160:13: warning: implicit truncation from 'int' to a one-bit wide bit-field changes value from 1 to -1 [-Wsingle-bit-bitfield-constant-conversion]
  160 |         s.d = 1; // new extents are dirty
      |             ^ ~
./extent.h:520:11: note: in instantiation of member function 'extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>::_extent' requested here
  520 |         T _e(base, limit - base, e);
      |           ^
./extent.h:671:9: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::_update' requested here
  671 |         _update(base, limit, e, false, nullptr);
      |         ^
translate.cc:451:18: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::update' requested here
  451 |             map->update(m.lba, m.lba + m.len,
      |                  ^
In file included from translate.cc:28:
./extent.h:174:13: warning: implicit truncation from 'int' to a one-bit wide bit-field changes value from 1 to -1 [-Wsingle-bit-bitfield-constant-conversion]
  174 |         s.d = 1; // dirty
      |             ^ ~
./extent.h:553:21: note: in instantiation of member function 'extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>::relimit' requested here
  553 |                 it->relimit(base);
      |                     ^
./extent.h:671:9: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::_update' requested here
  671 |         _update(base, limit, e, false, nullptr);
      |         ^
translate.cc:451:18: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::update' requested here
  451 |             map->update(m.lba, m.lba + m.len,
      |                  ^
In file included from translate.cc:28:
./extent.h:185:13: warning: implicit truncation from 'int' to a one-bit wide bit-field changes value from 1 to -1 [-Wsingle-bit-bitfield-constant-conversion]
  185 |         s.d = 1; // dirty
      |             ^ ~
./extent.h:601:21: note: in instantiation of member function 'extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>::rebase' requested here
  601 |                 it->rebase(limit);
      |                     ^
./extent.h:671:9: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::_update' requested here
  671 |         _update(base, limit, e, false, nullptr);
      |         ^
translate.cc:451:18: note: in instantiation of member function 'extmap::extmap<extmap::_extent<extmap::_lba2obj, long, extmap::obj_offset>, long, extmap::obj_offset>::update' requested here
  451 |             map->update(m.lba, m.lba + m.len,
      |                  ^
3 warnings generated.
LD liblsvd.so
LD imgtool
LD thick-image
+ mkdir -p /home/isaackhor/code/lsvd-rbd/test/baklibs/
+ cp /home/isaackhor/code/lsvd-rbd/liblsvd.so /home/isaackhor/code/lsvd-rbd/test/baklibs/liblsvd.so.2024-01-12T17:36:41
+ create_lsvd_thick triple-hdd lsvd-benchmark.multi.1 10g
+ local pool=triple-hdd
+ local img=lsvd-benchmark.multi.1
+ local size=10g
+ cd /home/isaackhor/code/lsvd-rbd
+ create_lsvd_thick triple-hdd lsvd-benchmark.multi.2 10g
+ ./remove_objs.py triple-hdd lsvd-benchmark.multi.1
+ local pool=triple-hdd
+ local img=lsvd-benchmark.multi.2
+ local size=10g
+ cd /home/isaackhor/code/lsvd-rbd
+ ./remove_objs.py triple-hdd lsvd-benchmark.multi.2
+ create_lsvd_thick triple-hdd lsvd-benchmark.multi.3 10g
+ wait
+ local pool=triple-hdd
+ local img=lsvd-benchmark.multi.3
+ local size=10g
+ create_lsvd_thick triple-hdd lsvd-benchmark.multi.4 10g
+ cd /home/isaackhor/code/lsvd-rbd
+ ./remove_objs.py triple-hdd lsvd-benchmark.multi.3
+ local pool=triple-hdd
+ local img=lsvd-benchmark.multi.4
+ local size=10g
+ cd /home/isaackhor/code/lsvd-rbd
+ ./remove_objs.py triple-hdd lsvd-benchmark.multi.4
Removing all objects from pool triple-hdd with prefix lsvd-benchmark.multi.2
+Removing all objects from pool triple-hdd with prefix lsvd-benchmark.multi.1
+Removing all objects from pool triple-hdd with prefix lsvd-benchmark.multi.3
+Removing all objects from pool triple-hdd with prefix lsvd-benchmark.multi.4
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Removed 0/55761 objects
+
Removed 0/55761 objects
+ ./thick-image --size=10g triple-hdd/lsvd-benchmark.multi.2
+
Removed 0/55761 objects
+ ./thick-image --size=10g triple-hdd/lsvd-benchmark.multi.1
+
Removed 0/55761 objects
+ ./thick-image --size=10g triple-hdd/lsvd-benchmark.multi.3
+ ./thick-image --size=10g triple-hdd/lsvd-benchmark.multi.4
Thick provisioning: 1% complete...Thick provisioning: 1% complete...Thick provisioning: 1% complete...Thick provisioning: 1% complete...Thick provisioning: 2% complete...Thick provisioning: 2% complete...Thick provisioning: 2% complete...Thick provisioning: 2% complete...Thick provisioning: 3% complete...Thick provisioning: 3% complete...Thick provisioning: 3% complete...Thick provisioning: 3% complete...Thick provisioning: 4% complete...Thick provisioning: 4% complete...Thick provisioning: 4% complete...Thick provisioning: 4% complete...Thick provisioning: 5% complete...Thick provisioning: 5% complete...Thick provisioning: 5% complete...Thick provisioning: 5% complete...Thick provisioning: 6% complete...Thick provisioning: 6% complete...Thick provisioning: 6% complete...Thick provisioning: 6% complete...Thick provisioning: 7% complete...Thick provisioning: 8% complete...Thick provisioning: 9% complete...Thick provisioning: 7% complete...Thick provisioning: 10% complete...Thick provisioning: 8% complete...Thick provisioning: 7% complete...Thick provisioning: 9% complete...Thick provisioning: 11% complete...Thick provisioning: 7% complete...Thick provisioning: 8% complete...Thick provisioning: 10% complete...Thick provisioning: 8% complete...Thick provisioning: 12% complete...Thick provisioning: 11% complete...Thick provisioning: 9% complete...Thick provisioning: 9% complete...Thick provisioning: 13% complete...Thick provisioning: 10% complete...Thick provisioning: 10% complete...Thick provisioning: 12% complete...Thick provisioning: 14% complete...Thick provisioning: 11% complete...Thick provisioning: 15% complete...Thick provisioning: 13% complete...Thick provisioning: 11% complete...Thick provisioning: 14% complete...Thick provisioning: 12% complete...Thick provisioning: 16% complete...Thick provisioning: 12% complete...Thick provisioning: 13% complete...Thick provisioning: 17% complete...Thick provisioning: 13% complete...Thick provisioning: 15% complete...Thick provisioning: 18% complete...Thick provisioning: 14% complete...Thick provisioning: 14% complete...Thick provisioning: 16% complete...Thick provisioning: 19% complete...Thick provisioning: 15% complete...Thick provisioning: 15% complete...Thick provisioning: 17% complete...Thick provisioning: 20% complete...Thick provisioning: 16% complete...Thick provisioning: 16% complete...Thick provisioning: 18% complete...Thick provisioning: 21% complete...Thick provisioning: 17% complete...Thick provisioning: 17% complete...Thick provisioning: 18% complete...Thick provisioning: 19% complete...Thick provisioning: 22% complete...Thick provisioning: 18% complete...Thick provisioning: 20% complete...Thick provisioning: 23% complete...Thick provisioning: 19% complete...Thick provisioning: 21% complete...Thick provisioning: 22% complete...Thick provisioning: 20% complete...Thick provisioning: 21% complete...Thick provisioning: 22% complete...Thick provisioning: 23% complete...Thick provisioning: 23% complete...Thick provisioning: 24% complete...Thick provisioning: 19% complete...Thick provisioning: 25% complete...Thick provisioning: 24% complete...Thick provisioning: 20% complete...Thick provisioning: 24% complete...Thick provisioning: 25% complete...Thick provisioning: 21% complete...Thick provisioning: 26% complete...Thick provisioning: 25% complete...Thick provisioning: 22% complete...Thick provisioning: 27% complete...Thick provisioning: 26% complete...Thick provisioning: 26% complete...Thick provisioning: 23% complete...Thick provisioning: 27% complete...Thick provisioning: 27% complete...Thick provisioning: 24% complete...Thick provisioning: 25% complete...Thick provisioning: 28% complete...Thick provisioning: 29% complete...Thick provisioning: 26% complete...Thick provisioning: 28% complete...Thick provisioning: 30% complete...Thick provisioning: 29% complete...Thick provisioning: 31% complete...Thick provisioning: 28% complete...Thick provisioning: 32% complete...Thick provisioning: 30% complete...Thick provisioning: 27% complete...Thick provisioning: 29% complete...Thick provisioning: 33% complete...Thick provisioning: 31% complete...Thick provisioning: 28% complete...Thick provisioning: 30% complete...Thick provisioning: 34% complete...Thick provisioning: 32% complete...Thick provisioning: 29% complete...Thick provisioning: 35% complete...Thick provisioning: 31% complete...Thick provisioning: 33% complete...Thick provisioning: 30% complete...Thick provisioning: 36% complete...Thick provisioning: 32% complete...Thick provisioning: 34% complete...Thick provisioning: 31% complete...Thick provisioning: 33% complete...Thick provisioning: 37% complete...Thick provisioning: 32% complete...Thick provisioning: 35% complete...Thick provisioning: 34% complete...Thick provisioning: 38% complete...Thick provisioning: 36% complete...Thick provisioning: 39% complete...Thick provisioning: 33% complete...Thick provisioning: 35% complete...Thick provisioning: 40% complete...Thick provisioning: 37% complete...Thick provisioning: 34% complete...Thick provisioning: 36% complete...Thick provisioning: 41% complete...Thick provisioning: 38% complete...Thick provisioning: 35% complete...Thick provisioning: 37% complete...Thick provisioning: 42% complete...Thick provisioning: 36% complete...Thick provisioning: 39% complete...Thick provisioning: 38% complete...Thick provisioning: 43% complete...Thick provisioning: 44% complete...Thick provisioning: 37% complete...Thick provisioning: 40% complete...Thick provisioning: 38% complete...Thick provisioning: 39% complete...Thick provisioning: 45% complete...Thick provisioning: 40% complete...Thick provisioning: 41% complete...Thick provisioning: 39% complete...Thick provisioning: 46% complete...Thick provisioning: 41% complete...Thick provisioning: 40% complete...Thick provisioning: 42% complete...Thick provisioning: 47% complete...Thick provisioning: 42% complete...Thick provisioning: 41% complete...Thick provisioning: 48% complete...Thick provisioning: 43% complete...Thick provisioning: 43% complete...Thick provisioning: 42% complete...Thick provisioning: 44% complete...Thick provisioning: 49% complete...Thick provisioning: 44% complete...Thick provisioning: 43% complete...Thick provisioning: 45% complete...Thick provisioning: 50% complete...Thick provisioning: 45% complete...Thick provisioning: 44% complete...Thick provisioning: 46% complete...Thick provisioning: 51% complete...Thick provisioning: 52% complete...Thick provisioning: 45% complete...Thick provisioning: 47% complete...Thick provisioning: 53% complete...Thick provisioning: 46% complete...Thick provisioning: 46% complete...Thick provisioning: 48% complete...Thick provisioning: 47% complete...Thick provisioning: 54% complete...Thick provisioning: 47% complete...Thick provisioning: 49% complete...Thick provisioning: 48% complete...Thick provisioning: 55% complete...Thick provisioning: 50% complete...Thick provisioning: 49% complete...Thick provisioning: 48% complete...Thick provisioning: 56% complete...Thick provisioning: 51% complete...Thick provisioning: 49% complete...Thick provisioning: 50% complete...Thick provisioning: 50% complete...Thick provisioning: 52% complete...Thick provisioning: 51% complete...Thick provisioning: 57% complete...Thick provisioning: 51% complete...Thick provisioning: 53% complete...Thick provisioning: 58% complete...Thick provisioning: 52% complete...Thick provisioning: 52% complete...Thick provisioning: 54% complete...Thick provisioning: 59% complete...Thick provisioning: 53% complete...Thick provisioning: 55% complete...Thick provisioning: 60% complete...Thick provisioning: 53% complete...Thick provisioning: 56% complete...Thick provisioning: 54% complete...Thick provisioning: 61% complete...Thick provisioning: 54% complete...Thick provisioning: 55% complete...Thick provisioning: 55% complete...Thick provisioning: 62% complete...Thick provisioning: 57% complete...Thick provisioning: 63% complete...Thick provisioning: 56% complete...Thick provisioning: 56% complete...Thick provisioning: 58% complete...Thick provisioning: 57% complete...Thick provisioning: 64% complete...Thick provisioning: 59% complete...Thick provisioning: 57% complete...Thick provisioning: 58% complete...Thick provisioning: 60% complete...Thick provisioning: 65% complete...Thick provisioning: 58% complete...Thick provisioning: 61% complete...Thick provisioning: 66% complete...Thick provisioning: 59% complete...Thick provisioning: 59% complete...Thick provisioning: 62% complete...Thick provisioning: 60% complete...Thick provisioning: 60% complete...Thick provisioning: 67% complete...Thick provisioning: 61% complete...Thick provisioning: 63% complete...Thick provisioning: 61% complete...Thick provisioning: 68% complete...Thick provisioning: 64% complete...Thick provisioning: 62% complete...Thick provisioning: 69% complete...Thick provisioning: 62% complete...Thick provisioning: 65% complete...Thick provisioning: 70% complete...Thick provisioning: 63% complete...Thick provisioning: 63% complete...Thick provisioning: 66% complete...Thick provisioning: 64% complete...Thick provisioning: 67% complete...Thick provisioning: 64% complete...Thick provisioning: 71% complete...Thick provisioning: 65% complete...Thick provisioning: 72% complete...Thick provisioning: 65% complete...Thick provisioning: 68% complete...Thick provisioning: 66% complete...Thick provisioning: 73% complete...Thick provisioning: 66% complete...Thick provisioning: 69% complete...Thick provisioning: 67% complete...Thick provisioning: 74% complete...Thick provisioning: 67% complete...Thick provisioning: 70% complete...Thick provisioning: 75% complete...Thick provisioning: 68% complete...Thick provisioning: 68% complete...Thick provisioning: 71% complete...Thick provisioning: 76% complete...Thick provisioning: 69% complete...Thick provisioning: 77% complete...Thick provisioning: 69% complete...Thick provisioning: 70% complete...Thick provisioning: 72% complete...Thick provisioning: 70% complete...Thick provisioning: 71% complete...Thick provisioning: 78% complete...Thick provisioning: 73% complete...Thick provisioning: 71% complete...Thick provisioning: 72% complete...Thick provisioning: 79% complete...Thick provisioning: 74% complete...Thick provisioning: 80% complete...Thick provisioning: 72% complete...Thick provisioning: 73% complete...Thick provisioning: 75% complete...Thick provisioning: 81% complete...Thick provisioning: 73% complete...Thick provisioning: 74% complete...Thick provisioning: 82% complete...Thick provisioning: 76% complete...Thick provisioning: 74% complete...Thick provisioning: 75% complete...Thick provisioning: 77% complete...Thick provisioning: 83% complete...Thick provisioning: 75% complete...Thick provisioning: 76% complete...Thick provisioning: 78% complete...Thick provisioning: 84% complete...Thick provisioning: 76% complete...Thick provisioning: 77% complete...Thick provisioning: 79% complete...Thick provisioning: 85% complete...Thick provisioning: 77% complete...Thick provisioning: 78% complete...Thick provisioning: 80% complete...Thick provisioning: 86% complete...Thick provisioning: 78% complete...Thick provisioning: 81% complete...Thick provisioning: 79% complete...Thick provisioning: 87% complete...Thick provisioning: 88% complete...Thick provisioning: 80% complete...Thick provisioning: 82% complete...Thick provisioning: 79% complete...Thick provisioning: 80% complete...Thick provisioning: 81% complete...Thick provisioning: 89% complete...Thick provisioning: 83% complete...Thick provisioning: 81% complete...Thick provisioning: 82% complete...Thick provisioning: 90% complete...Thick provisioning: 82% complete...Thick provisioning: 84% complete...Thick provisioning: 85% complete...Thick provisioning: 91% complete...Thick provisioning: 83% complete...Thick provisioning: 83% complete...Thick provisioning: 86% complete...Thick provisioning: 84% complete...Thick provisioning: 84% complete...Thick provisioning: 92% complete...Thick provisioning: 85% complete...Thick provisioning: 85% complete...Thick provisioning: 86% complete...Thick provisioning: 87% complete...Thick provisioning: 93% complete...Thick provisioning: 86% complete...Thick provisioning: 94% complete...Thick provisioning: 88% complete...Thick provisioning: 87% complete...Thick provisioning: 87% complete...Thick provisioning: 95% complete...Thick provisioning: 89% complete...Thick provisioning: 88% complete...Thick provisioning: 88% complete...Thick provisioning: 96% complete...Thick provisioning: 90% complete...Thick provisioning: 89% complete...Thick provisioning: 89% complete...Thick provisioning: 97% complete...Thick provisioning: 91% complete...Thick provisioning: 90% complete...Thick provisioning: 90% complete...Thick provisioning: 98% complete...Thick provisioning: 91% complete...Thick provisioning: 92% complete...Thick provisioning: 91% complete...Thick provisioning: 93% complete...Thick provisioning: 99% complete...Thick provisioning: 92% complete...Thick provisioning: 92% complete...Thick provisioning: 100% complete...Thick provisioning: 93% complete...Thick provisioning: 94% complete...Thick provisioning: 93% complete...Thick provisioning: 94% complete...Thick provisioning: 94% complete...Thick provisioning: 95% complete...Thick provisioning: 95% complete...Thick provisioning: 95% complete...Thick provisioning: 100% complete...done
Thick provisioning: 96% complete...+ rados -p triple-hdd stat lsvd-benchmark.multi.2
triple-hdd/lsvd-benchmark.multi.2 mtime 2024-01-12T17:38:22.000000+0000, size 4096
Thick provisioning: 96% complete...Thick provisioning: 96% complete...Thick provisioning: 97% complete...Thick provisioning: 97% complete...Thick provisioning: 97% complete...Thick provisioning: 98% complete...Thick provisioning: 98% complete...Thick provisioning: 98% complete...Thick provisioning: 99% complete...Thick provisioning: 99% complete...Thick provisioning: 99% complete...Thick provisioning: 100% complete...Thick provisioning: 100% complete...Thick provisioning: 100% complete...Thick provisioning: 100% complete...done
Thick provisioning: 100% complete...done
+ rados -p triple-hdd stat lsvd-benchmark.multi.1
Thick provisioning: 100% complete...done
+ rados -p triple-hdd stat lsvd-benchmark.multi.3
+ rados -p triple-hdd stat lsvd-benchmark.multi.4
triple-hdd/lsvd-benchmark.multi.1 mtime 2024-01-12T17:38:25.000000+0000, size 4096
triple-hdd/lsvd-benchmark.multi.3 mtime 2024-01-12T17:38:25.000000+0000, size 4096
triple-hdd/lsvd-benchmark.multi.4 mtime 2024-01-12T17:38:25.000000+0000, size 4096
+ kill_nvmf
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ scripts/rpc.py spdk_kill_instance SIGTERM
+ true
+ scripts/rpc.py spdk_kill_instance SIGKILL
+ true
+ pkill -f nvmf_tgt
+ true
+ pkill -f reactor_0
+ true
+ sleep 2
+ fstrim /mnt/nvme
+ launch_lsvd_gw_background /mnt/nvme/ /mnt/nvme-remote/ 128849018880
+ local rcache_root=/mnt/nvme/
+ local wlog_root=/mnt/nvme-remote/
+ local cache_size=128849018880
+ echo 4096
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ mkdir -p /mnt/nvme//lsvd-read/ /mnt/nvme-remote//lsvd-write/
+ export LSVD_RCACHE_DIR=/mnt/nvme//lsvd-read/
+ LSVD_RCACHE_DIR=/mnt/nvme//lsvd-read/
+ export LSVD_WCACHE_DIR=/mnt/nvme-remote//lsvd-write/
+ LSVD_WCACHE_DIR=/mnt/nvme-remote//lsvd-write/
+ export LSVD_GC_THRESHOLD=40
+ LSVD_GC_THRESHOLD=40
+ export LSVD_CACHE_SIZE=128849018880
+ LSVD_CACHE_SIZE=128849018880
+ rm -rf /mnt/nvme-remote//lsvd-write/1d5bd8bc-155c-4c01-ae6f-6f75e3aa914e.wcache /mnt/nvme-remote//lsvd-write/347196c9-2e6a-4c8f-89bb-ff9a2d684937.wcache /mnt/nvme-remote//lsvd-write/7d7b21ef-0c62-4f9f-86f7-8a11f7993dfa.wcache /mnt/nvme-remote//lsvd-write/ce9dbd0e-67a2-447b-8ff8-4e386d1605f7.wcache
+ sleep 5
+ LD_PRELOAD=/home/isaackhor/code/lsvd-rbd/liblsvd.so
+ ./build/bin/nvmf_tgt -m '[0,1,2,3]'
[2024-01-12 17:38:35.233447] Starting SPDK v23.09 git sha1 fb13eebf5 / DPDK 23.07.0 initialization...
[2024-01-12 17:38:35.233582] [ DPDK EAL parameters: nvmf --no-shconf -l 0,1,2,3 --huge-unlink --log-level=lib.eal:6 --log-level=lib.cryptodev:5 --log-level=user1:6 --iova-mode=pa --base-virtaddr=0x200000000000 --match-allocations --file-prefix=spdk_pid2826735 ]
TELEMETRY: No legacy callbacks, legacy socket not created
[2024-01-12 17:38:35.315414] app.c: 786:spdk_app_start: *NOTICE*: Total cores available: 4
[2024-01-12 17:38:35.425120] reactor.c: 937:reactor_run: *NOTICE*: Reactor started on core 1
[2024-01-12 17:38:35.425201] reactor.c: 937:reactor_run: *NOTICE*: Reactor started on core 2
[2024-01-12 17:38:35.425282] reactor.c: 937:reactor_run: *NOTICE*: Reactor started on core 3
[2024-01-12 17:38:35.425290] reactor.c: 937:reactor_run: *NOTICE*: Reactor started on core 0
+ configure_nvmf_common 10.1.0.5
+ local gateway_ip=10.1.0.5
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ scripts/rpc.py bdev_rbd_register_cluster rbd_cluster
rbd_cluster
+ scripts/rpc.py nvmf_create_transport -t TCP -u 16384 -m 8 -c 8192
[2024-01-12 17:38:41.004045] tcp.c: 656:nvmf_tcp_create: *NOTICE*: *** TCP Transport Init ***
+ scripts/rpc.py nvmf_create_subsystem nqn.2016-06.io.spdk:cnode1 -a -s SPDK00000000000001 -d SPDK_Controller1
+ scripts/rpc.py nvmf_subsystem_add_listener nqn.2016-06.io.spdk:cnode1 -t tcp -a 10.1.0.5 -s 9922
[2024-01-12 17:38:41.662684] tcp.c: 948:nvmf_tcp_listen: *NOTICE*: *** NVMe/TCP Target Listening on 10.1.0.5 port 9922 ***
+ add_rbd_img triple-hdd lsvd-benchmark.multi.1
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ local pool=triple-hdd
+ local img=lsvd-benchmark.multi.1
+ local bdev=bdev_lsvd-benchmark.multi.1
+ scripts/rpc.py bdev_rbd_create triple-hdd lsvd-benchmark.multi.1 4096 -c rbd_cluster -b bdev_lsvd-benchmark.multi.1
[1m[36m[INFO shared_read_cache.cc:692 sharded_cache] Initialising read cache of size 122880 MiB in 16 shards, 7680 MiB each
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_0 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_1 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_2 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_3 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_4 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_5 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_6 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_7 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_8 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_9 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_10 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_11 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_12 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_13 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_14 for the read cache
[0m[35m[DBG shared_read_cache.cc:432 shared_read_cache] Opening /mnt/nvme//lsvd-read//read_cache_shard_15 for the read cache
[0m[1m[36m[INFO image.cc:74 image_open] Creating write cache file /mnt/nvme-remote//lsvd-write//a21a87c2-ef8b-4baf-9ea2-e2b2f6aa4388.wcache
[0m[1m[36m[INFO liblsvd.cc:280 rbd_open] Opened image: lsvd-benchmark.multi.1, size 10737418240
[0m[35m[DBG translate.cc:1365 gc_thread] starting gc thread
[0m[2024-01-12 17:38:55.252537] bdev_rbd.c:1329:bdev_rbd_create: *NOTICE*: Add bdev_lsvd-benchmark.multi.1 rbd disk to lun
bdev_lsvd-benchmark.multi.1
+ scripts/rpc.py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 bdev_lsvd-benchmark.multi.1
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 1/2 hits, 0 MiB read, 1.778 read amp, 2 total
[0m+ add_rbd_img triple-hdd lsvd-benchmark.multi.2
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ local pool=triple-hdd
+ local img=lsvd-benchmark.multi.2
+ local bdev=bdev_lsvd-benchmark.multi.2
+ scripts/rpc.py bdev_rbd_create triple-hdd lsvd-benchmark.multi.2 4096 -c rbd_cluster -b bdev_lsvd-benchmark.multi.2
[1m[36m[INFO image.cc:74 image_open] Creating write cache file /mnt/nvme-remote//lsvd-write//dadf62cc-a4e5-484c-8f7c-4d420c84c560.wcache
[0m[1m[36m[INFO liblsvd.cc:280 rbd_open] Opened image: lsvd-benchmark.multi.2, size 10737418240
[0m[35m[DBG translate.cc:1365 gc_thread] starting gc thread
[0m[2024-01-12 17:38:56.819742] bdev_rbd.c:1329:bdev_rbd_create: *NOTICE*: Add bdev_lsvd-benchmark.multi.2 rbd disk to lun
bdev_lsvd-benchmark.multi.2
+ scripts/rpc.py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 bdev_lsvd-benchmark.multi.2
+ add_rbd_img triple-hdd lsvd-benchmark.multi.3
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ local pool=triple-hdd
+ local img=lsvd-benchmark.multi.3
+ local bdev=bdev_lsvd-benchmark.multi.3
+ scripts/rpc.py bdev_rbd_create triple-hdd lsvd-benchmark.multi.3 4096 -c rbd_cluster -b bdev_lsvd-benchmark.multi.3
[1m[36m[INFO image.cc:74 image_open] Creating write cache file /mnt/nvme-remote//lsvd-write//59836acc-facf-4f58-91d9-9227d7c088b9.wcache
[0m[1m[36m[INFO liblsvd.cc:280 rbd_open] Opened image: lsvd-benchmark.multi.3, size 10737418240
[0m[35m[DBG translate.cc:1365 gc_thread] starting gc thread
[0m[2024-01-12 17:38:58.340631] bdev_rbd.c:1329:bdev_rbd_create: *NOTICE*: Add bdev_lsvd-benchmark.multi.3 rbd disk to lun
bdev_lsvd-benchmark.multi.3
+ scripts/rpc.py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 bdev_lsvd-benchmark.multi.3
+ add_rbd_img triple-hdd lsvd-benchmark.multi.4
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ local pool=triple-hdd
+ local img=lsvd-benchmark.multi.4
+ local bdev=bdev_lsvd-benchmark.multi.4
+ scripts/rpc.py bdev_rbd_create triple-hdd lsvd-benchmark.multi.4 4096 -c rbd_cluster -b bdev_lsvd-benchmark.multi.4
[1m[36m[INFO image.cc:74 image_open] Creating write cache file /mnt/nvme-remote//lsvd-write//51ab91f8-f580-492a-9e6c-ecf99e3677ab.wcache
[0m[1m[36m[INFO liblsvd.cc:280 rbd_open] Opened image: lsvd-benchmark.multi.4, size 10737418240
[0m[35m[DBG translate.cc:1365 gc_thread] starting gc thread
[0m[2024-01-12 17:38:59.974546] bdev_rbd.c:1329:bdev_rbd_create: *NOTICE*: Add bdev_lsvd-benchmark.multi.4 rbd disk to lun
bdev_lsvd-benchmark.multi.4
+ scripts/rpc.py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 bdev_lsvd-benchmark.multi.4
+ trap 'cleanup_nvmf; exit' SIGINT SIGTERM EXIT
+ run_client_bench 10.1.0.6 /home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T17:36:41.lsvd-multi.triple-hdd.txt multi-client/client-bench-multi.bash read_entire_img=1
+ local client_ip=10.1.0.6
+ local outfile=/home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T17:36:41.lsvd-multi.triple-hdd.txt
+ local benchscript=multi-client/client-bench-multi.bash
+ local additional_args=read_entire_img=1
+ cd /home/isaackhor/code/lsvd-rbd/experiments
+ ssh 10.1.0.6 'mkdir -p /tmp/filebench; rm -rf /tmp/filebench/*'
+ scp ./filebench-workloads/fileserver.f ./filebench-workloads/oltp.f ./filebench-workloads/randomwrite.f ./filebench-workloads/varmail.f root@10.1.0.6:/tmp/filebench/
+ ssh 10.1.0.6 'bash -s gw_ip=10.1.0.5 read_entire_img=1'
+ tee -a /home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T17:36:41.lsvd-multi.triple-hdd.txt
===Starting client benchmark

NQN:nqn.2016-06.io.spdk:cnode1 disconnected 0 controller(s)
device: nvme1
Node                  SN                   Model                                    Namespace Usage                      Format           FW Rev  
--------------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------
/dev/nvme0n1          PHM27522000B480BGN   INTEL SSDPE21D480GA                      1         480.10  GB / 480.10  GB    512   B +  0 B   E2010414
/dev/nvme1n1          SPDK00000000000001   SPDK_Controller1                         1          10.74  GB /  10.74  GB      4 KiB +  0 B   23.09   
/dev/nvme1n2          SPDK00000000000001   SPDK_Controller1                         2          10.74  GB /  10.74  GB      4 KiB +  0 B   23.09   
/dev/nvme1n3          SPDK00000000000001   SPDK_Controller1                         3          10.74  GB /  10.74  GB      4 KiB +  0 B   23.09   
/dev/nvme1n4          SPDK00000000000001   SPDK_Controller1                         4          10.74  GB /  10.74  GB      4 KiB +  0 B   23.09   
Using device /dev/nvme1n1
/dev/nvme1n2
/dev/nvme1n3
/dev/nvme1n4


===Reading entire image to warm cache===

77594624 bytes (78 MB, 74 MiB) copied, 1 s, 77.4 MB/s85983232 bytes (86 MB, 82 MiB) copied, 1 s, 85.4 MB/s79691776 bytes (80 MB, 76 MiB) copied, 1 s, 79.0 MB/s82837504 bytes (83 MB, 79 MiB) copied, 1 s, 82.0 MB/s168820736 bytes (169 MB, 161 MiB) copied, 2 s, 84.2 MB/s160432128 bytes (160 MB, 153 MiB) copied, 2 s, 79.9 MB/s143654912 bytes (144 MB, 137 MiB) copied, 2 s, 71.2 MB/s143654912 bytes (144 MB, 137 MiB) copied, 2 s, 70.7 MB/s242221056 bytes (242 MB, 231 MiB) copied, 3 s, 80.7 MB/s244318208 bytes (244 MB, 233 MiB) copied, 3 s, 81.4 MB/s226492416 bytes (226 MB, 216 MiB) copied, 3 s, 75.3 MB/s221249536 bytes (221 MB, 211 MiB) copied, 3 s, 73.5 MB/s326107136 bytes (326 MB, 311 MiB) copied, 4 s, 81.5 MB/s301989888 bytes (302 MB, 288 MiB) copied, 4 s, 75.3 MB/s286261248 bytes (286 MB, 273 MiB) copied, 4 s, 70.6 MB/s303038464 bytes (303 MB, 289 MiB) copied, 4 s, 74.6 MB/s355467264 bytes (355 MB, 339 MiB) copied, 5 s, 71.1 MB/s407896064 bytes (408 MB, 389 MiB) copied, 5 s, 81.5 MB/s380633088 bytes (381 MB, 363 MiB) copied, 5 s, 76.0 MB/s348127232 bytes (348 MB, 332 MiB) copied, 5 s, 69.4 MB/s487587840 bytes (488 MB, 465 MiB) copied, 6 s, 81.2 MB/s433061888 bytes (433 MB, 413 MiB) copied, 6 s, 72.1 MB/s461373440 bytes (461 MB, 440 MiB) copied, 6 s, 76.8 MB/s427819008 bytes (428 MB, 408 MiB) copied, 6 s, 71.2 MB/s502267904 bytes (502 MB, 479 MiB) copied, 7 s, 71.7 MB/s516947968 bytes (517 MB, 493 MiB) copied, 7 s, 73.8 MB/s551550976 bytes (552 MB, 526 MiB) copied, 7 s, 78.8 MB/s494927872 bytes (495 MB, 472 MiB) copied, 7 s, 70.6 MB/s640679936 bytes (641 MB, 611 MiB) copied, 8 s, 80.0 MB/s590348288 bytes (590 MB, 563 MiB) copied, 8 s, 73.7 MB/s565182464 bytes (565 MB, 539 MiB) copied, 8 s, 70.6 MB/s583008256 bytes (583 MB, 556 MiB) copied, 8 s, 72.8 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 18847/56992 hits, 2367 MiB read, 1.007 read amp, 56992 total
[0m735051776 bytes (735 MB, 701 MiB) copied, 9 s, 81.7 MB/s661651456 bytes (662 MB, 631 MiB) copied, 9 s, 73.5 MB/s672137216 bytes (672 MB, 641 MiB) copied, 9 s, 74.6 MB/s635437056 bytes (635 MB, 606 MiB) copied, 9 s, 70.5 MB/s815792128 bytes (816 MB, 778 MiB) copied, 10 s, 81.5 MB/s720371712 bytes (720 MB, 687 MiB) copied, 10 s, 72.0 MB/s767557632 bytes (768 MB, 732 MiB) copied, 10 s, 76.7 MB/s739246080 bytes (739 MB, 705 MiB) copied, 10 s, 73.6 MB/s904921088 bytes (905 MB, 863 MiB) copied, 11 s, 82.2 MB/s797966336 bytes (798 MB, 761 MiB) copied, 11 s, 72.5 MB/s856686592 bytes (857 MB, 817 MiB) copied, 11 s, 77.8 MB/s806354944 bytes (806 MB, 769 MiB) copied, 11 s, 73.2 MB/s987758592 bytes (988 MB, 942 MiB) copied, 12 s, 82.3 MB/s882900992 bytes (883 MB, 842 MiB) copied, 12 s, 73.6 MB/s875560960 bytes (876 MB, 835 MiB) copied, 12 s, 72.9 MB/s916455424 bytes (916 MB, 874 MiB) copied, 12 s, 76.3 MB/s965738496 bytes (966 MB, 921 MiB) copied, 13 s, 74.3 MB/s959447040 bytes (959 MB, 915 MiB) copied, 13 s, 73.8 MB/s1074790400 bytes (1.1 GB, 1.0 GiB) copied, 13 s, 82.6 MB/s993001472 bytes (993 MB, 947 MiB) copied, 13 s, 76.3 MB/s1081081856 bytes (1.1 GB, 1.0 GiB) copied, 14 s, 77.2 MB/s1042284544 bytes (1.0 GB, 994 MiB) copied, 14 s, 74.4 MB/s1037041664 bytes (1.0 GB, 989 MiB) copied, 14 s, 74.0 MB/s1155530752 bytes (1.2 GB, 1.1 GiB) copied, 14 s, 82.5 MB/s1105199104 bytes (1.1 GB, 1.0 GiB) copied, 15 s, 73.6 MB/s1113587712 bytes (1.1 GB, 1.0 GiB) copied, 15 s, 74.2 MB/s1226833920 bytes (1.2 GB, 1.1 GiB) copied, 15 s, 81.7 MB/s1142947840 bytes (1.1 GB, 1.1 GiB) copied, 15 s, 76.0 MB/s1192230912 bytes (1.2 GB, 1.1 GiB) copied, 16 s, 74.5 MB/s1299185664 bytes (1.3 GB, 1.2 GiB) copied, 16 s, 81.2 MB/s1160773632 bytes (1.2 GB, 1.1 GiB) copied, 16 s, 72.5 MB/s1196425216 bytes (1.2 GB, 1.1 GiB) copied, 16 s, 74.7 MB/s1240465408 bytes (1.2 GB, 1.2 GiB) copied, 17 s, 73.0 MB/s1280311296 bytes (1.3 GB, 1.2 GiB) copied, 17 s, 75.3 MB/s1277165568 bytes (1.3 GB, 1.2 GiB) copied, 17 s, 75.1 MB/s1389363200 bytes (1.4 GB, 1.3 GiB) copied, 17 s, 81.7 MB/s1460666368 bytes (1.5 GB, 1.4 GiB) copied, 18 s, 81.1 MB/s1358954496 bytes (1.4 GB, 1.3 GiB) copied, 18 s, 75.5 MB/s1313865728 bytes (1.3 GB, 1.2 GiB) copied, 18 s, 73.0 MB/s1357905920 bytes (1.4 GB, 1.3 GiB) copied, 18 s, 75.4 MB/s1443889152 bytes (1.4 GB, 1.3 GiB) copied, 19 s, 76.0 MB/s1400897536 bytes (1.4 GB, 1.3 GiB) copied, 19 s, 73.7 MB/s1544552448 bytes (1.5 GB, 1.4 GiB) copied, 19 s, 81.2 MB/s1435500544 bytes (1.4 GB, 1.3 GiB) copied, 19 s, 75.5 MB/s1515192320 bytes (1.5 GB, 1.4 GiB) copied, 20 s, 75.7 MB/s1457520640 bytes (1.5 GB, 1.4 GiB) copied, 20 s, 72.8 MB/s1598029824 bytes (1.6 GB, 1.5 GiB) copied, 20 s, 79.6 MB/s1505755136 bytes (1.5 GB, 1.4 GiB) copied, 20 s, 74.9 MB/s1659895808 bytes (1.7 GB, 1.5 GiB) copied, 21 s, 79.0 MB/s1527775232 bytes (1.5 GB, 1.4 GiB) copied, 21 s, 72.7 MB/s1595932672 bytes (1.6 GB, 1.5 GiB) copied, 21 s, 75.9 MB/s1563426816 bytes (1.6 GB, 1.5 GiB) copied, 21 s, 74.3 MB/s1666187264 bytes (1.7 GB, 1.6 GiB) copied, 22 s, 75.7 MB/s1634729984 bytes (1.6 GB, 1.5 GiB) copied, 22 s, 74.3 MB/s1608515584 bytes (1.6 GB, 1.5 GiB) copied, 22 s, 73.1 MB/s1745879040 bytes (1.7 GB, 1.6 GiB) copied, 22 s, 79.2 MB/s1827667968 bytes (1.8 GB, 1.7 GiB) copied, 23 s, 79.5 MB/s1689255936 bytes (1.7 GB, 1.6 GiB) copied, 23 s, 73.4 MB/s1710227456 bytes (1.7 GB, 1.6 GiB) copied, 23 s, 74.3 MB/s1754267648 bytes (1.8 GB, 1.6 GiB) copied, 23 s, 76.2 MB/s1818230784 bytes (1.8 GB, 1.7 GiB) copied, 24 s, 75.7 MB/s1782579200 bytes (1.8 GB, 1.7 GiB) copied, 24 s, 74.2 MB/s1762656256 bytes (1.8 GB, 1.6 GiB) copied, 24 s, 73.4 MB/s1905262592 bytes (1.9 GB, 1.8 GiB) copied, 24 s, 79.3 MB/s1886388224 bytes (1.9 GB, 1.8 GiB) copied, 25 s, 75.4 MB/s1975517184 bytes (2.0 GB, 1.8 GiB) copied, 25 s, 79.0 MB/s1869611008 bytes (1.9 GB, 1.7 GiB) copied, 25 s, 74.8 MB/s1841299456 bytes (1.8 GB, 1.7 GiB) copied, 25 s, 73.6 MB/s1917845504 bytes (1.9 GB, 1.8 GiB) copied, 26 s, 73.8 MB/s2056257536 bytes (2.1 GB, 1.9 GiB) copied, 26 s, 79.1 MB/s1958739968 bytes (2.0 GB, 1.8 GiB) copied, 26 s, 75.3 MB/s1963982848 bytes (2.0 GB, 1.8 GiB) copied, 26 s, 75.5 MB/s1997537280 bytes (2.0 GB, 1.9 GiB) copied, 27 s, 74.0 MB/s2138046464 bytes (2.1 GB, 2.0 GiB) copied, 27 s, 79.2 MB/s2039480320 bytes (2.0 GB, 1.9 GiB) copied, 27 s, 75.5 MB/s2039480320 bytes (2.0 GB, 1.9 GiB) copied, 27 s, 75.5 MB/s2107637760 bytes (2.1 GB, 2.0 GiB) copied, 28 s, 75.3 MB/s2065694720 bytes (2.1 GB, 1.9 GiB) copied, 28 s, 73.8 MB/s2111832064 bytes (2.1 GB, 2.0 GiB) copied, 28 s, 75.4 MB/s2215641088 bytes (2.2 GB, 2.1 GiB) copied, 28 s, 78.8 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52499/160000 hits, 6666 MiB read, 1.008 read amp, 196906 total
[0m2281701376 bytes (2.3 GB, 2.1 GiB) copied, 29 s, 78.7 MB/s2182086656 bytes (2.2 GB, 2.0 GiB) copied, 29 s, 75.2 MB/s2182086656 bytes (2.2 GB, 2.0 GiB) copied, 29 s, 75.2 MB/s2148532224 bytes (2.1 GB, 2.0 GiB) copied, 29 s, 74.0 MB/s2366636032 bytes (2.4 GB, 2.2 GiB) copied, 30 s, 78.9 MB/s2230321152 bytes (2.2 GB, 2.1 GiB) copied, 30 s, 74.3 MB/s2256535552 bytes (2.3 GB, 2.1 GiB) copied, 30 s, 75.2 MB/s2272264192 bytes (2.3 GB, 2.1 GiB) copied, 30 s, 75.7 MB/s2305818624 bytes (2.3 GB, 2.1 GiB) copied, 31 s, 74.4 MB/s2448424960 bytes (2.4 GB, 2.3 GiB) copied, 31 s, 79.0 MB/s2337275904 bytes (2.3 GB, 2.2 GiB) copied, 31 s, 75.4 MB/s2354053120 bytes (2.4 GB, 2.2 GiB) copied, 31 s, 75.9 MB/s2423259136 bytes (2.4 GB, 2.3 GiB) copied, 32 s, 75.7 MB/s2533359616 bytes (2.5 GB, 2.4 GiB) copied, 32 s, 79.2 MB/s2429550592 bytes (2.4 GB, 2.3 GiB) copied, 32 s, 75.9 MB/s2380267520 bytes (2.4 GB, 2.2 GiB) copied, 32 s, 74.4 MB/s2510290944 bytes (2.5 GB, 2.3 GiB) copied, 33 s, 76.1 MB/s2606759936 bytes (2.6 GB, 2.4 GiB) copied, 33 s, 79.0 MB/s2517630976 bytes (2.5 GB, 2.3 GiB) copied, 33 s, 76.3 MB/s2458910720 bytes (2.5 GB, 2.3 GiB) copied, 33 s, 74.4 MB/s2679111680 bytes (2.7 GB, 2.5 GiB) copied, 34 s, 78.8 MB/s2540699648 bytes (2.5 GB, 2.4 GiB) copied, 34 s, 74.7 MB/s2580545536 bytes (2.6 GB, 2.4 GiB) copied, 34 s, 75.9 MB/s2599419904 bytes (2.6 GB, 2.4 GiB) copied, 34 s, 76.4 MB/s2750414848 bytes (2.8 GB, 2.6 GiB) copied, 35 s, 78.6 MB/s2677014528 bytes (2.7 GB, 2.5 GiB) copied, 35 s, 76.5 MB/s2654994432 bytes (2.7 GB, 2.5 GiB) copied, 35 s, 75.8 MB/s2626682880 bytes (2.6 GB, 2.4 GiB) copied, 35 s, 75.0 MB/s2762997760 bytes (2.8 GB, 2.6 GiB) copied, 36 s, 76.7 MB/s2734686208 bytes (2.7 GB, 2.5 GiB) copied, 36 s, 76.0 MB/s2834300928 bytes (2.8 GB, 2.6 GiB) copied, 36 s, 78.7 MB/s2699034624 bytes (2.7 GB, 2.5 GiB) copied, 36 s, 75.0 MB/s2810183680 bytes (2.8 GB, 2.6 GiB) copied, 37 s, 75.9 MB/s2761949184 bytes (2.8 GB, 2.6 GiB) copied, 37 s, 74.6 MB/s2839543808 bytes (2.8 GB, 2.6 GiB) copied, 37 s, 76.7 MB/s2895118336 bytes (2.9 GB, 2.7 GiB) copied, 37 s, 78.2 MB/s2876243968 bytes (2.9 GB, 2.7 GiB) copied, 38 s, 75.7 MB/s2807037952 bytes (2.8 GB, 2.6 GiB) copied, 38 s, 73.8 MB/s2953838592 bytes (3.0 GB, 2.8 GiB) copied, 38 s, 77.7 MB/s2901409792 bytes (2.9 GB, 2.7 GiB) copied, 38 s, 76.3 MB/s3017801728 bytes (3.0 GB, 2.8 GiB) copied, 39 s, 77.4 MB/s2873098240 bytes (2.9 GB, 2.7 GiB) copied, 39 s, 73.7 MB/s2949644288 bytes (2.9 GB, 2.7 GiB) copied, 39 s, 75.6 MB/s2976907264 bytes (3.0 GB, 2.8 GiB) copied, 39 s, 76.3 MB/s3096444928 bytes (3.1 GB, 2.9 GiB) copied, 40 s, 77.4 MB/s2934964224 bytes (2.9 GB, 2.7 GiB) copied, 40 s, 73.4 MB/s2986344448 bytes (3.0 GB, 2.8 GiB) copied, 40 s, 74.6 MB/s3027238912 bytes (3.0 GB, 2.8 GiB) copied, 40 s, 75.6 MB/s3176136704 bytes (3.2 GB, 3.0 GiB) copied, 41 s, 77.4 MB/s3041918976 bytes (3.0 GB, 2.8 GiB) copied, 41 s, 74.1 MB/s3012558848 bytes (3.0 GB, 2.8 GiB) copied, 41 s, 73.4 MB/s3091202048 bytes (3.1 GB, 2.9 GiB) copied, 41 s, 75.3 MB/s3255828480 bytes (3.3 GB, 3.0 GiB) copied, 42 s, 77.5 MB/s3101687808 bytes (3.1 GB, 2.9 GiB) copied, 42 s, 73.8 MB/s3152019456 bytes (3.2 GB, 2.9 GiB) copied, 42 s, 75.0 MB/s3071279104 bytes (3.1 GB, 2.9 GiB) copied, 42 s, 73.1 MB/s3184525312 bytes (3.2 GB, 3.0 GiB) copied, 43 s, 74.0 MB/s3148873728 bytes (3.1 GB, 2.9 GiB) copied, 43 s, 73.2 MB/s3230662656 bytes (3.2 GB, 3.0 GiB) copied, 43 s, 75.1 MB/s3326083072 bytes (3.3 GB, 3.1 GiB) copied, 43 s, 77.3 MB/s3314548736 bytes (3.3 GB, 3.1 GiB) copied, 44 s, 75.3 MB/s3272605696 bytes (3.3 GB, 3.0 GiB) copied, 44 s, 74.3 MB/s3382706176 bytes (3.4 GB, 3.2 GiB) copied, 44 s, 76.7 MB/s3222274048 bytes (3.2 GB, 3.0 GiB) copied, 44 s, 73.0 MB/s3353346048 bytes (3.4 GB, 3.1 GiB) copied, 45 s, 74.5 MB/s3285188608 bytes (3.3 GB, 3.1 GiB) copied, 45 s, 73.0 MB/s3445620736 bytes (3.4 GB, 3.2 GiB) copied, 45 s, 76.6 MB/s3311403008 bytes (3.3 GB, 3.1 GiB) copied, 45 s, 73.6 MB/s3387949056 bytes (3.4 GB, 3.2 GiB) copied, 46 s, 73.6 MB/s3420454912 bytes (3.4 GB, 3.2 GiB) copied, 46 s, 74.3 MB/s3348103168 bytes (3.3 GB, 3.1 GiB) copied, 46 s, 72.8 MB/s3498049536 bytes (3.5 GB, 3.3 GiB) copied, 46 s, 76.0 MB/s3461349376 bytes (3.5 GB, 3.2 GiB) copied, 47 s, 73.6 MB/s3564109824 bytes (3.6 GB, 3.3 GiB) copied, 47 s, 75.8 MB/s3387949056 bytes (3.4 GB, 3.2 GiB) copied, 47 s, 72.0 MB/s3446669312 bytes (3.4 GB, 3.2 GiB) copied, 47 s, 73.3 MB/s3516923904 bytes (3.5 GB, 3.3 GiB) copied, 48 s, 73.3 MB/s3524263936 bytes (3.5 GB, 3.3 GiB) copied, 48 s, 73.4 MB/s3438280704 bytes (3.4 GB, 3.2 GiB) copied, 48 s, 71.6 MB/s3624927232 bytes (3.6 GB, 3.4 GiB) copied, 48 s, 75.5 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52503/160000 hits, 6666 MiB read, 1.008 read amp, 325282 total
[0m3598712832 bytes (3.6 GB, 3.4 GiB) copied, 49 s, 73.4 MB/s3508535296 bytes (3.5 GB, 3.3 GiB) copied, 49 s, 71.6 MB/s3595567104 bytes (3.6 GB, 3.3 GiB) copied, 49 s, 73.4 MB/s3698327552 bytes (3.7 GB, 3.4 GiB) copied, 49 s, 75.5 MB/s3585081344 bytes (3.6 GB, 3.3 GiB) copied, 50 s, 71.7 MB/s3668967424 bytes (3.7 GB, 3.4 GiB) copied, 50 s, 73.4 MB/s3784310784 bytes (3.8 GB, 3.5 GiB) copied, 50 s, 75.7 MB/s3681550336 bytes (3.7 GB, 3.4 GiB) copied, 50 s, 73.6 MB/s3751804928 bytes (3.8 GB, 3.5 GiB) copied, 51 s, 73.6 MB/s3755999232 bytes (3.8 GB, 3.5 GiB) copied, 51 s, 73.6 MB/s3668967424 bytes (3.7 GB, 3.4 GiB) copied, 51 s, 71.9 MB/s3873439744 bytes (3.9 GB, 3.6 GiB) copied, 51 s, 75.9 MB/s3939500032 bytes (3.9 GB, 3.7 GiB) copied, 52 s, 75.8 MB/s3831496704 bytes (3.8 GB, 3.6 GiB) copied, 52 s, 73.7 MB/s3825205248 bytes (3.8 GB, 3.6 GiB) copied, 52 s, 73.6 MB/s3744464896 bytes (3.7 GB, 3.5 GiB) copied, 52 s, 72.0 MB/s3809476608 bytes (3.8 GB, 3.5 GiB) copied, 53 s, 71.9 MB/s4020240384 bytes (4.0 GB, 3.7 GiB) copied, 53 s, 75.9 MB/s3916431360 bytes (3.9 GB, 3.6 GiB) copied, 53 s, 73.9 MB/s3901751296 bytes (3.9 GB, 3.6 GiB) copied, 53 s, 73.6 MB/s3876585472 bytes (3.9 GB, 3.6 GiB) copied, 54 s, 71.8 MB/s3994025984 bytes (4.0 GB, 3.7 GiB) copied, 54 s, 73.9 MB/s4085252096 bytes (4.1 GB, 3.8 GiB) copied, 54 s, 75.6 MB/s3964665856 bytes (4.0 GB, 3.7 GiB) copied, 54 s, 73.4 MB/s4045406208 bytes (4.0 GB, 3.8 GiB) copied, 55 s, 73.6 MB/s4025483264 bytes (4.0 GB, 3.7 GiB) copied, 55 s, 73.2 MB/s4158652416 bytes (4.2 GB, 3.9 GiB) copied, 55 s, 75.6 MB/s3953131520 bytes (4.0 GB, 3.7 GiB) copied, 55 s, 71.9 MB/s4028628992 bytes (4.0 GB, 3.8 GiB) copied, 56 s, 71.9 MB/s4237295616 bytes (4.2 GB, 3.9 GiB) copied, 56 s, 75.7 MB/s4103077888 bytes (4.1 GB, 3.8 GiB) copied, 56 s, 73.3 MB/s4094689280 bytes (4.1 GB, 3.8 GiB) copied, 56 s, 73.1 MB/s4320133120 bytes (4.3 GB, 4.0 GiB) copied, 57 s, 75.8 MB/s4116709376 bytes (4.1 GB, 3.8 GiB) copied, 57 s, 72.2 MB/s4175429632 bytes (4.2 GB, 3.9 GiB) copied, 57 s, 73.2 MB/s4182769664 bytes (4.2 GB, 3.9 GiB) copied, 57 s, 73.4 MB/s4255121408 bytes (4.3 GB, 4.0 GiB) copied, 58 s, 73.4 MB/s4197449728 bytes (4.2 GB, 3.9 GiB) copied, 58 s, 72.4 MB/s4402970624 bytes (4.4 GB, 4.1 GiB) copied, 58 s, 75.9 MB/s4245684224 bytes (4.2 GB, 4.0 GiB) copied, 58 s, 73.2 MB/s4321181696 bytes (4.3 GB, 4.0 GiB) copied, 59 s, 73.2 MB/s4281335808 bytes (4.3 GB, 4.0 GiB) copied, 59 s, 72.6 MB/s4320133120 bytes (4.3 GB, 4.0 GiB) copied, 59 s, 73.2 MB/s4463788032 bytes (4.5 GB, 4.2 GiB) copied, 59 s, 75.6 MB/s4355784704 bytes (4.4 GB, 4.1 GiB) copied, 60 s, 72.6 MB/s4410310656 bytes (4.4 GB, 4.1 GiB) copied, 60 s, 73.5 MB/s4535091200 bytes (4.5 GB, 4.2 GiB) copied, 60 s, 75.6 MB/s4401922048 bytes (4.4 GB, 4.1 GiB) copied, 60 s, 73.4 MB/s4606394368 bytes (4.6 GB, 4.3 GiB) copied, 61 s, 75.5 MB/s4491051008 bytes (4.5 GB, 4.2 GiB) copied, 61 s, 73.6 MB/s4435476480 bytes (4.4 GB, 4.1 GiB) copied, 61 s, 72.7 MB/s4490002432 bytes (4.5 GB, 4.2 GiB) copied, 61 s, 73.6 MB/s4545576960 bytes (4.5 GB, 4.2 GiB) copied, 62 s, 73.3 MB/s4661968896 bytes (4.7 GB, 4.3 GiB) copied, 62 s, 75.2 MB/s4520411136 bytes (4.5 GB, 4.2 GiB) copied, 62 s, 72.9 MB/s4547674112 bytes (4.5 GB, 4.2 GiB) copied, 62 s, 73.3 MB/s4626317312 bytes (4.6 GB, 4.3 GiB) copied, 63 s, 73.4 MB/s4603248640 bytes (4.6 GB, 4.3 GiB) copied, 63 s, 73.1 MB/s4623171584 bytes (4.6 GB, 4.3 GiB) copied, 63 s, 73.4 MB/s4740612096 bytes (4.7 GB, 4.4 GiB) copied, 63 s, 75.2 MB/s4689231872 bytes (4.7 GB, 4.4 GiB) copied, 64 s, 73.3 MB/s4715446272 bytes (4.7 GB, 4.4 GiB) copied, 64 s, 73.7 MB/s4824498176 bytes (4.8 GB, 4.5 GiB) copied, 64 s, 75.4 MB/s4707057664 bytes (4.7 GB, 4.4 GiB) copied, 64 s, 73.5 MB/s4879024128 bytes (4.9 GB, 4.5 GiB) copied, 65 s, 75.1 MB/s4768923648 bytes (4.8 GB, 4.4 GiB) copied, 65 s, 73.4 MB/s4787798016 bytes (4.8 GB, 4.5 GiB) copied, 65 s, 73.6 MB/s4747952128 bytes (4.7 GB, 4.4 GiB) copied, 65 s, 73.0 MB/s4825546752 bytes (4.8 GB, 4.5 GiB) copied, 66 s, 73.1 MB/s4861198336 bytes (4.9 GB, 4.5 GiB) copied, 66 s, 73.7 MB/s4855955456 bytes (4.9 GB, 4.5 GiB) copied, 66 s, 73.6 MB/s4962910208 bytes (5.0 GB, 4.6 GiB) copied, 66 s, 75.2 MB/s4937744384 bytes (4.9 GB, 4.6 GiB) copied, 67 s, 73.7 MB/s4937744384 bytes (4.9 GB, 4.6 GiB) copied, 67 s, 73.7 MB/s4906287104 bytes (4.9 GB, 4.6 GiB) copied, 67 s, 73.2 MB/s5047844864 bytes (5.0 GB, 4.7 GiB) copied, 67 s, 75.3 MB/s4991221760 bytes (5.0 GB, 4.6 GiB) copied, 68 s, 73.4 MB/s4955570176 bytes (5.0 GB, 4.6 GiB) copied, 68 s, 72.9 MB/s5113905152 bytes (5.1 GB, 4.8 GiB) copied, 68 s, 75.2 MB/s5004853248 bytes (5.0 GB, 4.7 GiB) copied, 68 s, 73.6 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52506/160000 hits, 6666 MiB read, 1.008 read amp, 461734 total
[0m5058330624 bytes (5.1 GB, 4.7 GiB) copied, 69 s, 73.3 MB/s5193596928 bytes (5.2 GB, 4.8 GiB) copied, 69 s, 75.3 MB/s5018484736 bytes (5.0 GB, 4.7 GiB) copied, 69 s, 72.7 MB/s5059379200 bytes (5.1 GB, 4.7 GiB) copied, 69 s, 73.3 MB/s5122293760 bytes (5.1 GB, 4.8 GiB) copied, 70 s, 73.2 MB/s5062524928 bytes (5.1 GB, 4.7 GiB) copied, 70 s, 72.3 MB/s5118099456 bytes (5.1 GB, 4.8 GiB) copied, 70 s, 73.0 MB/s5247074304 bytes (5.2 GB, 4.9 GiB) copied, 70 s, 74.8 MB/s5289017344 bytes (5.3 GB, 4.9 GiB) copied, 71 s, 74.5 MB/s5119148032 bytes (5.1 GB, 4.8 GiB) copied, 71 s, 72.1 MB/s5210374144 bytes (5.2 GB, 4.9 GiB) copied, 71 s, 73.4 MB/s5162139648 bytes (5.2 GB, 4.8 GiB) copied, 71 s, 72.7 MB/s5368709120 bytes (5.4 GB, 5.0 GiB) copied, 72 s, 74.6 MB/s5172625408 bytes (5.2 GB, 4.8 GiB) copied, 72 s, 71.8 MB/s5300551680 bytes (5.3 GB, 4.9 GiB) copied, 72 s, 73.6 MB/s5214568448 bytes (5.2 GB, 4.9 GiB) copied, 72 s, 72.4 MB/s5378146304 bytes (5.4 GB, 5.0 GiB) copied, 73 s, 73.7 MB/s5292163072 bytes (5.3 GB, 4.9 GiB) copied, 73 s, 72.5 MB/s5249171456 bytes (5.2 GB, 4.9 GiB) copied, 73 s, 71.9 MB/s5445255168 bytes (5.4 GB, 5.1 GiB) copied, 73 s, 74.6 MB/s5417992192 bytes (5.4 GB, 5.0 GiB) copied, 74 s, 73.2 MB/s5360320512 bytes (5.4 GB, 5.0 GiB) copied, 74 s, 72.4 MB/s5521801216 bytes (5.5 GB, 5.1 GiB) copied, 74 s, 74.6 MB/s5293211648 bytes (5.3 GB, 4.9 GiB) copied, 74 s, 71.5 MB/s5592055808 bytes (5.6 GB, 5.2 GiB) copied, 75 s, 74.6 MB/s5388632064 bytes (5.4 GB, 5.0 GiB) copied, 75 s, 71.8 MB/s5328863232 bytes (5.3 GB, 5.0 GiB) copied, 75 s, 71.0 MB/s5487198208 bytes (5.5 GB, 5.1 GiB) copied, 75 s, 73.0 MB/s5550112768 bytes (5.6 GB, 5.2 GiB) copied, 76 s, 73.0 MB/s5445255168 bytes (5.4 GB, 5.1 GiB) copied, 76 s, 71.6 MB/s5391777792 bytes (5.4 GB, 5.0 GiB) copied, 76 s, 70.9 MB/s5645533184 bytes (5.6 GB, 5.3 GiB) copied, 76 s, 74.3 MB/s5626658816 bytes (5.6 GB, 5.2 GiB) copied, 77 s, 73.1 MB/s5704253440 bytes (5.7 GB, 5.3 GiB) copied, 77 s, 74.1 MB/s5527044096 bytes (5.5 GB, 5.1 GiB) copied, 77 s, 71.8 MB/s5453643776 bytes (5.5 GB, 5.1 GiB) copied, 77 s, 70.8 MB/s5695864832 bytes (5.7 GB, 5.3 GiB) copied, 78 s, 73.0 MB/s5775556608 bytes (5.8 GB, 5.4 GiB) copied, 78 s, 74.0 MB/s5533335552 bytes (5.5 GB, 5.2 GiB) copied, 78 s, 70.9 MB/s5583667200 bytes (5.6 GB, 5.2 GiB) copied, 78 s, 71.6 MB/s5837422592 bytes (5.8 GB, 5.4 GiB) copied, 79 s, 73.9 MB/s5611978752 bytes (5.6 GB, 5.2 GiB) copied, 79 s, 71.0 MB/s5645533184 bytes (5.6 GB, 5.3 GiB) copied, 79 s, 71.5 MB/s5772410880 bytes (5.8 GB, 5.4 GiB) copied, 79 s, 73.1 MB/s5706350592 bytes (5.7 GB, 5.3 GiB) copied, 80 s, 71.3 MB/s5667553280 bytes (5.7 GB, 5.3 GiB) copied, 80 s, 70.8 MB/s5920260096 bytes (5.9 GB, 5.5 GiB) copied, 80 s, 74.0 MB/s5851054080 bytes (5.9 GB, 5.4 GiB) copied, 80 s, 73.1 MB/s6007291904 bytes (6.0 GB, 5.6 GiB) copied, 81 s, 74.2 MB/s5780799488 bytes (5.8 GB, 5.4 GiB) copied, 81 s, 71.4 MB/s5747245056 bytes (5.7 GB, 5.4 GiB) copied, 81 s, 70.9 MB/s5931794432 bytes (5.9 GB, 5.5 GiB) copied, 81 s, 73.2 MB/s5802819584 bytes (5.8 GB, 5.4 GiB) copied, 82 s, 70.8 MB/s5961154560 bytes (6.0 GB, 5.6 GiB) copied, 82 s, 72.7 MB/s6085935104 bytes (6.1 GB, 5.7 GiB) copied, 82 s, 74.2 MB/s5821693952 bytes (5.8 GB, 5.4 GiB) copied, 82 s, 71.0 MB/s6016729088 bytes (6.0 GB, 5.6 GiB) copied, 83 s, 72.5 MB/s5880414208 bytes (5.9 GB, 5.5 GiB) copied, 83 s, 70.8 MB/s6139412480 bytes (6.1 GB, 5.7 GiB) copied, 83 s, 74.0 MB/s5865734144 bytes (5.9 GB, 5.5 GiB) copied, 83 s, 70.7 MB/s5950668800 bytes (6.0 GB, 5.5 GiB) copied, 84 s, 70.8 MB/s5953814528 bytes (6.0 GB, 5.5 GiB) copied, 84 s, 70.9 MB/s6088032256 bytes (6.1 GB, 5.7 GiB) copied, 84 s, 72.5 MB/s6223298560 bytes (6.2 GB, 5.8 GiB) copied, 84 s, 74.1 MB/s6307184640 bytes (6.3 GB, 5.9 GiB) copied, 85 s, 74.2 MB/s6143606784 bytes (6.1 GB, 5.7 GiB) copied, 85 s, 72.3 MB/s6017777664 bytes (6.0 GB, 5.6 GiB) copied, 85 s, 70.8 MB/s6013583360 bytes (6.0 GB, 5.6 GiB) copied, 85 s, 70.7 MB/s6382682112 bytes (6.4 GB, 5.9 GiB) copied, 86 s, 74.2 MB/s6082789376 bytes (6.1 GB, 5.7 GiB) copied, 86 s, 70.7 MB/s6083837952 bytes (6.1 GB, 5.7 GiB) copied, 86 s, 70.7 MB/s6208618496 bytes (6.2 GB, 5.8 GiB) copied, 86 s, 72.2 MB/s6161432576 bytes (6.2 GB, 5.7 GiB) copied, 87 s, 70.8 MB/s6466568192 bytes (6.5 GB, 6.0 GiB) copied, 87 s, 74.3 MB/s6283067392 bytes (6.3 GB, 5.9 GiB) copied, 87 s, 72.2 MB/s6164578304 bytes (6.2 GB, 5.7 GiB) copied, 87 s, 70.8 MB/s6210715648 bytes (6.2 GB, 5.8 GiB) copied, 88 s, 70.6 MB/s6243221504 bytes (6.2 GB, 5.8 GiB) copied, 88 s, 70.9 MB/s6515851264 bytes (6.5 GB, 6.1 GiB) copied, 88 s, 74.0 MB/s6340739072 bytes (6.3 GB, 5.9 GiB) copied, 88 s, 72.0 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52509/160000 hits, 6666 MiB read, 1.008 read amp, 581668 total
[0m6294601728 bytes (6.3 GB, 5.9 GiB) copied, 89 s, 70.7 MB/s6586105856 bytes (6.6 GB, 6.1 GiB) copied, 89 s, 74.0 MB/s6317670400 bytes (6.3 GB, 5.9 GiB) copied, 89 s, 71.0 MB/s6426722304 bytes (6.4 GB, 6.0 GiB) copied, 89 s, 72.2 MB/s6658457600 bytes (6.7 GB, 6.2 GiB) copied, 90 s, 74.0 MB/s6375342080 bytes (6.4 GB, 5.9 GiB) copied, 90 s, 70.8 MB/s6398410752 bytes (6.4 GB, 6.0 GiB) copied, 90 s, 71.1 MB/s6494879744 bytes (6.5 GB, 6.0 GiB) copied, 90 s, 72.2 MB/s6450839552 bytes (6.5 GB, 6.0 GiB) copied, 91 s, 70.9 MB/s6563037184 bytes (6.6 GB, 6.1 GiB) copied, 91 s, 72.1 MB/s6743392256 bytes (6.7 GB, 6.3 GiB) copied, 91 s, 74.1 MB/s6461325312 bytes (6.5 GB, 6.0 GiB) copied, 91 s, 71.0 MB/s6531579904 bytes (6.5 GB, 6.1 GiB) copied, 92 s, 71.0 MB/s6544162816 bytes (6.5 GB, 6.1 GiB) copied, 92 s, 71.1 MB/s6638534656 bytes (6.6 GB, 6.2 GiB) copied, 92 s, 72.2 MB/s6829375488 bytes (6.8 GB, 6.4 GiB) copied, 92 s, 74.2 MB/s6712983552 bytes (6.7 GB, 6.3 GiB) copied, 93 s, 72.2 MB/s6903824384 bytes (6.9 GB, 6.4 GiB) copied, 93 s, 74.2 MB/s6613368832 bytes (6.6 GB, 6.2 GiB) copied, 93 s, 71.1 MB/s6619660288 bytes (6.6 GB, 6.2 GiB) copied, 93 s, 71.1 MB/s6978273280 bytes (7.0 GB, 6.5 GiB) copied, 94 s, 74.2 MB/s6787432448 bytes (6.8 GB, 6.3 GiB) copied, 94 s, 72.2 MB/s6689914880 bytes (6.7 GB, 6.2 GiB) copied, 94 s, 71.2 MB/s6695157760 bytes (6.7 GB, 6.2 GiB) copied, 94 s, 71.2 MB/s6760169472 bytes (6.8 GB, 6.3 GiB) copied, 95 s, 71.2 MB/s7059013632 bytes (7.1 GB, 6.6 GiB) copied, 95 s, 74.3 MB/s6861881344 bytes (6.9 GB, 6.4 GiB) copied, 95 s, 72.2 MB/s6767509504 bytes (6.8 GB, 6.3 GiB) copied, 95 s, 71.2 MB/s6843006976 bytes (6.8 GB, 6.4 GiB) copied, 96 s, 71.3 MB/s7143948288 bytes (7.1 GB, 6.7 GiB) copied, 96 s, 74.4 MB/s6823084032 bytes (6.8 GB, 6.4 GiB) copied, 96 s, 71.1 MB/s6938427392 bytes (6.9 GB, 6.5 GiB) copied, 96 s, 72.2 MB/s6875512832 bytes (6.9 GB, 6.4 GiB) copied, 97 s, 70.9 MB/s6916407296 bytes (6.9 GB, 6.4 GiB) copied, 97 s, 71.3 MB/s7219445760 bytes (7.2 GB, 6.7 GiB) copied, 97 s, 74.4 MB/s6997147648 bytes (7.0 GB, 6.5 GiB) copied, 97 s, 72.1 MB/s6962544640 bytes (7.0 GB, 6.5 GiB) copied, 98 s, 71.0 MB/s7072645120 bytes (7.1 GB, 6.6 GiB) copied, 98 s, 72.2 MB/s7289700352 bytes (7.3 GB, 6.8 GiB) copied, 98 s, 74.4 MB/s6988759040 bytes (7.0 GB, 6.5 GiB) copied, 98 s, 71.3 MB/s7040139264 bytes (7.0 GB, 6.6 GiB) copied, 99 s, 71.1 MB/s7367294976 bytes (7.4 GB, 6.9 GiB) copied, 99 s, 74.4 MB/s7060062208 bytes (7.1 GB, 6.6 GiB) copied, 99 s, 71.3 MB/s7154434048 bytes (7.2 GB, 6.7 GiB) copied, 99 s, 72.3 MB/s7453278208 bytes (7.5 GB, 6.9 GiB) copied, 100 s, 74.5 MB/s7125073920 bytes (7.1 GB, 6.6 GiB) copied, 100 s, 71.2 MB/s7121928192 bytes (7.1 GB, 6.6 GiB) copied, 100 s, 71.2 MB/s7206862848 bytes (7.2 GB, 6.7 GiB) copied, 100 s, 72.0 MB/s7523532800 bytes (7.5 GB, 7.0 GiB) copied, 101 s, 74.5 MB/s7194279936 bytes (7.2 GB, 6.7 GiB) copied, 101 s, 71.2 MB/s7187988480 bytes (7.2 GB, 6.7 GiB) copied, 101 s, 71.2 MB/s7267680256 bytes (7.3 GB, 6.8 GiB) copied, 101 s, 71.9 MB/s7265583104 bytes (7.3 GB, 6.8 GiB) copied, 102 s, 71.2 MB/s7346323456 bytes (7.3 GB, 6.8 GiB) copied, 102 s, 72.0 MB/s7276068864 bytes (7.3 GB, 6.8 GiB) copied, 102 s, 71.3 MB/s7604273152 bytes (7.6 GB, 7.1 GiB) copied, 102 s, 74.5 MB/s7351566336 bytes (7.4 GB, 6.8 GiB) copied, 103 s, 71.4 MB/s7418675200 bytes (7.4 GB, 6.9 GiB) copied, 103 s, 72.0 MB/s7653556224 bytes (7.7 GB, 7.1 GiB) copied, 103 s, 74.3 MB/s7352614912 bytes (7.4 GB, 6.8 GiB) copied, 103 s, 71.4 MB/s7431258112 bytes (7.4 GB, 6.9 GiB) copied, 104 s, 71.5 MB/s7417626624 bytes (7.4 GB, 6.9 GiB) copied, 104 s, 71.3 MB/s7492075520 bytes (7.5 GB, 7.0 GiB) copied, 104 s, 72.0 MB/s7735345152 bytes (7.7 GB, 7.2 GiB) copied, 104 s, 74.4 MB/s7485784064 bytes (7.5 GB, 7.0 GiB) copied, 105 s, 71.3 MB/s7538212864 bytes (7.5 GB, 7.0 GiB) copied, 105 s, 71.8 MB/s7500464128 bytes (7.5 GB, 7.0 GiB) copied, 105 s, 71.4 MB/s7794065408 bytes (7.8 GB, 7.3 GiB) copied, 105 s, 74.2 MB/s7566524416 bytes (7.6 GB, 7.0 GiB) copied, 106 s, 71.4 MB/s7873757184 bytes (7.9 GB, 7.3 GiB) copied, 106 s, 74.3 MB/s7568621568 bytes (7.6 GB, 7.0 GiB) copied, 106 s, 71.4 MB/s7614758912 bytes (7.6 GB, 7.1 GiB) copied, 106 s, 71.8 MB/s7645167616 bytes (7.6 GB, 7.1 GiB) copied, 107 s, 71.4 MB/s7937720320 bytes (7.9 GB, 7.4 GiB) copied, 107 s, 74.2 MB/s7626293248 bytes (7.6 GB, 7.1 GiB) copied, 107 s, 71.3 MB/s7685013504 bytes (7.7 GB, 7.2 GiB) copied, 107 s, 71.8 MB/s7702839296 bytes (7.7 GB, 7.2 GiB) copied, 108 s, 71.3 MB/s7726956544 bytes (7.7 GB, 7.2 GiB) copied, 108 s, 71.5 MB/s8019509248 bytes (8.0 GB, 7.5 GiB) copied, 108 s, 74.2 MB/s7769948160 bytes (7.8 GB, 7.2 GiB) copied, 108 s, 71.9 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52499/160000 hits, 6667 MiB read, 1.008 read amp, 716968 total
[0m7809794048 bytes (7.8 GB, 7.3 GiB) copied, 109 s, 71.6 MB/s7850688512 bytes (7.9 GB, 7.3 GiB) copied, 109 s, 72.0 MB/s7784628224 bytes (7.8 GB, 7.2 GiB) copied, 109 s, 71.4 MB/s8096055296 bytes (8.1 GB, 7.5 GiB) copied, 109 s, 74.3 MB/s7890534400 bytes (7.9 GB, 7.3 GiB) copied, 110 s, 71.7 MB/s7829716992 bytes (7.8 GB, 7.3 GiB) copied, 110 s, 71.2 MB/s8153726976 bytes (8.2 GB, 7.6 GiB) copied, 110 s, 74.1 MB/s7904165888 bytes (7.9 GB, 7.4 GiB) copied, 110 s, 71.8 MB/s7896825856 bytes (7.9 GB, 7.4 GiB) copied, 111 s, 71.1 MB/s7971274752 bytes (8.0 GB, 7.4 GiB) copied, 111 s, 71.8 MB/s7959740416 bytes (8.0 GB, 7.4 GiB) copied, 111 s, 71.7 MB/s8225030144 bytes (8.2 GB, 7.7 GiB) copied, 111 s, 74.1 MB/s7962886144 bytes (8.0 GB, 7.4 GiB) copied, 112 s, 71.1 MB/s8037335040 bytes (8.0 GB, 7.5 GiB) copied, 112 s, 71.8 MB/s8301576192 bytes (8.3 GB, 7.7 GiB) copied, 112 s, 74.1 MB/s8054112256 bytes (8.1 GB, 7.5 GiB) copied, 112 s, 71.9 MB/s8125415424 bytes (8.1 GB, 7.6 GiB) copied, 113 s, 71.9 MB/s8137998336 bytes (8.1 GB, 7.6 GiB) copied, 113 s, 72.0 MB/s8377073664 bytes (8.4 GB, 7.8 GiB) copied, 113 s, 74.1 MB/s8045723648 bytes (8.0 GB, 7.5 GiB) copied, 113 s, 71.2 MB/s8207204352 bytes (8.2 GB, 7.6 GiB) copied, 114 s, 72.0 MB/s8132755456 bytes (8.1 GB, 7.6 GiB) copied, 114 s, 71.3 MB/s8213495808 bytes (8.2 GB, 7.6 GiB) copied, 114 s, 72.0 MB/s8465154048 bytes (8.5 GB, 7.9 GiB) copied, 114 s, 74.2 MB/s8277458944 bytes (8.3 GB, 7.7 GiB) copied, 115 s, 72.0 MB/s8519680000 bytes (8.5 GB, 7.9 GiB) copied, 115 s, 74.1 MB/s8179941376 bytes (8.2 GB, 7.6 GiB) copied, 115 s, 71.1 MB/s8273264640 bytes (8.3 GB, 7.7 GiB) copied, 115 s, 71.9 MB/s8342470656 bytes (8.3 GB, 7.8 GiB) copied, 116 s, 71.9 MB/s8352956416 bytes (8.4 GB, 7.8 GiB) copied, 116 s, 72.0 MB/s8253341696 bytes (8.3 GB, 7.7 GiB) copied, 116 s, 71.1 MB/s8588886016 bytes (8.6 GB, 8.0 GiB) copied, 116 s, 74.0 MB/s8323596288 bytes (8.3 GB, 7.8 GiB) copied, 117 s, 71.1 MB/s8653897728 bytes (8.7 GB, 8.1 GiB) copied, 117 s, 74.0 MB/s8432648192 bytes (8.4 GB, 7.9 GiB) copied, 117 s, 72.1 MB/s8424259584 bytes (8.4 GB, 7.8 GiB) copied, 117 s, 72.0 MB/s8487174144 bytes (8.5 GB, 7.9 GiB) copied, 118 s, 71.9 MB/s8735686656 bytes (8.7 GB, 8.1 GiB) copied, 118 s, 74.0 MB/s8403288064 bytes (8.4 GB, 7.8 GiB) copied, 118 s, 71.2 MB/s8498708480 bytes (8.5 GB, 7.9 GiB) copied, 118 s, 72.0 MB/s8562671616 bytes (8.6 GB, 8.0 GiB) copied, 119 s, 72.0 MB/s8552185856 bytes (8.6 GB, 8.0 GiB) copied, 119 s, 71.9 MB/s8820621312 bytes (8.8 GB, 8.2 GiB) copied, 119 s, 74.1 MB/s8470396928 bytes (8.5 GB, 7.9 GiB) copied, 119 s, 71.2 MB/s8880390144 bytes (8.9 GB, 8.3 GiB) copied, 120 s, 74.0 MB/s8622440448 bytes (8.6 GB, 8.0 GiB) copied, 120 s, 71.9 MB/s8553234432 bytes (8.6 GB, 8.0 GiB) copied, 120 s, 71.3 MB/s8635023360 bytes (8.6 GB, 8.0 GiB) copied, 120 s, 72.0 MB/s8710520832 bytes (8.7 GB, 8.1 GiB) copied, 121 s, 72.0 MB/s8631877632 bytes (8.6 GB, 8.0 GiB) copied, 121 s, 71.3 MB/s8702132224 bytes (8.7 GB, 8.1 GiB) copied, 121 s, 71.9 MB/s8960081920 bytes (9.0 GB, 8.3 GiB) copied, 121 s, 74.0 MB/s8768192512 bytes (8.8 GB, 8.2 GiB) copied, 122 s, 71.9 MB/s9041870848 bytes (9.0 GB, 8.4 GiB) copied, 122 s, 74.1 MB/s8687452160 bytes (8.7 GB, 8.1 GiB) copied, 122 s, 71.2 MB/s8744075264 bytes (8.7 GB, 8.1 GiB) copied, 122 s, 71.7 MB/s8796504064 bytes (8.8 GB, 8.2 GiB) copied, 123 s, 71.5 MB/s9098493952 bytes (9.1 GB, 8.5 GiB) copied, 123 s, 74.0 MB/s8768192512 bytes (8.8 GB, 8.2 GiB) copied, 123 s, 71.3 MB/s8824815616 bytes (8.8 GB, 8.2 GiB) copied, 123 s, 71.7 MB/s8872001536 bytes (8.9 GB, 8.3 GiB) copied, 124 s, 71.5 MB/s9182380032 bytes (9.2 GB, 8.6 GiB) copied, 124 s, 74.0 MB/s8906604544 bytes (8.9 GB, 8.3 GiB) copied, 124 s, 71.8 MB/s8851030016 bytes (8.9 GB, 8.2 GiB) copied, 124 s, 71.4 MB/s8953790464 bytes (9.0 GB, 8.3 GiB) copied, 125 s, 71.6 MB/s8903458816 bytes (8.9 GB, 8.3 GiB) copied, 125 s, 71.2 MB/s9236905984 bytes (9.2 GB, 8.6 GiB) copied, 125 s, 73.9 MB/s8993636352 bytes (9.0 GB, 8.4 GiB) copied, 125 s, 71.9 MB/s8983150592 bytes (9.0 GB, 8.4 GiB) copied, 126 s, 71.3 MB/s9021947904 bytes (9.0 GB, 8.4 GiB) copied, 126 s, 71.6 MB/s9308209152 bytes (9.3 GB, 8.7 GiB) copied, 126 s, 73.9 MB/s9055502336 bytes (9.1 GB, 8.4 GiB) copied, 126 s, 71.8 MB/s9383706624 bytes (9.4 GB, 8.7 GiB) copied, 127 s, 73.9 MB/s9127854080 bytes (9.1 GB, 8.5 GiB) copied, 127 s, 71.9 MB/s9060745216 bytes (9.1 GB, 8.4 GiB) copied, 127 s, 71.3 MB/s9094299648 bytes (9.1 GB, 8.5 GiB) copied, 127 s, 71.6 MB/s9122611200 bytes (9.1 GB, 8.5 GiB) copied, 128 s, 71.3 MB/s9203351552 bytes (9.2 GB, 8.6 GiB) copied, 128 s, 71.9 MB/s9145679872 bytes (9.1 GB, 8.5 GiB) copied, 128 s, 71.4 MB/s9455009792 bytes (9.5 GB, 8.8 GiB) copied, 128 s, 73.9 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52501/160000 hits, 6666 MiB read, 1.008 read amp, 847660 total
[0m9517924352 bytes (9.5 GB, 8.9 GiB) copied, 129 s, 73.8 MB/s9192865792 bytes (9.2 GB, 8.6 GiB) copied, 129 s, 71.3 MB/s9272557568 bytes (9.3 GB, 8.6 GiB) copied, 129 s, 71.9 MB/s9214885888 bytes (9.2 GB, 8.6 GiB) copied, 129 s, 71.4 MB/s9350152192 bytes (9.4 GB, 8.7 GiB) copied, 130 s, 71.9 MB/s9268363264 bytes (9.3 GB, 8.6 GiB) copied, 130 s, 71.3 MB/s9284091904 bytes (9.3 GB, 8.6 GiB) copied, 130 s, 71.4 MB/s9590276096 bytes (9.6 GB, 8.9 GiB) copied, 130 s, 73.8 MB/s9430892544 bytes (9.4 GB, 8.8 GiB) copied, 131 s, 72.0 MB/s9672065024 bytes (9.7 GB, 9.0 GiB) copied, 131 s, 73.8 MB/s9363783680 bytes (9.4 GB, 8.7 GiB) copied, 131 s, 71.5 MB/s9351200768 bytes (9.4 GB, 8.7 GiB) copied, 131 s, 71.4 MB/s9441378304 bytes (9.4 GB, 8.8 GiB) copied, 132 s, 71.5 MB/s9503244288 bytes (9.5 GB, 8.9 GiB) copied, 132 s, 72.0 MB/s9414115328 bytes (9.4 GB, 8.8 GiB) copied, 132 s, 71.3 MB/s9744416768 bytes (9.7 GB, 9.1 GiB) copied, 132 s, 73.8 MB/s9496952832 bytes (9.5 GB, 8.8 GiB) copied, 133 s, 71.4 MB/s9819914240 bytes (9.8 GB, 9.1 GiB) copied, 133 s, 73.8 MB/s9522118656 bytes (9.5 GB, 8.9 GiB) copied, 133 s, 71.6 MB/s9582936064 bytes (9.6 GB, 8.9 GiB) copied, 133 s, 72.0 MB/s9606004736 bytes (9.6 GB, 8.9 GiB) copied, 134 s, 71.7 MB/s9579790336 bytes (9.6 GB, 8.9 GiB) copied, 134 s, 71.5 MB/s9899606016 bytes (9.9 GB, 9.2 GiB) copied, 134 s, 73.9 MB/s9662627840 bytes (9.7 GB, 9.0 GiB) copied, 134 s, 72.1 MB/s9690939392 bytes (9.7 GB, 9.0 GiB) copied, 135 s, 71.8 MB/s9961472000 bytes (10 GB, 9.3 GiB) copied, 135 s, 73.8 MB/s 9656336384 bytes (9.7 GB, 9.0 GiB) copied, 135 s, 71.5 MB/s9727639552 bytes (9.7 GB, 9.1 GiB) copied, 135 s, 72.0 MB/s9768534016 bytes (9.8 GB, 9.1 GiB) copied, 136 s, 71.8 MB/s10041163776 bytes (10 GB, 9.4 GiB) copied, 136 s, 73.8 MB/s9724493824 bytes (9.7 GB, 9.1 GiB) copied, 136 s, 71.5 MB/s9799991296 bytes (9.8 GB, 9.1 GiB) copied, 136 s, 72.1 MB/s9857662976 bytes (9.9 GB, 9.2 GiB) copied, 137 s, 72.0 MB/s10125049856 bytes (10 GB, 9.4 GiB) copied, 137 s, 73.9 MB/s9881780224 bytes (9.9 GB, 9.2 GiB) copied, 137 s, 72.1 MB/s9801039872 bytes (9.8 GB, 9.1 GiB) copied, 137 s, 71.5 MB/s9944694784 bytes (9.9 GB, 9.3 GiB) copied, 138 s, 72.1 MB/s9963569152 bytes (10 GB, 9.3 GiB) copied, 138 s, 72.2 MB/s 9866051584 bytes (9.9 GB, 9.2 GiB) copied, 138 s, 71.5 MB/s10193207296 bytes (10 GB, 9.5 GiB) copied, 138 s, 73.8 MB/s10266607616 bytes (10 GB, 9.6 GiB) copied, 139 s, 73.9 MB/s10025435136 bytes (10 GB, 9.3 GiB) copied, 139 s, 72.1 MB/s10049552384 bytes (10 GB, 9.4 GiB) copied, 139 s, 72.3 MB/s9954131968 bytes (10 GB, 9.3 GiB) copied, 139 s, 71.6 MB/s 10349445120 bytes (10 GB, 9.6 GiB) copied, 140 s, 73.9 MB/s10092544000 bytes (10 GB, 9.4 GiB) copied, 140 s, 72.1 MB/s10020192256 bytes (10 GB, 9.3 GiB) copied, 140 s, 71.6 MB/s10105126912 bytes (10 GB, 9.4 GiB) copied, 140 s, 72.2 MB/s10425991168 bytes (10 GB, 9.7 GiB) copied, 141 s, 73.9 MB/s10173284352 bytes (10 GB, 9.5 GiB) copied, 141 s, 72.1 MB/s10178527232 bytes (10 GB, 9.5 GiB) copied, 141 s, 72.2 MB/s10088349696 bytes (10 GB, 9.4 GiB) copied, 141 s, 71.5 MB/s10484711424 bytes (10 GB, 9.8 GiB) copied, 142 s, 73.8 MB/s10221518848 bytes (10 GB, 9.5 GiB) copied, 142 s, 72.0 MB/s10216275968 bytes (10 GB, 9.5 GiB) copied, 142 s, 71.9 MB/s10127147008 bytes (10 GB, 9.4 GiB) copied, 142 s, 71.3 MB/s10545528832 bytes (11 GB, 9.8 GiB) copied, 143 s, 73.7 MB/s10201595904 bytes (10 GB, 9.5 GiB) copied, 143 s, 71.3 MB/s10294919168 bytes (10 GB, 9.6 GiB) copied, 143 s, 72.0 MB/s10284433408 bytes (10 GB, 9.6 GiB) copied, 143 s, 71.9 MB/s10356785152 bytes (10 GB, 9.6 GiB) copied, 144 s, 71.9 MB/s10615783424 bytes (11 GB, 9.9 GiB) copied, 144 s, 73.7 MB/s10290724864 bytes (10 GB, 9.6 GiB) copied, 144 s, 71.5 MB/s10364125184 bytes (10 GB, 9.7 GiB) copied, 144 s, 72.0 MB/s10438574080 bytes (10 GB, 9.7 GiB) copied, 145 s, 72.0 MB/s10371465216 bytes (10 GB, 9.7 GiB) copied, 145 s, 71.5 MB/s10679746560 bytes (11 GB, 9.9 GiB) copied, 145 s, 73.6 MB/s10430185472 bytes (10 GB, 9.7 GiB) copied, 145 s, 71.9 MB/s10477371392 bytes (10 GB, 9.8 GiB) copied, 146 s, 71.8 MB/s10451156992 bytes (10 GB, 9.7 GiB) copied, 146 s, 71.6 MB/s10503585792 bytes (11 GB, 9.8 GiB) copied, 146 s, 71.9 MB/s10561257472 bytes (11 GB, 9.8 GiB) copied, 147 s, 71.8 MB/s10569646080 bytes (11 GB, 9.8 GiB) copied, 147 s, 71.9 MB/s10519314432 bytes (11 GB, 9.8 GiB) copied, 147 s, 71.5 MB/s
10240+0 records in
10240+0 records out
10737418240 bytes (11 GB, 10 GiB) copied, 147.137 s, 73.0 MB/s
10583277568 bytes (11 GB, 9.9 GiB) copied, 148 s, 71.5 MB/s10641997824 bytes (11 GB, 9.9 GiB) copied, 148 s, 71.9 MB/s10637803520 bytes (11 GB, 9.9 GiB) copied, 148 s, 71.9 MB/s[35m[DBG shared_read_cache.cc:805 report_cache_stats] 52512/160000 hits, 6666 MiB read, 1.008 read amp, 976948 total
[0m10716446720 bytes (11 GB, 10 GiB) copied, 149 s, 71.9 MB/s 10664017920 bytes (11 GB, 9.9 GiB) copied, 149 s, 71.6 MB/s10717495296 bytes (11 GB, 10 GiB) copied, 149 s, 71.9 MB/s 
10240+0 records in
10240+0 records out
10737418240 bytes (11 GB, 10 GiB) copied, 150.472 s, 71.4 MB/s

10240+0 records in
10240+0 records out
10737418240 bytes (11 GB, 10 GiB) copied, 150.612 s, 71.3 MB/s

10240+0 records in
10240+0 records out
10737418240 bytes (11 GB, 10 GiB) copied, 151.183 s, 71.0 MB/s


===Fio: workload=randread, time=180, iodepth=256, bs=4ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 4093795 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 7811109 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 11474520 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 14954257 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 18890992 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 22855678 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 26639940 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 30704397 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 34515308 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8038: Fri Jan 12 17:44:38 2024
  read: IOPS=179k, BW=698MiB/s (732MB/s)(123GiB/180001msec)
    slat (usec): min=3, max=8475, avg=20.28, stdev=53.08
    clat (usec): min=323, max=18778, avg=5704.62, stdev=2108.27
     lat (usec): min=358, max=18785, avg=5725.15, stdev=2116.18
    clat percentiles (usec):
     |  1.00th=[ 3654],  5.00th=[ 3752], 10.00th=[ 3851], 20.00th=[ 3982],
     | 30.00th=[ 4113], 40.00th=[ 4293], 50.00th=[ 4555], 60.00th=[ 5014],
     | 70.00th=[ 7177], 80.00th=[ 7767], 90.00th=[ 8586], 95.00th=[ 9372],
     | 99.00th=[11994], 99.50th=[12780], 99.90th=[14222], 99.95th=[15533],
     | 99.99th=[16909]
   bw (  KiB/s): min=302720, max=1071976, per=100.00%, avg=715854.18, stdev=48856.61, samples=1436
   iops        : min=75680, max=267994, avg=178963.46, stdev=12214.14, samples=1436
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=21.48%, 10=75.30%, 20=3.22%
  cpu          : usr=11.52%, sys=32.83%, ctx=3786572, majf=0, minf=1076
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=32185398,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=698MiB/s (732MB/s), 698MiB/s-698MiB/s (732MB/s-732MB/s), io=123GiB (132GB), run=180001-180001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4ki) randread:  read: IOPS=179k, BW=698MiB/s (732MB/s)(123GiB/180001msec)


===Fio: workload=randread, time=60, iodepth=128, bs=4ki, disks=1 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 1 process
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 36212298 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 37718700 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 39156701 total
[0m
j1: (groupid=0, jobs=1): err= 0: pid=8091: Fri Jan 12 17:45:41 2024
  read: IOPS=69.0k, BW=270MiB/s (283MB/s)(15.8GiB/60001msec)
    slat (usec): min=3, max=5133, avg=12.29, stdev=27.61
    clat (usec): min=196, max=7306, avg=1840.22, stdev=205.07
     lat (usec): min=206, max=7312, avg=1852.76, stdev=205.00
    clat percentiles (usec):
     |  1.00th=[ 1205],  5.00th=[ 1532], 10.00th=[ 1631], 20.00th=[ 1713],
     | 30.00th=[ 1762], 40.00th=[ 1795], 50.00th=[ 1827], 60.00th=[ 1876],
     | 70.00th=[ 1926], 80.00th=[ 1975], 90.00th=[ 2073], 95.00th=[ 2147],
     | 99.00th=[ 2409], 99.50th=[ 2474], 99.90th=[ 2638], 99.95th=[ 2737],
     | 99.99th=[ 2966]
   bw (  KiB/s): min=258272, max=291136, per=100.00%, avg=276170.42, stdev=10987.87, samples=119
   iops        : min=64568, max=72784, avg=69042.62, stdev=2746.94, samples=119
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.35%
  lat (msec)   : 2=82.26%, 4=17.39%, 10=0.01%
  cpu          : usr=18.99%, sys=51.77%, ctx=209956, majf=0, minf=139
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=4141518,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=270MiB/s (283MB/s), 270MiB/s-270MiB/s (283MB/s-283MB/s), io=15.8GiB (17.0GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=1, iodepth=128; bs=4ki) randread:  read: IOPS=69.0k, BW=270MiB/s (283MB/s)(15.8GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=128, bs=4ki, disks=2 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 2 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 41317695 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 43879654 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 46540450 total
[0m
j1: (groupid=0, jobs=2): err= 0: pid=8140: Fri Jan 12 17:46:43 2024
  read: IOPS=128k, BW=499MiB/s (523MB/s)(29.2GiB/60001msec)
    slat (usec): min=3, max=2203, avg=13.60, stdev=33.78
    clat (usec): min=159, max=9784, avg=1988.70, stdev=539.04
     lat (usec): min=171, max=9794, avg=2002.54, stdev=542.57
    clat percentiles (usec):
     |  1.00th=[ 1385],  5.00th=[ 1549], 10.00th=[ 1614], 20.00th=[ 1696],
     | 30.00th=[ 1762], 40.00th=[ 1811], 50.00th=[ 1860], 60.00th=[ 1926],
     | 70.00th=[ 1991], 80.00th=[ 2089], 90.00th=[ 2278], 95.00th=[ 3621],
     | 99.00th=[ 4178], 99.50th=[ 4359], 99.90th=[ 4686], 99.95th=[ 4817],
     | 99.99th=[ 5669]
   bw (  KiB/s): min=256904, max=583192, per=99.99%, avg=510903.66, stdev=45167.65, samples=238
   iops        : min=64226, max=145798, avg=127725.88, stdev=11291.91, samples=238
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.13%
  lat (msec)   : 2=70.80%, 4=26.77%, 10=2.29%
  cpu          : usr=16.44%, sys=44.92%, ctx=531463, majf=0, minf=278
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=7664460,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=499MiB/s (523MB/s), 499MiB/s-499MiB/s (523MB/s-523MB/s), io=29.2GiB (31.4GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=2, iodepth=128; bs=4ki) randread:  read: IOPS=128k, BW=499MiB/s (523MB/s)(29.2GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=128, bs=4ki, disks=3 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 3 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 49446377 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 53157802 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 56679386 total
[0m
j1: (groupid=0, jobs=3): err= 0: pid=8187: Fri Jan 12 17:47:45 2024
  read: IOPS=173k, BW=677MiB/s (710MB/s)(39.7GiB/60001msec)
    slat (usec): min=3, max=7937, avg=15.25, stdev=40.65
    clat (usec): min=106, max=10574, avg=2198.02, stdev=716.41
     lat (usec): min=180, max=10729, avg=2213.51, stdev=721.39
    clat percentiles (usec):
     |  1.00th=[ 1516],  5.00th=[ 1663], 10.00th=[ 1729], 20.00th=[ 1827],
     | 30.00th=[ 1893], 40.00th=[ 1958], 50.00th=[ 2008], 60.00th=[ 2073],
     | 70.00th=[ 2147], 80.00th=[ 2245], 90.00th=[ 2999], 95.00th=[ 3818],
     | 99.00th=[ 5014], 99.50th=[ 5932], 99.90th=[ 7701], 99.95th=[ 7898],
     | 99.99th=[ 8356]
   bw (  KiB/s): min=261944, max=863288, per=99.98%, avg=693309.92, stdev=44081.61, samples=357
   iops        : min=65486, max=215822, avg=173327.32, stdev=11020.37, samples=357
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.02%
  lat (msec)   : 2=48.04%, 4=48.02%, 10=3.91%, 20=0.01%
  cpu          : usr=14.44%, sys=40.59%, ctx=812095, majf=0, minf=428
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=10401642,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=677MiB/s (710MB/s), 677MiB/s-677MiB/s (710MB/s-710MB/s), io=39.7GiB (42.6GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=3, iodepth=128; bs=4ki) randread:  read: IOPS=173k, BW=677MiB/s (710MB/s)(39.7GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=128, bs=4ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 60244041 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 64214251 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 68045380 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8236: Fri Jan 12 17:48:48 2024
  read: IOPS=184k, BW=718MiB/s (753MB/s)(42.1GiB/60001msec)
    slat (usec): min=3, max=8475, avg=19.64, stdev=52.12
    clat (usec): min=155, max=12816, avg=2764.22, stdev=1134.37
     lat (usec): min=166, max=12825, avg=2784.12, stdev=1142.64
    clat percentiles (usec):
     |  1.00th=[ 1663],  5.00th=[ 1795], 10.00th=[ 1860], 20.00th=[ 1942],
     | 30.00th=[ 2008], 40.00th=[ 2089], 50.00th=[ 2180], 60.00th=[ 2343],
     | 70.00th=[ 3392], 80.00th=[ 3851], 90.00th=[ 4228], 95.00th=[ 4686],
     | 99.00th=[ 6587], 99.50th=[ 6980], 99.90th=[ 7832], 99.95th=[ 8225],
     | 99.99th=[10683]
   bw (  KiB/s): min=321981, max=1088008, per=100.00%, avg=735218.47, stdev=51053.34, samples=476
   iops        : min=80495, max=272002, avg=183804.29, stdev=12763.35, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=28.25%, 4=56.16%, 10=15.57%, 20=0.01%
  cpu          : usr=11.76%, sys=34.30%, ctx=1240022, majf=0, minf=559
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=11027794,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=718MiB/s (753MB/s), 718MiB/s-718MiB/s (753MB/s-753MB/s), io=42.1GiB (45.2GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4ki) randread:  read: IOPS=184k, BW=718MiB/s (753MB/s)(42.1GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4ki, disks=1 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 1 process
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 70892362 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 72656628 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 74375596 total
[0m
j1: (groupid=0, jobs=1): err= 0: pid=8285: Fri Jan 12 17:49:50 2024
  read: IOPS=81.4k, BW=318MiB/s (334MB/s)(18.6GiB/60001msec)
    slat (usec): min=3, max=1208, avg=10.38, stdev=19.38
    clat (usec): min=301, max=3797, avg=1559.59, stdev=191.09
     lat (usec): min=512, max=3816, avg=1570.21, stdev=191.37
    clat percentiles (usec):
     |  1.00th=[ 1020],  5.00th=[ 1237], 10.00th=[ 1352], 20.00th=[ 1434],
     | 30.00th=[ 1467], 40.00th=[ 1516], 50.00th=[ 1549], 60.00th=[ 1598],
     | 70.00th=[ 1647], 80.00th=[ 1713], 90.00th=[ 1795], 95.00th=[ 1844],
     | 99.00th=[ 2040], 99.50th=[ 2114], 99.90th=[ 2343], 99.95th=[ 2442],
     | 99.99th=[ 2638]
   bw (  KiB/s): min=287264, max=350840, per=100.00%, avg=326188.72, stdev=15742.44, samples=119
   iops        : min=71816, max=87710, avg=81547.18, stdev=3935.60, samples=119
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.81%
  lat (msec)   : 2=97.91%, 4=1.28%
  cpu          : usr=20.61%, sys=58.68%, ctx=171839, majf=0, minf=138
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=4886943,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=318MiB/s (334MB/s), 318MiB/s-318MiB/s (334MB/s-334MB/s), io=18.6GiB (20.0GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=1, iodepth=128; bs=4ki) read:  read: IOPS=81.4k, BW=318MiB/s (334MB/s)(18.6GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4ki, disks=2 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 2 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 76040017 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 79185391 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 82286911 total
[0m
j1: (groupid=0, jobs=2): err= 0: pid=8331: Fri Jan 12 17:50:53 2024
  read: IOPS=148k, BW=578MiB/s (606MB/s)(33.9GiB/60001msec)
    slat (usec): min=3, max=8030, avg=11.71, stdev=26.51
    clat (usec): min=243, max=9954, avg=1716.59, stdev=334.73
     lat (usec): min=252, max=9963, avg=1728.54, stdev=336.73
    clat percentiles (usec):
     |  1.00th=[ 1254],  5.00th=[ 1369], 10.00th=[ 1434], 20.00th=[ 1500],
     | 30.00th=[ 1565], 40.00th=[ 1614], 50.00th=[ 1663], 60.00th=[ 1729],
     | 70.00th=[ 1778], 80.00th=[ 1844], 90.00th=[ 1975], 95.00th=[ 2180],
     | 99.00th=[ 3261], 99.50th=[ 3458], 99.90th=[ 3851], 99.95th=[ 5276],
     | 99.99th=[ 6259]
   bw (  KiB/s): min=323664, max=679256, per=100.00%, avg=592130.49, stdev=29357.14, samples=238
   iops        : min=80916, max=169814, avg=148032.61, stdev=7339.28, samples=238
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.12%
  lat (msec)   : 2=90.95%, 4=8.85%, 10=0.08%
  cpu          : usr=16.34%, sys=52.06%, ctx=492106, majf=0, minf=285
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=8879414,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=578MiB/s (606MB/s), 578MiB/s-578MiB/s (606MB/s-606MB/s), io=33.9GiB (36.4GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=2, iodepth=128; bs=4ki) read:  read: IOPS=148k, BW=578MiB/s (606MB/s)(33.9GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4ki, disks=3 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 3 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 85123065 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 89358950 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 93101562 total
[0m
j1: (groupid=0, jobs=3): err= 0: pid=8380: Fri Jan 12 17:51:55 2024
  read: IOPS=195k, BW=762MiB/s (799MB/s)(44.7GiB/60001msec)
    slat (usec): min=3, max=8608, avg=13.60, stdev=33.89
    clat (usec): min=117, max=11655, avg=1953.14, stdev=686.14
     lat (usec): min=125, max=11660, avg=1966.98, stdev=691.04
    clat percentiles (usec):
     |  1.00th=[ 1303],  5.00th=[ 1418], 10.00th=[ 1467], 20.00th=[ 1532],
     | 30.00th=[ 1598], 40.00th=[ 1647], 50.00th=[ 1713], 60.00th=[ 1778],
     | 70.00th=[ 1876], 80.00th=[ 2073], 90.00th=[ 3130], 95.00th=[ 3523],
     | 99.00th=[ 4178], 99.50th=[ 4752], 99.90th=[ 6587], 99.95th=[ 7242],
     | 99.99th=[ 8455]
   bw (  KiB/s): min=349064, max=999296, per=100.00%, avg=780410.46, stdev=58755.28, samples=357
   iops        : min=87266, max=249826, avg=195102.26, stdev=14688.85, samples=357
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.09%
  lat (msec)   : 2=77.72%, 4=20.78%, 10=1.41%, 20=0.01%
  cpu          : usr=14.43%, sys=44.84%, ctx=864361, majf=0, minf=425
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=11705648,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=762MiB/s (799MB/s), 762MiB/s-762MiB/s (799MB/s-799MB/s), io=44.7GiB (47.9GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 97556728 total
[0m
RESULT: Fio (disks=3, iodepth=128; bs=4ki) read:  read: IOPS=195k, BW=762MiB/s (799MB/s)(44.7GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 101566993 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 105460748 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 109896249 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8429: Fri Jan 12 17:52:57 2024
  read: IOPS=202k, BW=788MiB/s (827MB/s)(46.2GiB/60001msec)
    slat (usec): min=3, max=8855, avg=18.02, stdev=47.88
    clat (usec): min=302, max=15692, avg=2516.96, stdev=1102.74
     lat (usec): min=308, max=15727, avg=2535.23, stdev=1110.86
    clat percentiles (usec):
     |  1.00th=[ 1369],  5.00th=[ 1500], 10.00th=[ 1565], 20.00th=[ 1680],
     | 30.00th=[ 1762], 40.00th=[ 1860], 50.00th=[ 1958], 60.00th=[ 2180],
     | 70.00th=[ 3097], 80.00th=[ 3556], 90.00th=[ 4015], 95.00th=[ 4555],
     | 99.00th=[ 5866], 99.50th=[ 6325], 99.90th=[ 7504], 99.95th=[ 7898],
     | 99.99th=[ 9765]
   bw (  KiB/s): min=367384, max=1307888, per=100.00%, avg=807948.94, stdev=64644.69, samples=476
   iops        : min=91846, max=326972, avg=201986.97, stdev=16161.16, samples=476
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.07%
  lat (msec)   : 2=53.10%, 4=36.84%, 10=9.98%, 20=0.01%
  cpu          : usr=11.72%, sys=35.71%, ctx=1261993, majf=0, minf=572
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=12110959,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=788MiB/s (827MB/s), 788MiB/s-788MiB/s (827MB/s-827MB/s), io=46.2GiB (49.6GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4ki) read:  read: IOPS=202k, BW=788MiB/s (827MB/s)(46.2GiB/60001msec)


===Fio: workload=randread, time=30, iodepth=128, bs=4ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 113434785 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8480: Fri Jan 12 17:53:30 2024
  read: IOPS=172k, BW=671MiB/s (704MB/s)(19.7GiB/30001msec)
    slat (usec): min=3, max=5492, avg=21.18, stdev=56.78
    clat (usec): min=245, max=12631, avg=2956.66, stdev=1190.07
     lat (usec): min=269, max=13071, avg=2978.10, stdev=1198.76
    clat percentiles (usec):
     |  1.00th=[ 1680],  5.00th=[ 1811], 10.00th=[ 1876], 20.00th=[ 2008],
     | 30.00th=[ 2114], 40.00th=[ 2180], 50.00th=[ 2311], 60.00th=[ 3130],
     | 70.00th=[ 3621], 80.00th=[ 4015], 90.00th=[ 4490], 95.00th=[ 5080],
     | 99.00th=[ 6521], 99.50th=[ 7046], 99.90th=[ 9634], 99.95th=[11207],
     | 99.99th=[11863]
   bw (  KiB/s): min=357496, max=1065816, per=99.90%, avg=686648.81, stdev=52043.44, samples=236
   iops        : min=89374, max=266454, avg=171662.27, stdev=13010.90, samples=236
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=19.74%, 4=60.19%, 10=19.97%, 20=0.09%
  cpu          : usr=11.08%, sys=31.49%, ctx=612689, majf=0, minf=572
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=5154943,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=671MiB/s (704MB/s), 671MiB/s-671MiB/s (704MB/s-704MB/s), io=19.7GiB (21.1GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4ki) randread:  read: IOPS=172k, BW=671MiB/s (704MB/s)(19.7GiB/30001msec)


===Fio: workload=randread, time=30, iodepth=128, bs=8ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1110 MiB read, 0.000 read amp, 116383834 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1110 MiB read, 0.000 read amp, 120052434 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8529: Fri Jan 12 17:54:02 2024
  read: IOPS=162k, BW=1269MiB/s (1331MB/s)(37.2GiB/30001msec)
    slat (usec): min=4, max=8674, avg=22.32, stdev=58.49
    clat (usec): min=273, max=15413, avg=3127.77, stdev=1153.98
     lat (usec): min=298, max=15424, avg=3150.37, stdev=1162.41
    clat percentiles (usec):
     |  1.00th=[ 1942],  5.00th=[ 2089], 10.00th=[ 2180], 20.00th=[ 2278],
     | 30.00th=[ 2376], 40.00th=[ 2474], 50.00th=[ 2540], 60.00th=[ 2671],
     | 70.00th=[ 3359], 80.00th=[ 4424], 90.00th=[ 4883], 95.00th=[ 5211],
     | 99.00th=[ 6652], 99.50th=[ 7177], 99.90th=[ 7832], 99.95th=[ 8094],
     | 99.99th=[ 9503]
   bw (  MiB/s): min=  676, max= 1800, per=99.96%, avg=1268.46, stdev=75.46, samples=236
   iops        : min=86584, max=230490, avg=162363.14, stdev=9658.94, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=1.79%, 4=71.58%, 10=26.63%, 20=0.01%
  cpu          : usr=11.11%, sys=32.87%, ctx=647753, majf=0, minf=1071
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=4872945,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1269MiB/s (1331MB/s), 1269MiB/s-1269MiB/s (1331MB/s-1331MB/s), io=37.2GiB (39.9GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=8ki) randread:  read: IOPS=162k, BW=1269MiB/s (1331MB/s)(37.2GiB/30001msec)


===Fio: workload=randread, time=30, iodepth=128, bs=16ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2001 MiB read, 0.000 read amp, 123038209 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8578: Fri Jan 12 17:54:35 2024
  read: IOPS=116k, BW=1814MiB/s (1902MB/s)(53.1GiB/30002msec)
    slat (usec): min=4, max=4300, avg=31.87, stdev=65.47
    clat (usec): min=401, max=11412, avg=4376.70, stdev=1506.49
     lat (usec): min=452, max=11438, avg=4408.89, stdev=1517.70
    clat percentiles (usec):
     |  1.00th=[ 2409],  5.00th=[ 2540], 10.00th=[ 2638], 20.00th=[ 2802],
     | 30.00th=[ 2966], 40.00th=[ 3163], 50.00th=[ 4817], 60.00th=[ 5473],
     | 70.00th=[ 5604], 80.00th=[ 5735], 90.00th=[ 5997], 95.00th=[ 6325],
     | 99.00th=[ 7767], 99.50th=[ 8291], 99.90th=[ 8848], 99.95th=[ 9241],
     | 99.99th=[10159]
   bw (  MiB/s): min= 1131, max= 2829, per=100.00%, avg=1821.52, stdev=131.99, samples=236
   iops        : min=72446, max=181118, avg=116577.02, stdev=8447.64, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=48.03%, 10=51.94%, 20=0.01%
  cpu          : usr=9.50%, sys=28.72%, ctx=1265046, majf=0, minf=2095
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=3482378,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1814MiB/s (1902MB/s), 1814MiB/s-1814MiB/s (1902MB/s-1902MB/s), io=53.1GiB (57.1GB), run=30002-30002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=16ki) randread:  read: IOPS=116k, BW=1814MiB/s (1902MB/s)(53.1GiB/30002msec)
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2002 MiB read, 0.000 read amp, 125737081 total
[0m

===Fio: workload=randread, time=30, iodepth=128, bs=32ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 3335 MiB read, 0.000 read amp, 127930295 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8628: Fri Jan 12 17:55:07 2024
  read: IOPS=80.3k, BW=2509MiB/s (2631MB/s)(73.5GiB/30003msec)
    slat (usec): min=5, max=10297, avg=47.29, stdev=87.26
    clat (usec): min=220, max=26358, avg=6327.49, stdev=2385.66
     lat (usec): min=231, max=26459, avg=6375.12, stdev=2403.64
    clat percentiles (usec):
     |  1.00th=[ 4015],  5.00th=[ 4293], 10.00th=[ 4490], 20.00th=[ 4752],
     | 30.00th=[ 5014], 40.00th=[ 5276], 50.00th=[ 5473], 60.00th=[ 5866],
     | 70.00th=[ 6718], 80.00th=[ 6980], 90.00th=[ 9765], 95.00th=[10945],
     | 99.00th=[16057], 99.50th=[17695], 99.90th=[19792], 99.95th=[20579],
     | 99.99th=[21365]
   bw (  MiB/s): min= 1235, max= 3541, per=100.00%, avg=2517.59, stdev=143.40, samples=236
   iops        : min=39523, max=113333, avg=80562.69, stdev=4588.97, samples=236
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.02%, 4=0.94%, 10=89.94%, 20=9.00%, 50=0.09%
  cpu          : usr=8.03%, sys=24.29%, ctx=2084281, majf=0, minf=4137
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=2408658,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=2509MiB/s (2631MB/s), 2509MiB/s-2509MiB/s (2631MB/s-2631MB/s), io=73.5GiB (78.9GB), run=30003-30003msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=32ki) randread:  read: IOPS=80.3k, BW=2509MiB/s (2631MB/s)(73.5GiB/30003msec)


===Fio: workload=randread, time=30, iodepth=128, bs=64ki, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 4998 MiB read, 0.000 read amp, 129693751 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 4999 MiB read, 0.000 read amp, 130657497 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8680: Fri Jan 12 17:55:40 2024
  read: IOPS=26.3k, BW=1644MiB/s (1723MB/s)(48.2GiB/30013msec)
    slat (usec): min=5, max=11699, avg=148.75, stdev=386.83
    clat (usec): min=482, max=49808, avg=19313.94, stdev=11058.50
     lat (usec): min=503, max=49993, avg=19463.17, stdev=11140.05
    clat percentiles (usec):
     |  1.00th=[ 7242],  5.00th=[ 7635], 10.00th=[ 7832], 20.00th=[ 8094],
     | 30.00th=[ 8586], 40.00th=[14615], 50.00th=[21103], 60.00th=[23462],
     | 70.00th=[23987], 80.00th=[26084], 90.00th=[27657], 95.00th=[46400],
     | 99.00th=[47449], 99.50th=[47449], 99.90th=[47973], 99.95th=[47973],
     | 99.99th=[49021]
   bw (  MiB/s): min=  850, max= 3817, per=99.50%, avg=1635.31, stdev=233.68, samples=236
   iops        : min=13604, max=61086, avg=26165.02, stdev=3738.89, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.03%, 4=0.05%, 10=33.32%, 20=16.25%, 50=50.35%
  cpu          : usr=3.39%, sys=10.68%, ctx=801835, majf=0, minf=8239
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=789256,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1644MiB/s (1723MB/s), 1644MiB/s-1644MiB/s (1723MB/s-1723MB/s), io=48.2GiB (51.7GB), run=30013-30013msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=64ki) randread:  read: IOPS=26.3k, BW=1644MiB/s (1723MB/s)(48.2GiB/30013msec)


===Fio: workload=read, time=30, iodepth=128, bs=4ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 133490057 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8729: Fri Jan 12 17:56:12 2024
  read: IOPS=192k, BW=750MiB/s (787MB/s)(22.0GiB/30001msec)
    slat (usec): min=3, max=8079, avg=18.96, stdev=48.09
    clat (usec): min=290, max=11909, avg=2644.76, stdev=987.51
     lat (usec): min=302, max=12147, avg=2663.99, stdev=994.73
    clat percentiles (usec):
     |  1.00th=[ 1434],  5.00th=[ 1549], 10.00th=[ 1631], 20.00th=[ 1729],
     | 30.00th=[ 1844], 40.00th=[ 1991], 50.00th=[ 2507], 60.00th=[ 2966],
     | 70.00th=[ 3163], 80.00th=[ 3392], 90.00th=[ 3851], 95.00th=[ 4424],
     | 99.00th=[ 5669], 99.50th=[ 6194], 99.90th=[ 6718], 99.95th=[ 7177],
     | 99.99th=[10814]
   bw (  KiB/s): min=370520, max=1220512, per=99.93%, avg=767837.93, stdev=49803.90, samples=236
   iops        : min=92630, max=305128, avg=191959.42, stdev=12450.97, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=40.75%, 4=50.51%, 10=8.71%, 20=0.02%
  cpu          : usr=11.16%, sys=35.22%, ctx=637013, majf=0, minf=570
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=5762954,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=750MiB/s (787MB/s), 750MiB/s-750MiB/s (787MB/s-787MB/s), io=22.0GiB (23.6GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4ki) read:  read: IOPS=192k, BW=750MiB/s (787MB/s)(22.0GiB/30001msec)


===Fio: workload=read, time=30, iodepth=128, bs=8ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 8192B-8192B, (W) 8192B-8192B, (T) 8192B-8192B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 846 MiB read, 0.000 read amp, 137130508 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1111 MiB read, 0.000 read amp, 140739274 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8778: Fri Jan 12 17:56:45 2024
  read: IOPS=163k, BW=1272MiB/s (1334MB/s)(37.3GiB/30001msec)
    slat (usec): min=4, max=2973, avg=22.20, stdev=56.48
    clat (usec): min=224, max=10003, avg=3120.89, stdev=1231.29
     lat (usec): min=268, max=10064, avg=3143.40, stdev=1240.47
    clat percentiles (usec):
     |  1.00th=[ 1663],  5.00th=[ 1860], 10.00th=[ 1958], 20.00th=[ 2089],
     | 30.00th=[ 2180], 40.00th=[ 2311], 50.00th=[ 2540], 60.00th=[ 3425],
     | 70.00th=[ 3818], 80.00th=[ 4113], 90.00th=[ 4621], 95.00th=[ 5538],
     | 99.00th=[ 6980], 99.50th=[ 7635], 99.90th=[ 8455], 99.95th=[ 8717],
     | 99.99th=[ 9241]
   bw (  MiB/s): min=  588, max= 2023, per=100.00%, avg=1272.69, stdev=96.21, samples=240
   iops        : min=75263, max=259043, avg=162903.85, stdev=12315.29, samples=240
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=13.31%, 4=62.98%, 10=23.71%, 20=0.01%
  cpu          : usr=11.15%, sys=36.17%, ctx=664083, majf=0, minf=1076
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=4883653,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1272MiB/s (1334MB/s), 1272MiB/s-1272MiB/s (1334MB/s-1334MB/s), io=37.3GiB (40.0GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=8ki) read:  read: IOPS=163k, BW=1272MiB/s (1334MB/s)(37.3GiB/30001msec)


===Fio: workload=read, time=30, iodepth=128, bs=16ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 143936593 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 147057183 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8827: Fri Jan 12 17:57:17 2024
  read: IOPS=127k, BW=1979MiB/s (2076MB/s)(58.0GiB/30002msec)
    slat (usec): min=4, max=8617, avg=29.51, stdev=75.04
    clat (usec): min=419, max=14685, avg=4009.92, stdev=1767.56
     lat (usec): min=454, max=14771, avg=4039.73, stdev=1780.50
    clat percentiles (usec):
     |  1.00th=[ 2212],  5.00th=[ 2376], 10.00th=[ 2474], 20.00th=[ 2638],
     | 30.00th=[ 2737], 40.00th=[ 2868], 50.00th=[ 3032], 60.00th=[ 4080],
     | 70.00th=[ 5014], 80.00th=[ 5342], 90.00th=[ 6259], 95.00th=[ 8029],
     | 99.00th=[ 9110], 99.50th=[ 9372], 99.90th=[10028], 99.95th=[10814],
     | 99.99th=[12387]
   bw (  MiB/s): min= 1088, max= 3155, per=100.00%, avg=1985.85, stdev=142.61, samples=236
   iops        : min=69668, max=201954, avg=127094.31, stdev=9126.78, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.07%, 4=59.60%, 10=40.22%, 20=0.11%
  cpu          : usr=8.60%, sys=29.98%, ctx=1162121, majf=0, minf=2098
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=3800615,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=1979MiB/s (2076MB/s), 1979MiB/s-1979MiB/s (2076MB/s-2076MB/s), io=58.0GiB (62.3GB), run=30002-30002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=16ki) read:  read: IOPS=127k, BW=1979MiB/s (2076MB/s)(58.0GiB/30002msec)


===Fio: workload=read, time=30, iodepth=128, bs=32ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 32.0KiB-32.0KiB, (W) 32.0KiB-32.0KiB, (T) 32.0KiB-32.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 3333 MiB read, 0.000 read amp, 149102617 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8876: Fri Jan 12 17:57:49 2024
  read: IOPS=69.9k, BW=2184MiB/s (2290MB/s)(64.0GiB/30003msec)
    slat (usec): min=4, max=8435, avg=55.03, stdev=133.39
    clat (usec): min=357, max=24065, avg=7268.60, stdev=3133.03
     lat (usec): min=367, max=24087, avg=7323.98, stdev=3155.58
    clat percentiles (usec):
     |  1.00th=[ 3621],  5.00th=[ 3916], 10.00th=[ 4113], 20.00th=[ 4490],
     | 30.00th=[ 4883], 40.00th=[ 5145], 50.00th=[ 5473], 60.00th=[ 7439],
     | 70.00th=[10028], 80.00th=[10814], 90.00th=[11600], 95.00th=[12125],
     | 99.00th=[13829], 99.50th=[14877], 99.90th=[17957], 99.95th=[18482],
     | 99.99th=[21103]
   bw (  MiB/s): min= 1101, max= 3704, per=99.73%, avg=2177.74, stdev=203.43, samples=236
   iops        : min=35232, max=118549, avg=69686.97, stdev=6509.91, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.02%, 4=6.84%, 10=62.26%, 20=30.86%, 50=0.02%
  cpu          : usr=6.55%, sys=21.33%, ctx=1768962, majf=0, minf=4151
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=2096605,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=2184MiB/s (2290MB/s), 2184MiB/s-2184MiB/s (2290MB/s-2290MB/s), io=64.0GiB (68.7GB), run=30003-30003msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=32ki) read:  read: IOPS=69.9k, BW=2184MiB/s (2290MB/s)(64.0GiB/30003msec)


===Fio: workload=read, time=30, iodepth=128, bs=64ki, disks=4 ===

j1: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 150724549 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 152500747 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8925: Fri Jan 12 17:58:22 2024
  read: IOPS=41.8k, BW=2615MiB/s (2742MB/s)(76.6GiB/30006msec)
    slat (usec): min=5, max=14022, avg=93.11, stdev=138.27
    clat (usec): min=468, max=46106, avg=12137.16, stdev=3968.89
     lat (usec): min=479, max=46504, avg=12230.66, stdev=3998.12
    clat percentiles (usec):
     |  1.00th=[ 7832],  5.00th=[ 8455], 10.00th=[ 8717], 20.00th=[ 8979],
     | 30.00th=[ 9372], 40.00th=[10028], 50.00th=[10814], 60.00th=[11469],
     | 70.00th=[13829], 80.00th=[14615], 90.00th=[17695], 95.00th=[18744],
     | 99.00th=[28705], 99.50th=[29492], 99.90th=[31327], 99.95th=[33817],
     | 99.99th=[38011]
   bw (  MiB/s): min= 1155, max= 3614, per=100.00%, avg=2626.75, stdev=162.15, samples=236
   iops        : min=18480, max=57828, avg=42027.93, stdev=2594.37, samples=236
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.05%, 10=39.53%, 20=57.03%, 50=3.38%
  cpu          : usr=4.43%, sys=14.15%, ctx=1260005, majf=0, minf=8246
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=99.9%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=1255397,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=2615MiB/s (2742MB/s), 2615MiB/s-2615MiB/s (2742MB/s-2742MB/s), io=76.6GiB (82.3GB), run=30006-30006msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=64ki) read:  read: IOPS=41.8k, BW=2615MiB/s (2742MB/s)(76.6GiB/30006msec)


===Fio: workload=randread, time=60, iodepth=256, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 154801592 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 158349091 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 162334377 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=8975: Fri Jan 12 17:59:24 2024
  read: IOPS=173k, BW=677MiB/s (710MB/s)(39.7GiB/60001msec)
    slat (usec): min=3, max=8045, avg=20.96, stdev=54.73
    clat (usec): min=266, max=22429, avg=5883.01, stdev=2327.97
     lat (usec): min=283, max=22440, avg=5904.22, stdev=2336.72
    clat percentiles (usec):
     |  1.00th=[ 3425],  5.00th=[ 3654], 10.00th=[ 3752], 20.00th=[ 3916],
     | 30.00th=[ 4113], 40.00th=[ 4293], 50.00th=[ 4555], 60.00th=[ 6587],
     | 70.00th=[ 7373], 80.00th=[ 8029], 90.00th=[ 8717], 95.00th=[10159],
     | 99.00th=[12649], 99.50th=[13435], 99.90th=[15139], 99.95th=[15795],
     | 99.99th=[20841]
   bw (  KiB/s): min=344992, max=1105800, per=100.00%, avg=693726.99, stdev=50534.49, samples=476
   iops        : min=86248, max=276450, avg=173431.60, stdev=12633.62, samples=476
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=24.03%, 10=70.81%, 20=5.12%, 50=0.03%
  cpu          : usr=11.20%, sys=32.25%, ctx=1254068, majf=0, minf=1076
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=10402937,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=677MiB/s (710MB/s), 677MiB/s-677MiB/s (710MB/s-710MB/s), io=39.7GiB (42.6GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4k) randread:  read: IOPS=173k, BW=677MiB/s (710MB/s)(39.7GiB/60001msec)


===Fio: workload=read, time=60, iodepth=256, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 165905374 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 170119963 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 174733220 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9025: Fri Jan 12 18:00:27 2024
  read: IOPS=205k, BW=802MiB/s (841MB/s)(47.0GiB/60001msec)
    slat (usec): min=3, max=11674, avg=17.69, stdev=46.68
    clat (usec): min=293, max=20977, avg=4969.00, stdev=2014.85
     lat (usec): min=298, max=20989, avg=4986.96, stdev=2022.44
    clat percentiles (usec):
     |  1.00th=[ 2868],  5.00th=[ 3097], 10.00th=[ 3195], 20.00th=[ 3359],
     | 30.00th=[ 3490], 40.00th=[ 3654], 50.00th=[ 3818], 60.00th=[ 4228],
     | 70.00th=[ 6587], 80.00th=[ 7111], 90.00th=[ 7635], 95.00th=[ 8094],
     | 99.00th=[11076], 99.50th=[11469], 99.90th=[13042], 99.95th=[14353],
     | 99.99th=[15664]
   bw (  KiB/s): min=395517, max=1285176, per=100.00%, avg=823681.52, stdev=61977.08, samples=476
   iops        : min=98879, max=321294, avg=205920.30, stdev=15494.28, samples=476
  lat (usec)   : 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=55.95%, 10=41.75%, 20=2.29%, 50=0.01%
  cpu          : usr=11.73%, sys=36.66%, ctx=1264359, majf=0, minf=1075
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=12315950,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=802MiB/s (841MB/s), 802MiB/s-802MiB/s (841MB/s-841MB/s), io=47.0GiB (50.4GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4k) read:  read: IOPS=205k, BW=802MiB/s (841MB/s)(47.0GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=1, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 177280204 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 177892184 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 178557420 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9075: Fri Jan 12 18:01:29 2024
  read: IOPS=30.5k, BW=119MiB/s (125MB/s)(7141MiB/60001msec)
    slat (usec): min=5, max=477, avg= 8.61, stdev= 4.31
    clat (nsec): min=895, max=6215.1k, avg=120232.18, stdev=41255.64
     lat (usec): min=83, max=6222, avg=129.11, stdev=41.85
    clat percentiles (usec):
     |  1.00th=[   85],  5.00th=[   89], 10.00th=[   92], 20.00th=[   95],
     | 30.00th=[   99], 40.00th=[  103], 50.00th=[  110], 60.00th=[  116],
     | 70.00th=[  124], 80.00th=[  133], 90.00th=[  159], 95.00th=[  194],
     | 99.00th=[  281], 99.50th=[  318], 99.90th=[  486], 99.95th=[  523],
     | 99.99th=[  627]
   bw (  KiB/s): min=104360, max=139600, per=100.00%, avg=121917.03, stdev=2340.37, samples=476
   iops        : min=26090, max=34900, avg=30479.19, stdev=585.07, samples=476
  lat (nsec)   : 1000=0.01%
  lat (usec)   : 2=0.01%, 20=0.01%, 50=0.01%, 100=33.47%, 250=64.75%
  lat (usec)   : 500=1.71%, 750=0.08%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.01%
  cpu          : usr=4.15%, sys=10.11%, ctx=1828167, majf=0, minf=54
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwts: total=1828142,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=1

Run status group 0 (all jobs):
   READ: bw=119MiB/s (125MB/s), 119MiB/s-119MiB/s (125MB/s-125MB/s), io=7141MiB (7488MB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=1; bs=4k) randread:  read: IOPS=30.5k, BW=119MiB/s (125MB/s)(7141MiB/60001msec)


===Fio: workload=randread, time=60, iodepth=32, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 179737317 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 183478806 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 187310349 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9127: Fri Jan 12 18:02:32 2024
  read: IOPS=182k, BW=711MiB/s (746MB/s)(41.7GiB/60001msec)
    slat (usec): min=3, max=2526, avg= 7.19, stdev= 8.58
    clat (usec): min=56, max=9265, avg=693.86, stdev=302.24
     lat (usec): min=103, max=9272, avg=701.28, stdev=302.49
    clat percentiles (usec):
     |  1.00th=[  285],  5.00th=[  355], 10.00th=[  396], 20.00th=[  449],
     | 30.00th=[  498], 40.00th=[  545], 50.00th=[  594], 60.00th=[  660],
     | 70.00th=[  824], 80.00th=[  979], 90.00th=[ 1106], 95.00th=[ 1237],
     | 99.00th=[ 1549], 99.50th=[ 1713], 99.90th=[ 2114], 99.95th=[ 2245],
     | 99.99th=[ 2802]
   bw (  KiB/s): min=281360, max=1070949, per=100.00%, avg=728931.09, stdev=48665.82, samples=480
   iops        : min=70340, max=267736, avg=182232.15, stdev=12166.46, samples=480
  lat (usec)   : 100=0.01%, 250=0.16%, 500=30.25%, 750=36.39%, 1000=14.77%
  lat (msec)   : 2=18.23%, 4=0.19%, 10=0.01%
  cpu          : usr=12.25%, sys=34.53%, ctx=1226843, majf=0, minf=554
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued rwts: total=10925285,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32

Run status group 0 (all jobs):
   READ: bw=711MiB/s (746MB/s), 711MiB/s-711MiB/s (746MB/s-746MB/s), io=41.7GiB (44.7GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=32; bs=4k) randread:  read: IOPS=182k, BW=711MiB/s (746MB/s)(41.7GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=64, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 190887114 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 195124434 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 198737493 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9177: Fri Jan 12 18:03:34 2024
  read: IOPS=182k, BW=712MiB/s (747MB/s)(41.7GiB/60001msec)
    slat (usec): min=3, max=11404, avg=19.09, stdev=50.97
    clat (usec): min=153, max=13503, avg=1382.74, stdev=577.13
     lat (usec): min=175, max=13516, avg=1402.09, stdev=584.78
    clat percentiles (usec):
     |  1.00th=[  676],  5.00th=[  832], 10.00th=[  873], 20.00th=[  930],
     | 30.00th=[  979], 40.00th=[ 1029], 50.00th=[ 1106], 60.00th=[ 1270],
     | 70.00th=[ 1713], 80.00th=[ 1926], 90.00th=[ 2180], 95.00th=[ 2442],
     | 99.00th=[ 3097], 99.50th=[ 3294], 99.90th=[ 3720], 99.95th=[ 3916],
     | 99.99th=[ 5014]
   bw (  KiB/s): min=374888, max=1100592, per=100.00%, avg=730424.29, stdev=50651.94, samples=476
   iops        : min=93722, max=275148, avg=182605.81, stdev=12663.00, samples=476
  lat (usec)   : 250=0.01%, 500=0.09%, 750=1.70%, 1000=32.96%
  lat (msec)   : 2=48.62%, 4=16.59%, 10=0.03%, 20=0.01%
  cpu          : usr=11.95%, sys=33.79%, ctx=1245905, majf=0, minf=463
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=10942842,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=712MiB/s (747MB/s), 712MiB/s-712MiB/s (747MB/s-747MB/s), io=41.7GiB (44.8GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=64; bs=4k) randread:  read: IOPS=182k, BW=712MiB/s (747MB/s)(41.7GiB/60001msec)
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 202268605 total
[0m

===Fio: workload=randread, time=60, iodepth=128, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 205536522 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 209272994 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 212983248 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9227: Fri Jan 12 18:04:36 2024
  read: IOPS=171k, BW=668MiB/s (700MB/s)(39.1GiB/60001msec)
    slat (usec): min=3, max=9159, avg=21.23, stdev=55.52
    clat (usec): min=142, max=14564, avg=2971.64, stdev=1234.99
     lat (usec): min=152, max=14815, avg=2993.14, stdev=1244.01
    clat percentiles (usec):
     |  1.00th=[ 1696],  5.00th=[ 1827], 10.00th=[ 1893], 20.00th=[ 2008],
     | 30.00th=[ 2114], 40.00th=[ 2180], 50.00th=[ 2278], 60.00th=[ 2900],
     | 70.00th=[ 3752], 80.00th=[ 4015], 90.00th=[ 4424], 95.00th=[ 5211],
     | 99.00th=[ 7111], 99.50th=[ 7504], 99.90th=[10159], 99.95th=[10814],
     | 99.99th=[11207]
   bw (  KiB/s): min=280248, max=1083437, per=100.00%, avg=685633.46, stdev=52710.97, samples=476
   iops        : min=70062, max=270859, avg=171407.96, stdev=13177.72, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=18.76%, 4=60.27%, 10=20.86%, 20=0.11%
  cpu          : usr=11.46%, sys=32.25%, ctx=1242993, majf=0, minf=562
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=10257913,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=668MiB/s (700MB/s), 668MiB/s-668MiB/s (700MB/s-700MB/s), io=39.1GiB (42.0GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4k) randread:  read: IOPS=171k, BW=668MiB/s (700MB/s)(39.1GiB/60001msec)


===Fio: workload=read, time=60, iodepth=1, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=1
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 213729932 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 214396578 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 215079961 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9277: Fri Jan 12 18:05:39 2024
  read: IOPS=32.1k, BW=125MiB/s (131MB/s)(7512MiB/60001msec)
    slat (usec): min=5, max=393, avg= 8.84, stdev= 4.30
    clat (nsec): min=571, max=1473.6k, avg=113838.77, stdev=37896.05
     lat (usec): min=82, max=1480, avg=122.96, stdev=38.60
    clat percentiles (usec):
     |  1.00th=[   86],  5.00th=[   89], 10.00th=[   91], 20.00th=[   94],
     | 30.00th=[   97], 40.00th=[  100], 50.00th=[  104], 60.00th=[  109],
     | 70.00th=[  114], 80.00th=[  122], 90.00th=[  141], 95.00th=[  184],
     | 99.00th=[  277], 99.50th=[  314], 99.90th=[  478], 99.95th=[  519],
     | 99.99th=[  619]
   bw (  KiB/s): min=110280, max=142550, per=100.00%, avg=128301.13, stdev=1919.95, samples=476
   iops        : min=27570, max=35637, avg=32074.97, stdev=479.99, samples=476
  lat (nsec)   : 750=0.01%, 1000=0.01%
  lat (usec)   : 2=0.01%, 20=0.01%, 50=0.01%, 100=40.39%, 250=58.06%
  lat (usec)   : 500=1.47%, 750=0.07%, 1000=0.01%
  lat (msec)   : 2=0.01%
  cpu          : usr=4.03%, sys=10.98%, ctx=1923103, majf=0, minf=57
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwts: total=1923047,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=1

Run status group 0 (all jobs):
   READ: bw=125MiB/s (131MB/s), 125MiB/s-125MiB/s (131MB/s-131MB/s), io=7512MiB (7877MB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=1; bs=4k) read:  read: IOPS=32.1k, BW=125MiB/s (131MB/s)(7512MiB/60001msec)


===Fio: workload=read, time=60, iodepth=32, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=32
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 218458639 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 222726603 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 227231790 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9329: Fri Jan 12 18:06:41 2024
  read: IOPS=211k, BW=825MiB/s (865MB/s)(48.3GiB/60001msec)
    slat (usec): min=3, max=1434, avg= 6.91, stdev= 6.47
    clat (usec): min=77, max=8585, avg=597.83, stdev=265.83
     lat (usec): min=105, max=8593, avg=604.97, stdev=265.94
    clat percentiles (usec):
     |  1.00th=[  262],  5.00th=[  310], 10.00th=[  343], 20.00th=[  388],
     | 30.00th=[  429], 40.00th=[  465], 50.00th=[  510], 60.00th=[  562],
     | 70.00th=[  652], 80.00th=[  832], 90.00th=[ 1029], 95.00th=[ 1123],
     | 99.00th=[ 1336], 99.50th=[ 1434], 99.90th=[ 1631], 99.95th=[ 1713],
     | 99.99th=[ 1926]
   bw (  KiB/s): min=432744, max=1205562, per=100.00%, avg=845275.10, stdev=56918.09, samples=476
   iops        : min=108186, max=301390, avg=211318.64, stdev=14229.52, samples=476
  lat (usec)   : 100=0.01%, 250=0.57%, 500=47.41%, 750=27.94%, 1000=12.63%
  lat (msec)   : 2=11.45%, 4=0.01%, 10=0.01%
  cpu          : usr=12.67%, sys=37.65%, ctx=1335694, majf=0, minf=245
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued rwts: total=12667573,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32

Run status group 0 (all jobs):
   READ: bw=825MiB/s (865MB/s), 825MiB/s-825MiB/s (865MB/s-865MB/s), io=48.3GiB (51.9GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=32; bs=4k) read:  read: IOPS=211k, BW=825MiB/s (865MB/s)(48.3GiB/60001msec)


===Fio: workload=read, time=60, iodepth=64, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=64
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 231042096 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 235491312 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 240005697 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9381: Fri Jan 12 18:07:44 2024
  read: IOPS=208k, BW=812MiB/s (851MB/s)(47.6GiB/60001msec)
    slat (usec): min=3, max=8239, avg=16.77, stdev=42.67
    clat (usec): min=106, max=13789, avg=1213.55, stdev=477.16
     lat (usec): min=114, max=13794, avg=1230.57, stdev=483.30
    clat percentiles (usec):
     |  1.00th=[  635],  5.00th=[  742], 10.00th=[  783], 20.00th=[  840],
     | 30.00th=[  889], 40.00th=[  938], 50.00th=[ 1004], 60.00th=[ 1106],
     | 70.00th=[ 1401], 80.00th=[ 1680], 90.00th=[ 1926], 95.00th=[ 2114],
     | 99.00th=[ 2606], 99.50th=[ 2835], 99.90th=[ 3326], 99.95th=[ 3556],
     | 99.99th=[ 3982]
   bw (  KiB/s): min=422848, max=1219575, per=100.00%, avg=832201.44, stdev=52609.92, samples=476
   iops        : min=105712, max=304893, avg=208049.80, stdev=13152.46, samples=476
  lat (usec)   : 250=0.01%, 500=0.17%, 750=5.60%, 1000=44.20%
  lat (msec)   : 2=42.46%, 4=7.56%, 10=0.01%, 20=0.01%
  cpu          : usr=11.80%, sys=38.04%, ctx=1262141, majf=0, minf=311
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=12469301,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=812MiB/s (851MB/s), 812MiB/s-812MiB/s (851MB/s-851MB/s), io=47.6GiB (51.1GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=64; bs=4k) read:  read: IOPS=208k, BW=812MiB/s (851MB/s)(47.6GiB/60001msec)


===Fio: workload=read, time=60, iodepth=128, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 243917492 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 247885453 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 252090514 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9430: Fri Jan 12 18:08:46 2024
  read: IOPS=196k, BW=765MiB/s (803MB/s)(44.8GiB/60001msec)
    slat (usec): min=3, max=7856, avg=18.58, stdev=47.93
    clat (usec): min=224, max=17311, avg=2592.68, stdev=1151.27
     lat (usec): min=271, max=17333, avg=2611.52, stdev=1159.79
    clat percentiles (usec):
     |  1.00th=[ 1369],  5.00th=[ 1516], 10.00th=[ 1598], 20.00th=[ 1696],
     | 30.00th=[ 1778], 40.00th=[ 1876], 50.00th=[ 1991], 60.00th=[ 2507],
     | 70.00th=[ 3228], 80.00th=[ 3523], 90.00th=[ 3982], 95.00th=[ 4948],
     | 99.00th=[ 6063], 99.50th=[ 7373], 99.90th=[ 7963], 99.95th=[ 8455],
     | 99.99th=[10290]
   bw (  KiB/s): min=327856, max=1293104, per=100.00%, avg=784731.04, stdev=62572.20, samples=476
   iops        : min=81964, max=323276, avg=196182.47, stdev=15643.05, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.05%
  lat (msec)   : 2=50.40%, 4=39.62%, 10=9.91%, 20=0.01%
  cpu          : usr=11.69%, sys=35.49%, ctx=1286743, majf=0, minf=565
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=11757274,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=765MiB/s (803MB/s), 765MiB/s-765MiB/s (803MB/s-803MB/s), io=44.8GiB (48.2GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=128; bs=4k) read:  read: IOPS=196k, BW=765MiB/s (803MB/s)(44.8GiB/60001msec)


===Fio: workload=read, time=60, iodepth=256, bs=4k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 255510407 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 259746736 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 264192644 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9481: Fri Jan 12 18:09:48 2024
  read: IOPS=200k, BW=783MiB/s (821MB/s)(45.9GiB/60001msec)
    slat (usec): min=3, max=7885, avg=18.15, stdev=47.22
    clat (usec): min=213, max=19228, avg=5087.57, stdev=2073.37
     lat (usec): min=310, max=19281, avg=5105.98, stdev=2081.20
    clat percentiles (usec):
     |  1.00th=[ 3032],  5.00th=[ 3228], 10.00th=[ 3359], 20.00th=[ 3523],
     | 30.00th=[ 3654], 40.00th=[ 3785], 50.00th=[ 3949], 60.00th=[ 4359],
     | 70.00th=[ 6390], 80.00th=[ 6980], 90.00th=[ 7635], 95.00th=[ 9372],
     | 99.00th=[11207], 99.50th=[12256], 99.90th=[14877], 99.95th=[15139],
     | 99.99th=[16188]
   bw (  KiB/s): min=343984, max=1219368, per=100.00%, avg=802765.66, stdev=58033.53, samples=476
   iops        : min=85996, max=304842, avg=200691.29, stdev=14508.37, samples=476
  lat (usec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=51.60%, 10=44.85%, 20=3.54%
  cpu          : usr=11.58%, sys=36.03%, ctx=1268215, majf=0, minf=1080
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=12029064,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=783MiB/s (821MB/s), 783MiB/s-783MiB/s (821MB/s-821MB/s), io=45.9GiB (49.3GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4k) read:  read: IOPS=200k, BW=783MiB/s (821MB/s)(45.9GiB/60001msec)


===Fio: workload=read, time=60, iodepth=256, bs=16k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j2: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j3: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j4: (g=0): rw=read, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 267985104 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 271351156 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 274313328 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9531: Fri Jan 12 18:10:51 2024
  read: IOPS=126k, BW=1972MiB/s (2068MB/s)(116GiB/60002msec)
    slat (usec): min=4, max=9780, avg=29.45, stdev=79.94
    clat (usec): min=508, max=24777, avg=8080.87, stdev=2975.44
     lat (usec): min=515, max=24850, avg=8110.64, stdev=2986.37
    clat percentiles (usec):
     |  1.00th=[ 4752],  5.00th=[ 5145], 10.00th=[ 5473], 20.00th=[ 5997],
     | 30.00th=[ 6390], 40.00th=[ 6652], 50.00th=[ 6915], 60.00th=[ 7177],
     | 70.00th=[ 7767], 80.00th=[11076], 90.00th=[12649], 95.00th=[13960],
     | 99.00th=[17433], 99.50th=[17957], 99.90th=[18744], 99.95th=[19006],
     | 99.99th=[21890]
   bw (  MiB/s): min=  909, max= 3086, per=100.00%, avg=1973.54, stdev=138.20, samples=476
   iops        : min=58232, max=197540, avg=126306.21, stdev=8844.86, samples=476
  lat (usec)   : 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.01%, 10=76.10%, 20=23.86%, 50=0.02%
  cpu          : usr=8.85%, sys=30.51%, ctx=2466018, majf=0, minf=4153
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=7572146,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=1972MiB/s (2068MB/s), 1972MiB/s-1972MiB/s (2068MB/s-2068MB/s), io=116GiB (124GB), run=60002-60002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=16k) read:  read: IOPS=126k, BW=1972MiB/s (2068MB/s)(116GiB/60002msec)


===Fio: workload=read, time=60, iodepth=256, bs=64k, disks=4 ===

j1: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j2: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j3: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j4: (g=0): rw=read, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 4553 MiB read, 0.000 read amp, 276793166 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 278423604 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 280110662 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9582: Fri Jan 12 18:11:53 2024
  read: IOPS=42.2k, BW=2638MiB/s (2766MB/s)(155GiB/60010msec)
    slat (usec): min=5, max=12194, avg=92.42, stdev=131.95
    clat (usec): min=1428, max=91226, avg=24145.45, stdev=8550.31
     lat (usec): min=1627, max=91299, avg=24238.27, stdev=8582.50
    clat percentiles (usec):
     |  1.00th=[16581],  5.00th=[17433], 10.00th=[17957], 20.00th=[18220],
     | 30.00th=[18744], 40.00th=[19006], 50.00th=[19792], 60.00th=[23725],
     | 70.00th=[27919], 80.00th=[29230], 90.00th=[34341], 95.00th=[36439],
     | 99.00th=[55837], 99.50th=[74974], 99.90th=[80217], 99.95th=[81265],
     | 99.99th=[86508]
   bw (  MiB/s): min= 1235, max= 3663, per=100.00%, avg=2639.16, stdev=168.95, samples=480
   iops        : min=19766, max=58612, avg=42225.73, stdev=2703.12, samples=480
  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.05%, 20=52.95%, 50=45.17%
  lat (msec)   : 100=1.82%
  cpu          : usr=4.27%, sys=14.25%, ctx=2539790, majf=0, minf=16440
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=2532683,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=2638MiB/s (2766MB/s), 2638MiB/s-2638MiB/s (2766MB/s-2766MB/s), io=155GiB (166GB), run=60010-60010msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=64k) read:  read: IOPS=42.2k, BW=2638MiB/s (2766MB/s)(155GiB/60010msec)
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 281722356 total
[0m

===Fio: workload=randread, time=60, iodepth=256, bs=4k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 587 MiB read, 0.000 read amp, 285234851 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 289250949 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 588 MiB read, 0.000 read amp, 293063071 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9631: Fri Jan 12 18:12:56 2024
  read: IOPS=179k, BW=701MiB/s (735MB/s)(41.1GiB/60001msec)
    slat (usec): min=3, max=9611, avg=20.21, stdev=52.26
    clat (usec): min=556, max=20885, avg=5687.18, stdev=1994.14
     lat (usec): min=565, max=20999, avg=5707.64, stdev=2001.64
    clat percentiles (usec):
     |  1.00th=[ 3523],  5.00th=[ 3687], 10.00th=[ 3752], 20.00th=[ 3916],
     | 30.00th=[ 4113], 40.00th=[ 4293], 50.00th=[ 4490], 60.00th=[ 6652],
     | 70.00th=[ 7111], 80.00th=[ 7635], 90.00th=[ 8225], 95.00th=[ 9110],
     | 99.00th=[10945], 99.50th=[11863], 99.90th=[14222], 99.95th=[15795],
     | 99.99th=[19006]
   bw (  KiB/s): min=395176, max=1100088, per=100.00%, avg=719315.85, stdev=49449.08, samples=476
   iops        : min=98794, max=275022, avg=179828.72, stdev=12362.26, samples=476
  lat (usec)   : 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=23.73%, 10=74.23%, 20=2.04%, 50=0.01%
  cpu          : usr=11.29%, sys=32.77%, ctx=1280949, majf=0, minf=1073
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=10761240,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=701MiB/s (735MB/s), 701MiB/s-701MiB/s (735MB/s-735MB/s), io=41.1GiB (44.1GB), run=60001-60001msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=4k) randread:  read: IOPS=179k, BW=701MiB/s (735MB/s)(41.1GiB/60001msec)


===Fio: workload=randread, time=60, iodepth=256, bs=16k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 16.0KiB-16.0KiB, (W) 16.0KiB-16.0KiB, (T) 16.0KiB-16.0KiB, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 2000 MiB read, 0.000 read amp, 295561573 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1998 MiB read, 0.000 read amp, 298433249 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 1995 MiB read, 0.000 read amp, 301353727 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9680: Fri Jan 12 18:13:58 2024
  read: IOPS=115k, BW=1798MiB/s (1886MB/s)(105GiB/60002msec)
    slat (usec): min=4, max=7889, avg=32.09, stdev=88.91
    clat (usec): min=478, max=24872, avg=8862.32, stdev=3357.33
     lat (usec): min=1152, max=24888, avg=8894.76, stdev=3369.60
    clat percentiles (usec):
     |  1.00th=[ 5276],  5.00th=[ 5604], 10.00th=[ 5866], 20.00th=[ 6259],
     | 30.00th=[ 6587], 40.00th=[ 6849], 50.00th=[ 7177], 60.00th=[ 7767],
     | 70.00th=[10683], 80.00th=[12518], 90.00th=[13566], 95.00th=[14484],
     | 99.00th=[19006], 99.50th=[19530], 99.90th=[20841], 99.95th=[22152],
     | 99.99th=[23725]
   bw (  MiB/s): min=  842, max= 2834, per=100.00%, avg=1799.52, stdev=129.53, samples=476
   iops        : min=53920, max=181430, avg=115169.22, stdev=8289.89, samples=476
  lat (usec)   : 500=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.01%, 10=67.46%, 20=32.25%, 50=0.29%
  cpu          : usr=8.91%, sys=29.09%, ctx=2245214, majf=0, minf=4142
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=6905589,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=1798MiB/s (1886MB/s), 1798MiB/s-1798MiB/s (1886MB/s-1886MB/s), io=105GiB (113GB), run=60002-60002msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=16k) randread:  read: IOPS=115k, BW=1798MiB/s (1886MB/s)(105GiB/60002msec)


===Fio: workload=randread, time=60, iodepth=256, bs=64k, disks=4 ===

j1: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j2: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j3: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
j4: (g=0): rw=randread, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=io_uring, iodepth=256
fio-3.28
Starting 4 processes
[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 303046930 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 304650161 total
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 306245241 total
[0m
j1: (groupid=0, jobs=4): err= 0: pid=9730: Fri Jan 12 18:15:01 2024
  read: IOPS=40.8k, BW=2553MiB/s (2677MB/s)(150GiB/60007msec)
    slat (usec): min=5, max=540873, avg=94.99, stdev=378.59
    clat (usec): min=1735, max=599100, avg=24967.47, stdev=9369.39
     lat (usec): min=1957, max=599216, avg=25062.89, stdev=9398.50
    clat percentiles (msec):
     |  1.00th=[   18],  5.00th=[   18], 10.00th=[   19], 20.00th=[   19],
     | 30.00th=[   20], 40.00th=[   22], 50.00th=[   23], 60.00th=[   25],
     | 70.00th=[   27], 80.00th=[   31], 90.00th=[   37], 95.00th=[   41],
     | 99.00th=[   46], 99.50th=[   56], 99.90th=[   57], 99.95th=[   58],
     | 99.99th=[  575]
   bw (  MiB/s): min= 1095, max= 3513, per=100.00%, avg=2557.44, stdev=159.15, samples=476
   iops        : min=17524, max=56214, avg=40919.27, stdev=2546.35, samples=476
  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.02%, 20=35.61%, 50=63.66%
  lat (msec)   : 100=0.70%, 750=0.01%
  cpu          : usr=5.04%, sys=14.48%, ctx=2463598, majf=0, minf=16432
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=2451015,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=256

Run status group 0 (all jobs):
   READ: bw=2553MiB/s (2677MB/s), 2553MiB/s-2553MiB/s (2677MB/s-2677MB/s), io=150GiB (161GB), run=60007-60007msec

Disk stats (read/write):
  nvme1n1: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n2: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n3: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%
  nvme1n4: ios=0/0, merge=0/0, ticks=0/0, in_queue=0, util=0.00%

RESULT: Fio (disks=4, iodepth=256; bs=64k) randread:  read: IOPS=40.8k, BW=2553MiB/s (2677MB/s)(150GiB/60007msec)
umount: /mnt/fsbench: not mounted.
NQN:nqn.2016-06.io.spdk:cnode1 disconnected 1 controller(s)
+ perl -lane 'print if s/^RESULT: //' /home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T17:36:41.lsvd-multi.triple-hdd.txt
+ tee -a /home/isaackhor/code/lsvd-rbd/experiments/results/2024-01-12T17:36:41.lsvd-multi.triple-hdd.txt
Fio (disks=4, iodepth=256; bs=4ki) randread:  read: IOPS=179k, BW=698MiB/s (732MB/s)(123GiB/180001msec)
Fio (disks=1, iodepth=128; bs=4ki) randread:  read: IOPS=69.0k, BW=270MiB/s (283MB/s)(15.8GiB/60001msec)
Fio (disks=2, iodepth=128; bs=4ki) randread:  read: IOPS=128k, BW=499MiB/s (523MB/s)(29.2GiB/60001msec)
Fio (disks=3, iodepth=128; bs=4ki) randread:  read: IOPS=173k, BW=677MiB/s (710MB/s)(39.7GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4ki) randread:  read: IOPS=184k, BW=718MiB/s (753MB/s)(42.1GiB/60001msec)
Fio (disks=1, iodepth=128; bs=4ki) read:  read: IOPS=81.4k, BW=318MiB/s (334MB/s)(18.6GiB/60001msec)
Fio (disks=2, iodepth=128; bs=4ki) read:  read: IOPS=148k, BW=578MiB/s (606MB/s)(33.9GiB/60001msec)
Fio (disks=3, iodepth=128; bs=4ki) read:  read: IOPS=195k, BW=762MiB/s (799MB/s)(44.7GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4ki) read:  read: IOPS=202k, BW=788MiB/s (827MB/s)(46.2GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4ki) randread:  read: IOPS=172k, BW=671MiB/s (704MB/s)(19.7GiB/30001msec)
Fio (disks=4, iodepth=128; bs=8ki) randread:  read: IOPS=162k, BW=1269MiB/s (1331MB/s)(37.2GiB/30001msec)
Fio (disks=4, iodepth=128; bs=16ki) randread:  read: IOPS=116k, BW=1814MiB/s (1902MB/s)(53.1GiB/30002msec)
Fio (disks=4, iodepth=128; bs=32ki) randread:  read: IOPS=80.3k, BW=2509MiB/s (2631MB/s)(73.5GiB/30003msec)
Fio (disks=4, iodepth=128; bs=64ki) randread:  read: IOPS=26.3k, BW=1644MiB/s (1723MB/s)(48.2GiB/30013msec)
Fio (disks=4, iodepth=128; bs=4ki) read:  read: IOPS=192k, BW=750MiB/s (787MB/s)(22.0GiB/30001msec)
Fio (disks=4, iodepth=128; bs=8ki) read:  read: IOPS=163k, BW=1272MiB/s (1334MB/s)(37.3GiB/30001msec)
Fio (disks=4, iodepth=128; bs=16ki) read:  read: IOPS=127k, BW=1979MiB/s (2076MB/s)(58.0GiB/30002msec)
Fio (disks=4, iodepth=128; bs=32ki) read:  read: IOPS=69.9k, BW=2184MiB/s (2290MB/s)(64.0GiB/30003msec)
Fio (disks=4, iodepth=128; bs=64ki) read:  read: IOPS=41.8k, BW=2615MiB/s (2742MB/s)(76.6GiB/30006msec)
Fio (disks=4, iodepth=256; bs=4k) randread:  read: IOPS=173k, BW=677MiB/s (710MB/s)(39.7GiB/60001msec)
Fio (disks=4, iodepth=256; bs=4k) read:  read: IOPS=205k, BW=802MiB/s (841MB/s)(47.0GiB/60001msec)
Fio (disks=4, iodepth=1; bs=4k) randread:  read: IOPS=30.5k, BW=119MiB/s (125MB/s)(7141MiB/60001msec)
Fio (disks=4, iodepth=32; bs=4k) randread:  read: IOPS=182k, BW=711MiB/s (746MB/s)(41.7GiB/60001msec)
Fio (disks=4, iodepth=64; bs=4k) randread:  read: IOPS=182k, BW=712MiB/s (747MB/s)(41.7GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4k) randread:  read: IOPS=171k, BW=668MiB/s (700MB/s)(39.1GiB/60001msec)
Fio (disks=4, iodepth=1; bs=4k) read:  read: IOPS=32.1k, BW=125MiB/s (131MB/s)(7512MiB/60001msec)
Fio (disks=4, iodepth=32; bs=4k) read:  read: IOPS=211k, BW=825MiB/s (865MB/s)(48.3GiB/60001msec)
Fio (disks=4, iodepth=64; bs=4k) read:  read: IOPS=208k, BW=812MiB/s (851MB/s)(47.6GiB/60001msec)
Fio (disks=4, iodepth=128; bs=4k) read:  read: IOPS=196k, BW=765MiB/s (803MB/s)(44.8GiB/60001msec)
Fio (disks=4, iodepth=256; bs=4k) read:  read: IOPS=200k, BW=783MiB/s (821MB/s)(45.9GiB/60001msec)
Fio (disks=4, iodepth=256; bs=16k) read:  read: IOPS=126k, BW=1972MiB/s (2068MB/s)(116GiB/60002msec)
Fio (disks=4, iodepth=256; bs=64k) read:  read: IOPS=42.2k, BW=2638MiB/s (2766MB/s)(155GiB/60010msec)
Fio (disks=4, iodepth=256; bs=4k) randread:  read: IOPS=179k, BW=701MiB/s (735MB/s)(41.1GiB/60001msec)
Fio (disks=4, iodepth=256; bs=16k) randread:  read: IOPS=115k, BW=1798MiB/s (1886MB/s)(105GiB/60002msec)
Fio (disks=4, iodepth=256; bs=64k) randread:  read: IOPS=40.8k, BW=2553MiB/s (2677MB/s)(150GiB/60007msec)
+ cleanup_nvmf
+ cd /home/isaackhor/code/lsvd-rbd/spdk
+ scripts/rpc.py spdk_kill_instance SIGTERM
[1m[36m[INFO liblsvd.cc:287 rbd_close] Closing image lsvd-benchmark.multi.4
[0m[1m[36m[INFO liblsvd.cc:287 rbd_close] Closing image lsvd-benchmark.multi.3
[0m+ exit
[1m[36m[INFO liblsvd.cc:287 rbd_close] Closing image lsvd-benchmark.multi.2
[0m[1m[36m[INFO liblsvd.cc:287 rbd_close] Closing image lsvd-benchmark.multi.1
[0m[35m[DBG shared_read_cache.cc:805 report_cache_stats] 160000/160000 hits, 5000 MiB read, 0.000 read amp, 306689683 total
[0m[35m[DBG shared_read_cache.cc:808 report_cache_stats] cache stats reporter exiting
[0mflush thread (7fa04f7fe640) exiting
flush thread (7fa07d7f2640) exiting
flush thread (7fa0a2ff5640) exiting
flush thread (7fa0b47e8640) exiting
./experiments/bench-suite.bash: line 28: ./multi-client/bench-rbd-multi.bash: Permission denied
./experiments/bench-suite.bash: line 29: ./multi-client/bench-rbd-multi.bash: Permission denied
